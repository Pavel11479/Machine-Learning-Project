{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns # for visualisation\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = 'Downloads/sml-ht2021/'\n",
    "y_train = pd.read_csv(rep + 'y_train.csv', index_col = 0, squeeze=True)\n",
    "X_train = pd.read_csv(rep + 'X_train.csv', index_col = 0, header=[0, 1, 2])\n",
    "X_test = pd.read_csv(rep + 'X_test.csv', index_col = 0, header=[0, 1, 2])\n",
    "from sklearn.model_selection import train_test_split\n",
    "inputs_train, inputs_test, targets_train, targets_test = train_test_split(X_train, y_train, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train_nn = inputs_train.reset_index(drop=True)\n",
    "inputs_test_nn = inputs_test.reset_index(drop=True)\n",
    "targets_train_nn=targets_train.reset_index(drop=True)\n",
    "targets_test_nn=targets_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y_pred_RF = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    RF = RandomForestClassifier(n_estimators = 150, max_depth = 50, class_weight = 'balanced')\n",
    "    RF_prob = RF.fit(inputs_train.drop(inputs_train.index[i-840:i]), \n",
    "                       targets_train.drop(targets_train.index[i-840:i])).predict_proba(inputs_train[i-840:i])\n",
    "    y_pred_RF = np.append(y_pred_RF, RF_prob, axis = 0)\n",
    "\n",
    "\n",
    "dfRF_train = pd.DataFrame(y_pred_RF, columns = ['RF_El', 'RF_Exp', 'RF_Flk', 'RF_HH', \n",
    "                                           'RF_Inst', 'RF_Intr', 'RF_Pop', 'RF_Rck'])\n",
    "\n",
    "RF_fitted = RF.fit(inputs_train, targets_train)\n",
    "\n",
    "y_pred_test_RF = RF_fitted.predict_proba(inputs_test)\n",
    "dfRF_test = pd.DataFrame(y_pred_test_RF, columns = ['RF_El', 'RF_Exp', 'RF_Flk', 'RF_HH', \n",
    "                                           'RF_Inst', 'RF_Intr', 'RF_Pop', 'RF_Rck'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# PASHA PLEASE CHECK TO MAKE SURE THIS IS THE SAME ORDER OF CLASSES AS YOU ARE USING\n",
    "classes = ['Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental','International', 'Pop', 'Rock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(AudioDataset, self).__init__()\n",
    "        assert x.shape[0] == y.shape[0] # assuming shape[0] = dataset size\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x_tensor = torch.tensor(self.x.loc[index].values, dtype=torch.float)\n",
    "        y_tensor = torch.tensor(self.y.loc[index], dtype=torch.long)\n",
    "        return (x_tensor, y_tensor)\n",
    "    \n",
    "def nn_accuracy(network, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i,d in enumerate(data_loader):\n",
    "            data, labels = d\n",
    "            outputs = network(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #print(i,predicted,labels)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def nn_train(net, train_dl, val_dl, SAVE_PATH, epoch_num=20, num_batches=100, \n",
    "             lr=0.01, momentum=0.9, verbose=False):\n",
    "    # define the optimization\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    # enumerate epochs\n",
    "    max_val_acc = 0\n",
    "    for epoch in range(epoch_num):\n",
    "        # enumerate mini batches\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_dl):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # training loss\n",
    "            running_loss += loss.item()\n",
    "            val_acc = nn_accuracy(net, val_dl)\n",
    "            if val_acc > max_val_acc:\n",
    "                    torch.save(net.state_dict(), SAVE_PATH)\n",
    "                    max_val_acc = val_acc\n",
    "            if i % num_batches == (num_batches-1): \n",
    "                tr_acc = nn_accuracy(net, train_dl)\n",
    "                val_acc = nn_accuracy(net, val_dl)\n",
    "                if verbose:\n",
    "                    print('[EPOCH #', epoch+1,']') \n",
    "                    print('       Loss:', round(running_loss / num_batches, 3))\n",
    "                    print('  Train Acc:', round(tr_acc,2), '%')\n",
    "                    print('    Val Acc:', round(val_acc,2),'%')\n",
    "                    print('Max Val Acc:', round(max_val_acc,2) ,'%')\n",
    "                    print(\"------------\")\n",
    "                running_loss = 0.0\n",
    "                \n",
    "\n",
    "    print('Finished Training')\n",
    "    print('Max Validation Acc:', max_val_acc, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(len(X_train.columns), 800)\n",
    "        self.fc2 = nn.Linear(800, 100)\n",
    "        self.fc3 = nn.Linear(100, 500)\n",
    "        self.fc4 = nn.Linear(500, 100)\n",
    "        self.fc5 = nn.Linear(100, 100)\n",
    "        self.fc6 = nn.Linear(100, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.celu(self.fc1(x))\n",
    "        x = torch.celu(self.fc2(x),alpha=2)\n",
    "        x = torch.celu(self.fc3(x),alpha=3)\n",
    "        x = torch.celu(self.fc4(x),alpha=2)\n",
    "        x = torch.celu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_train_to_prob_mat(X_train, y_train, X_test, epoch_num = 20, class_labels=classes, verbose=False):\n",
    "    \n",
    "    y_train = y_train.replace(classes,range(0,len(class_labels)))\n",
    "    \n",
    "    # normalize data\n",
    "    std_scale = StandardScaler()\n",
    "    X_train = std_scale.fit_transform(X_train)\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = std_scale.transform(X_test)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    \n",
    "    # make dataset\n",
    "    dataset = AudioDataset(X_train,y_train)\n",
    "    \n",
    "    # split into train and validation set for nn training\n",
    "    num_train = int(len(X_train)*.8)\n",
    "    num_val = len(X_train)-num_train\n",
    "    batch_size = 100\n",
    "    num_batches = num_train//batch_size\n",
    "    train, val = random_split(dataset, [num_train,num_val])\n",
    "    \n",
    "    # make dataloaders\n",
    "    train_dl = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val, batch_size=num_val, shuffle=False)\n",
    "    #test_dl = DataLoader(val, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # make folder to save network params if does not exist\n",
    "    if not os.path.exists('./NN_CV_params'):\n",
    "        os.makedirs('./NN_CV_params')\n",
    "    \n",
    "    # train the network\n",
    "    if verbose:\n",
    "        print(\"--- BEGIN TRAINING NETWORK ---\")\n",
    "    net = Net()\n",
    "    nn_train(net, train_dl, val_dl, './NN_CV_params/network_params.pth',epoch_num=epoch_num,\n",
    "             num_batches=num_batches,verbose=verbose)\n",
    "    if verbose:\n",
    "        print(\"--- FINISHED TRAINING NETWORK ---\")\n",
    "    \n",
    "    # generate probability matrix for test data\n",
    "    prob_matrix = []\n",
    "    with torch.no_grad():\n",
    "        for index in range(len(X_test)):\n",
    "            data = torch.tensor(X_test.loc[index].values, dtype=torch.float)\n",
    "            net.load_state_dict(torch.load('./NN_CV_params/network_params.pth'))\n",
    "            outputs = torch.softmax(net(data).unsqueeze(1).T, dim=1)\n",
    "            prob_dist = outputs.tolist()[0]\n",
    "            prob_matrix.append(prob_dist)\n",
    "            \n",
    "    return np.array(prob_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.055\n",
      "  Train Acc: 35.49 %\n",
      "    Val Acc: 34.23 %\n",
      "Max Val Acc: 34.23 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 1.86\n",
      "  Train Acc: 40.18 %\n",
      "    Val Acc: 37.5 %\n",
      "Max Val Acc: 38.24 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 1.627\n",
      "  Train Acc: 46.65 %\n",
      "    Val Acc: 41.67 %\n",
      "Max Val Acc: 41.67 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 1.445\n",
      "  Train Acc: 50.89 %\n",
      "    Val Acc: 48.07 %\n",
      "Max Val Acc: 48.07 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 1.32\n",
      "  Train Acc: 56.77 %\n",
      "    Val Acc: 49.7 %\n",
      "Max Val Acc: 50.3 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.226\n",
      "  Train Acc: 59.93 %\n",
      "    Val Acc: 51.79 %\n",
      "Max Val Acc: 52.38 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.137\n",
      "  Train Acc: 63.39 %\n",
      "    Val Acc: 51.34 %\n",
      "Max Val Acc: 52.38 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.052\n",
      "  Train Acc: 67.67 %\n",
      "    Val Acc: 50.6 %\n",
      "Max Val Acc: 53.27 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 0.985\n",
      "  Train Acc: 68.42 %\n",
      "    Val Acc: 52.08 %\n",
      "Max Val Acc: 54.32 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 0.942\n",
      "  Train Acc: 70.68 %\n",
      "    Val Acc: 53.12 %\n",
      "Max Val Acc: 54.32 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 0.883\n",
      "  Train Acc: 73.18 %\n",
      "    Val Acc: 51.49 %\n",
      "Max Val Acc: 54.32 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 0.828\n",
      "  Train Acc: 75.26 %\n",
      "    Val Acc: 54.61 %\n",
      "Max Val Acc: 54.61 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 0.774\n",
      "  Train Acc: 76.82 %\n",
      "    Val Acc: 54.17 %\n",
      "Max Val Acc: 54.61 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 0.748\n",
      "  Train Acc: 78.79 %\n",
      "    Val Acc: 52.38 %\n",
      "Max Val Acc: 55.06 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 0.719\n",
      "  Train Acc: 79.39 %\n",
      "    Val Acc: 52.83 %\n",
      "Max Val Acc: 55.06 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 0.67\n",
      "  Train Acc: 80.32 %\n",
      "    Val Acc: 52.53 %\n",
      "Max Val Acc: 55.06 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 0.636\n",
      "  Train Acc: 80.54 %\n",
      "    Val Acc: 52.23 %\n",
      "Max Val Acc: 55.06 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 0.594\n",
      "  Train Acc: 83.85 %\n",
      "    Val Acc: 51.93 %\n",
      "Max Val Acc: 55.06 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 0.542\n",
      "  Train Acc: 86.16 %\n",
      "    Val Acc: 51.34 %\n",
      "Max Val Acc: 55.06 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 0.505\n",
      "  Train Acc: 88.36 %\n",
      "    Val Acc: 52.68 %\n",
      "Max Val Acc: 55.06 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 55.05952380952381 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.059\n",
      "  Train Acc: 29.95 %\n",
      "    Val Acc: 28.87 %\n",
      "Max Val Acc: 28.87 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 1.878\n",
      "  Train Acc: 36.31 %\n",
      "    Val Acc: 34.52 %\n",
      "Max Val Acc: 34.52 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 1.689\n",
      "  Train Acc: 42.67 %\n",
      "    Val Acc: 40.18 %\n",
      "Max Val Acc: 40.18 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 1.512\n",
      "  Train Acc: 49.37 %\n",
      "    Val Acc: 45.24 %\n",
      "Max Val Acc: 45.24 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 1.361\n",
      "  Train Acc: 55.32 %\n",
      "    Val Acc: 46.13 %\n",
      "Max Val Acc: 47.62 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.258\n",
      "  Train Acc: 59.34 %\n",
      "    Val Acc: 49.11 %\n",
      "Max Val Acc: 49.4 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.158\n",
      "  Train Acc: 63.91 %\n",
      "    Val Acc: 52.38 %\n",
      "Max Val Acc: 53.12 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.074\n",
      "  Train Acc: 65.96 %\n",
      "    Val Acc: 53.72 %\n",
      "Max Val Acc: 53.72 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.0\n",
      "  Train Acc: 68.38 %\n",
      "    Val Acc: 53.27 %\n",
      "Max Val Acc: 54.46 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 0.928\n",
      "  Train Acc: 72.17 %\n",
      "    Val Acc: 54.91 %\n",
      "Max Val Acc: 55.8 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 0.873\n",
      "  Train Acc: 74.44 %\n",
      "    Val Acc: 53.42 %\n",
      "Max Val Acc: 55.8 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 0.848\n",
      "  Train Acc: 74.07 %\n",
      "    Val Acc: 54.91 %\n",
      "Max Val Acc: 55.8 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 0.782\n",
      "  Train Acc: 78.31 %\n",
      "    Val Acc: 53.42 %\n",
      "Max Val Acc: 55.8 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 0.742\n",
      "  Train Acc: 79.5 %\n",
      "    Val Acc: 52.98 %\n",
      "Max Val Acc: 55.8 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 0.696\n",
      "  Train Acc: 80.58 %\n",
      "    Val Acc: 52.23 %\n",
      "Max Val Acc: 55.8 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 0.639\n",
      "  Train Acc: 83.04 %\n",
      "    Val Acc: 52.53 %\n",
      "Max Val Acc: 55.8 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 0.612\n",
      "  Train Acc: 82.48 %\n",
      "    Val Acc: 49.4 %\n",
      "Max Val Acc: 55.8 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 0.564\n",
      "  Train Acc: 84.23 %\n",
      "    Val Acc: 52.83 %\n",
      "Max Val Acc: 55.8 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 0.542\n",
      "  Train Acc: 85.68 %\n",
      "    Val Acc: 50.89 %\n",
      "Max Val Acc: 55.8 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 0.495\n",
      "  Train Acc: 84.71 %\n",
      "    Val Acc: 50.3 %\n",
      "Max Val Acc: 55.8 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 55.80357142857143 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.058\n",
      "  Train Acc: 30.88 %\n",
      "    Val Acc: 29.17 %\n",
      "Max Val Acc: 29.17 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 1.884\n",
      "  Train Acc: 39.03 %\n",
      "    Val Acc: 35.42 %\n",
      "Max Val Acc: 35.86 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 1.657\n",
      "  Train Acc: 44.49 %\n",
      "    Val Acc: 42.86 %\n",
      "Max Val Acc: 42.86 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 1.468\n",
      "  Train Acc: 51.08 %\n",
      "    Val Acc: 47.92 %\n",
      "Max Val Acc: 47.92 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 1.334\n",
      "  Train Acc: 56.44 %\n",
      "    Val Acc: 50.0 %\n",
      "Max Val Acc: 51.19 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.224\n",
      "  Train Acc: 60.12 %\n",
      "    Val Acc: 51.93 %\n",
      "Max Val Acc: 51.93 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.139\n",
      "  Train Acc: 62.65 %\n",
      "    Val Acc: 51.64 %\n",
      "Max Val Acc: 52.53 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.063\n",
      "  Train Acc: 65.44 %\n",
      "    Val Acc: 50.3 %\n",
      "Max Val Acc: 52.83 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.011\n",
      "  Train Acc: 69.87 %\n",
      "    Val Acc: 51.34 %\n",
      "Max Val Acc: 53.42 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 0.948\n",
      "  Train Acc: 70.39 %\n",
      "    Val Acc: 50.74 %\n",
      "Max Val Acc: 53.42 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 0.883\n",
      "  Train Acc: 72.54 %\n",
      "    Val Acc: 51.19 %\n",
      "Max Val Acc: 53.42 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 0.835\n",
      "  Train Acc: 75.52 %\n",
      "    Val Acc: 51.19 %\n",
      "Max Val Acc: 54.91 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 0.783\n",
      "  Train Acc: 76.86 %\n",
      "    Val Acc: 52.23 %\n",
      "Max Val Acc: 54.91 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 0.747\n",
      "  Train Acc: 77.6 %\n",
      "    Val Acc: 53.57 %\n",
      "Max Val Acc: 54.91 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 0.702\n",
      "  Train Acc: 79.65 %\n",
      "    Val Acc: 52.53 %\n",
      "Max Val Acc: 54.91 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 0.66\n",
      "  Train Acc: 80.32 %\n",
      "    Val Acc: 51.04 %\n",
      "Max Val Acc: 54.91 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 0.638\n",
      "  Train Acc: 84.0 %\n",
      "    Val Acc: 52.08 %\n",
      "Max Val Acc: 54.91 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 0.584\n",
      "  Train Acc: 84.45 %\n",
      "    Val Acc: 49.4 %\n",
      "Max Val Acc: 54.91 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 0.557\n",
      "  Train Acc: 83.93 %\n",
      "    Val Acc: 49.26 %\n",
      "Max Val Acc: 54.91 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 0.489\n",
      "  Train Acc: 86.42 %\n",
      "    Val Acc: 52.38 %\n",
      "Max Val Acc: 54.91 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 54.910714285714285 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.045\n",
      "  Train Acc: 32.81 %\n",
      "    Val Acc: 29.02 %\n",
      "Max Val Acc: 29.61 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 1.836\n",
      "  Train Acc: 37.65 %\n",
      "    Val Acc: 36.9 %\n",
      "Max Val Acc: 37.35 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 1.697\n",
      "  Train Acc: 41.0 %\n",
      "    Val Acc: 36.76 %\n",
      "Max Val Acc: 37.35 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 1.533\n",
      "  Train Acc: 48.29 %\n",
      "    Val Acc: 45.09 %\n",
      "Max Val Acc: 45.09 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 1.391\n",
      "  Train Acc: 52.19 %\n",
      "    Val Acc: 47.77 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.278\n",
      "  Train Acc: 57.59 %\n",
      "    Val Acc: 52.38 %\n",
      "Max Val Acc: 52.38 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.18\n",
      "  Train Acc: 61.76 %\n",
      "    Val Acc: 52.83 %\n",
      "Max Val Acc: 53.72 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.104\n",
      "  Train Acc: 65.07 %\n",
      "    Val Acc: 54.91 %\n",
      "Max Val Acc: 55.36 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.048\n",
      "  Train Acc: 68.01 %\n",
      "    Val Acc: 54.32 %\n",
      "Max Val Acc: 55.65 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 0.966\n",
      "  Train Acc: 71.28 %\n",
      "    Val Acc: 55.21 %\n",
      "Max Val Acc: 57.14 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 0.903\n",
      "  Train Acc: 72.28 %\n",
      "    Val Acc: 53.72 %\n",
      "Max Val Acc: 57.14 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 0.844\n",
      "  Train Acc: 74.59 %\n",
      "    Val Acc: 52.83 %\n",
      "Max Val Acc: 57.14 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 0.815\n",
      "  Train Acc: 76.19 %\n",
      "    Val Acc: 53.57 %\n",
      "Max Val Acc: 57.14 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 0.765\n",
      "  Train Acc: 77.49 %\n",
      "    Val Acc: 53.12 %\n",
      "Max Val Acc: 57.14 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 0.699\n",
      "  Train Acc: 80.21 %\n",
      "    Val Acc: 54.32 %\n",
      "Max Val Acc: 57.14 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 0.674\n",
      "  Train Acc: 80.69 %\n",
      "    Val Acc: 51.93 %\n",
      "Max Val Acc: 57.14 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 0.618\n",
      "  Train Acc: 82.89 %\n",
      "    Val Acc: 53.57 %\n",
      "Max Val Acc: 57.14 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 0.587\n",
      "  Train Acc: 84.0 %\n",
      "    Val Acc: 52.83 %\n",
      "Max Val Acc: 57.14 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 0.571\n",
      "  Train Acc: 85.19 %\n",
      "    Val Acc: 50.3 %\n",
      "Max Val Acc: 57.14 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 0.538\n",
      "  Train Acc: 86.57 %\n",
      "    Val Acc: 52.08 %\n",
      "Max Val Acc: 57.14 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 57.142857142857146 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.051\n",
      "  Train Acc: 28.24 %\n",
      "    Val Acc: 28.27 %\n",
      "Max Val Acc: 28.27 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 1.873\n",
      "  Train Acc: 36.38 %\n",
      "    Val Acc: 37.8 %\n",
      "Max Val Acc: 37.8 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 1.678\n",
      "  Train Acc: 43.97 %\n",
      "    Val Acc: 43.6 %\n",
      "Max Val Acc: 43.6 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 1.501\n",
      "  Train Acc: 49.96 %\n",
      "    Val Acc: 47.47 %\n",
      "Max Val Acc: 47.47 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 1.371\n",
      "  Train Acc: 54.39 %\n",
      "    Val Acc: 51.64 %\n",
      "Max Val Acc: 51.93 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.265\n",
      "  Train Acc: 59.26 %\n",
      "    Val Acc: 52.83 %\n",
      "Max Val Acc: 53.87 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.18\n",
      "  Train Acc: 62.95 %\n",
      "    Val Acc: 54.76 %\n",
      "Max Val Acc: 55.06 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.099\n",
      "  Train Acc: 65.33 %\n",
      "    Val Acc: 54.32 %\n",
      "Max Val Acc: 55.36 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.026\n",
      "  Train Acc: 68.15 %\n",
      "    Val Acc: 55.65 %\n",
      "Max Val Acc: 56.7 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 0.975\n",
      "  Train Acc: 70.42 %\n",
      "    Val Acc: 56.7 %\n",
      "Max Val Acc: 59.23 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 0.923\n",
      "  Train Acc: 73.62 %\n",
      "    Val Acc: 57.74 %\n",
      "Max Val Acc: 59.23 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 0.853\n",
      "  Train Acc: 75.15 %\n",
      "    Val Acc: 57.89 %\n",
      "Max Val Acc: 59.23 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 0.796\n",
      "  Train Acc: 74.74 %\n",
      "    Val Acc: 59.08 %\n",
      "Max Val Acc: 59.23 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 0.778\n",
      "  Train Acc: 77.86 %\n",
      "    Val Acc: 56.99 %\n",
      "Max Val Acc: 59.23 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 0.721\n",
      "  Train Acc: 79.84 %\n",
      "    Val Acc: 57.14 %\n",
      "Max Val Acc: 59.23 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 0.677\n",
      "  Train Acc: 82.29 %\n",
      "    Val Acc: 55.65 %\n",
      "Max Val Acc: 59.23 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 0.607\n",
      "  Train Acc: 82.51 %\n",
      "    Val Acc: 53.87 %\n",
      "Max Val Acc: 59.23 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 0.572\n",
      "  Train Acc: 84.82 %\n",
      "    Val Acc: 54.46 %\n",
      "Max Val Acc: 59.23 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 0.549\n",
      "  Train Acc: 85.04 %\n",
      "    Val Acc: 54.32 %\n",
      "Max Val Acc: 59.23 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 0.542\n",
      "  Train Acc: 87.98 %\n",
      "    Val Acc: 57.29 %\n",
      "Max Val Acc: 59.23 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 59.226190476190474 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.057\n",
      "  Train Acc: 33.18 %\n",
      "    Val Acc: 32.89 %\n",
      "Max Val Acc: 33.18 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 1.89\n",
      "  Train Acc: 36.27 %\n",
      "    Val Acc: 35.57 %\n",
      "Max Val Acc: 35.57 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 1.691\n",
      "  Train Acc: 43.45 %\n",
      "    Val Acc: 38.39 %\n",
      "Max Val Acc: 38.39 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 1.51\n",
      "  Train Acc: 49.59 %\n",
      "    Val Acc: 46.88 %\n",
      "Max Val Acc: 46.88 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 1.372\n",
      "  Train Acc: 54.43 %\n",
      "    Val Acc: 50.15 %\n",
      "Max Val Acc: 50.6 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.277\n",
      "  Train Acc: 58.37 %\n",
      "    Val Acc: 50.6 %\n",
      "Max Val Acc: 51.64 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.183\n",
      "  Train Acc: 61.27 %\n",
      "    Val Acc: 52.23 %\n",
      "Max Val Acc: 52.98 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.112\n",
      "  Train Acc: 65.36 %\n",
      "    Val Acc: 54.32 %\n",
      "Max Val Acc: 54.61 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.026\n",
      "  Train Acc: 68.23 %\n",
      "    Val Acc: 54.17 %\n",
      "Max Val Acc: 55.21 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 0.984\n",
      "  Train Acc: 69.31 %\n",
      "    Val Acc: 53.27 %\n",
      "Max Val Acc: 55.21 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 0.929\n",
      "  Train Acc: 70.46 %\n",
      "    Val Acc: 53.12 %\n",
      "Max Val Acc: 55.21 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 0.874\n",
      "  Train Acc: 72.51 %\n",
      "    Val Acc: 54.61 %\n",
      "Max Val Acc: 55.65 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 0.817\n",
      "  Train Acc: 75.97 %\n",
      "    Val Acc: 52.83 %\n",
      "Max Val Acc: 55.95 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 0.777\n",
      "  Train Acc: 74.18 %\n",
      "    Val Acc: 50.45 %\n",
      "Max Val Acc: 55.95 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 0.767\n",
      "  Train Acc: 78.27 %\n",
      "    Val Acc: 51.64 %\n",
      "Max Val Acc: 55.95 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 0.695\n",
      "  Train Acc: 80.62 %\n",
      "    Val Acc: 52.98 %\n",
      "Max Val Acc: 55.95 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 0.642\n",
      "  Train Acc: 79.65 %\n",
      "    Val Acc: 52.98 %\n",
      "Max Val Acc: 55.95 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 0.601\n",
      "  Train Acc: 84.52 %\n",
      "    Val Acc: 52.08 %\n",
      "Max Val Acc: 55.95 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 0.552\n",
      "  Train Acc: 83.97 %\n",
      "    Val Acc: 54.17 %\n",
      "Max Val Acc: 55.95 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 0.52\n",
      "  Train Acc: 86.31 %\n",
      "    Val Acc: 53.87 %\n",
      "Max Val Acc: 55.95 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 55.95238095238095 %\n",
      "--- FINISHED TRAINING NETWORK ---\n"
     ]
    }
   ],
   "source": [
    "y_pred_NN = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    \n",
    "    inputs_train_d = inputs_train.drop(inputs_train.index[i-840:i])\n",
    "    targets_train_d = targets_train.drop(targets_train.index[i-840:i])\n",
    "    inputs_train_td = inputs_train[i-840:i]\n",
    "    \n",
    "    inputs_train_nn = inputs_train_d.reset_index(drop=True)\n",
    "    inputs_test_nn = inputs_train_td.reset_index(drop=True)\n",
    "    targets_train_nn=targets_train_d.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    NN_prob = nn_train_to_prob_mat(inputs_train_nn,\n",
    "                                    targets_train_nn, \n",
    "                                    inputs_test_nn, class_labels=classes, epoch_num=20, verbose=True)\n",
    "    y_pred_NN = np.append(y_pred_NN, NN_prob, axis = 0)\n",
    "\n",
    "dfNN_train = pd.DataFrame(y_pred_NN, columns = ['NN_El', 'NN_Exp', 'NN_Flk', 'NN_HH', \n",
    "                                           'NN_Inst', 'NN_Intr', 'NN_Pop', 'NN_Rck'])\n",
    "\n",
    "inputs_train_nnf = inputs_train.reset_index(drop=True)\n",
    "targets_train_nnf = targets_train.reset_index(drop=True)\n",
    "inputs_test_nnf = inputs_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "y_pred_test_NN = nn_train_to_prob_mat(inputs_train_nnf,\n",
    "                                    targets_train_nnf, inputs_test_nnf, class_labels=classes, epoch_num=20, verbose=True)\n",
    "\n",
    "dfNN_test = pd.DataFrame(y_pred_test_NN, columns = ['NN_El', 'NN_Exp', 'NN_Flk', 'NN_HH', \n",
    "                                           'NN_Inst', 'NN_Intr', 'NN_Pop', 'NN_Rck'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different activation functions\n",
    "class Net2(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.fc1 = nn.Linear(len(X_train.columns), 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.fc3 = nn.Linear(300, 200)\n",
    "        self.fc4 = nn.Linear(200, 100)\n",
    "        self.fc5 = nn.Linear(100, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_train_to_prob_mat(X_train, y_train, X_test, epoch_num = 20, class_labels=classes, verbose=False):\n",
    "    \n",
    "    y_train = y_train.replace(classes,range(0,len(class_labels)))\n",
    "    \n",
    "    # normalize data\n",
    "    std_scale = StandardScaler()\n",
    "    X_train = std_scale.fit_transform(X_train)\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = std_scale.transform(X_test)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    \n",
    "    # make dataset\n",
    "    dataset = AudioDataset(X_train,y_train)\n",
    "    \n",
    "    # split into train and validation set for nn training\n",
    "    num_train = int(len(X_train)*.8)\n",
    "    num_val = len(X_train)-num_train\n",
    "    batch_size = 100\n",
    "    num_batches = num_train//batch_size\n",
    "    train, val = random_split(dataset, [num_train,num_val])\n",
    "    \n",
    "    # make dataloaders\n",
    "    train_dl = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val, batch_size=num_val, shuffle=False)\n",
    "    #test_dl = DataLoader(val, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # make folder to save network params if does not exist\n",
    "    if not os.path.exists('./NN_CV_params'):\n",
    "        os.makedirs('./NN_CV_params')\n",
    "    \n",
    "    # train the network\n",
    "    if verbose:\n",
    "        print(\"--- BEGIN TRAINING NETWORK ---\")\n",
    "    net = Net2()\n",
    "    nn_train(net, train_dl, val_dl, './NN_CV_params/network_params.pth',epoch_num=epoch_num,\n",
    "             num_batches=num_batches,verbose=verbose)\n",
    "    if verbose:\n",
    "        print(\"--- FINISHED TRAINING NETWORK ---\")\n",
    "    \n",
    "    # generate probability matrix for test data\n",
    "    prob_matrix = []\n",
    "    with torch.no_grad():\n",
    "        for index in range(len(X_test)):\n",
    "            data = torch.tensor(X_test.loc[index].values, dtype=torch.float)\n",
    "            net.load_state_dict(torch.load('./NN_CV_params/network_params.pth'))\n",
    "            outputs = torch.softmax(net(data).unsqueeze(1).T, dim=1)\n",
    "            prob_dist = outputs.tolist()[0]\n",
    "            prob_matrix.append(prob_dist)\n",
    "            \n",
    "    return np.array(prob_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.08\n",
      "  Train Acc: 13.95 %\n",
      "    Val Acc: 13.69 %\n",
      "Max Val Acc: 14.58 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.075\n",
      "  Train Acc: 16.67 %\n",
      "    Val Acc: 15.48 %\n",
      "Max Val Acc: 16.82 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.068\n",
      "  Train Acc: 22.58 %\n",
      "    Val Acc: 23.66 %\n",
      "Max Val Acc: 25.6 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.058\n",
      "  Train Acc: 23.85 %\n",
      "    Val Acc: 23.51 %\n",
      "Max Val Acc: 25.6 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.036\n",
      "  Train Acc: 24.33 %\n",
      "    Val Acc: 23.66 %\n",
      "Max Val Acc: 25.6 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.98\n",
      "  Train Acc: 25.33 %\n",
      "    Val Acc: 23.96 %\n",
      "Max Val Acc: 25.6 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.884\n",
      "  Train Acc: 32.22 %\n",
      "    Val Acc: 31.25 %\n",
      "Max Val Acc: 31.25 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.826\n",
      "  Train Acc: 32.18 %\n",
      "    Val Acc: 33.18 %\n",
      "Max Val Acc: 33.18 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.793\n",
      "  Train Acc: 32.22 %\n",
      "    Val Acc: 32.89 %\n",
      "Max Val Acc: 33.18 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 1.739\n",
      "  Train Acc: 34.08 %\n",
      "    Val Acc: 31.1 %\n",
      "Max Val Acc: 34.97 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.695\n",
      "  Train Acc: 34.93 %\n",
      "    Val Acc: 33.93 %\n",
      "Max Val Acc: 35.71 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.665\n",
      "  Train Acc: 36.38 %\n",
      "    Val Acc: 36.61 %\n",
      "Max Val Acc: 37.35 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.631\n",
      "  Train Acc: 41.52 %\n",
      "    Val Acc: 42.41 %\n",
      "Max Val Acc: 43.15 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.58\n",
      "  Train Acc: 42.04 %\n",
      "    Val Acc: 41.82 %\n",
      "Max Val Acc: 43.15 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.529\n",
      "  Train Acc: 44.72 %\n",
      "    Val Acc: 44.2 %\n",
      "Max Val Acc: 45.09 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.478\n",
      "  Train Acc: 47.54 %\n",
      "    Val Acc: 45.39 %\n",
      "Max Val Acc: 46.73 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.422\n",
      "  Train Acc: 49.29 %\n",
      "    Val Acc: 47.47 %\n",
      "Max Val Acc: 49.26 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.395\n",
      "  Train Acc: 51.71 %\n",
      "    Val Acc: 49.4 %\n",
      "Max Val Acc: 51.49 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.344\n",
      "  Train Acc: 54.02 %\n",
      "    Val Acc: 49.85 %\n",
      "Max Val Acc: 51.49 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.31\n",
      "  Train Acc: 53.65 %\n",
      "    Val Acc: 50.6 %\n",
      "Max Val Acc: 51.49 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 51.48809523809524 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.078\n",
      "  Train Acc: 17.93 %\n",
      "    Val Acc: 20.68 %\n",
      "Max Val Acc: 20.68 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.071\n",
      "  Train Acc: 21.43 %\n",
      "    Val Acc: 24.7 %\n",
      "Max Val Acc: 25.6 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.06\n",
      "  Train Acc: 25.97 %\n",
      "    Val Acc: 29.61 %\n",
      "Max Val Acc: 29.61 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.035\n",
      "  Train Acc: 29.61 %\n",
      "    Val Acc: 29.46 %\n",
      "Max Val Acc: 32.59 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 1.969\n",
      "  Train Acc: 27.83 %\n",
      "    Val Acc: 28.57 %\n",
      "Max Val Acc: 32.59 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.865\n",
      "  Train Acc: 30.36 %\n",
      "    Val Acc: 31.1 %\n",
      "Max Val Acc: 34.52 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.812\n",
      "  Train Acc: 27.6 %\n",
      "    Val Acc: 27.68 %\n",
      "Max Val Acc: 36.61 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.794\n",
      "  Train Acc: 30.43 %\n",
      "    Val Acc: 34.52 %\n",
      "Max Val Acc: 36.61 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.756\n",
      "  Train Acc: 37.54 %\n",
      "    Val Acc: 38.69 %\n",
      "Max Val Acc: 38.69 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 1.731\n",
      "  Train Acc: 33.07 %\n",
      "    Val Acc: 37.2 %\n",
      "Max Val Acc: 39.14 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.671\n",
      "  Train Acc: 41.37 %\n",
      "    Val Acc: 43.01 %\n",
      "Max Val Acc: 43.01 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.619\n",
      "  Train Acc: 38.76 %\n",
      "    Val Acc: 41.82 %\n",
      "Max Val Acc: 43.6 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.576\n",
      "  Train Acc: 40.48 %\n",
      "    Val Acc: 42.86 %\n",
      "Max Val Acc: 46.28 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.525\n",
      "  Train Acc: 47.06 %\n",
      "    Val Acc: 45.54 %\n",
      "Max Val Acc: 46.73 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.447\n",
      "  Train Acc: 47.28 %\n",
      "    Val Acc: 46.43 %\n",
      "Max Val Acc: 47.17 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.408\n",
      "  Train Acc: 50.56 %\n",
      "    Val Acc: 47.77 %\n",
      "Max Val Acc: 50.6 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.356\n",
      "  Train Acc: 50.04 %\n",
      "    Val Acc: 48.21 %\n",
      "Max Val Acc: 50.89 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.317\n",
      "  Train Acc: 54.5 %\n",
      "    Val Acc: 53.42 %\n",
      "Max Val Acc: 53.42 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.29\n",
      "  Train Acc: 55.73 %\n",
      "    Val Acc: 51.49 %\n",
      "Max Val Acc: 54.91 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.274\n",
      "  Train Acc: 56.14 %\n",
      "    Val Acc: 53.27 %\n",
      "Max Val Acc: 54.91 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 54.910714285714285 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.078\n",
      "  Train Acc: 12.87 %\n",
      "    Val Acc: 12.95 %\n",
      "Max Val Acc: 13.1 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.072\n",
      "  Train Acc: 17.78 %\n",
      "    Val Acc: 18.01 %\n",
      "Max Val Acc: 25.3 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.063\n",
      "  Train Acc: 21.69 %\n",
      "    Val Acc: 22.92 %\n",
      "Max Val Acc: 25.3 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.045\n",
      "  Train Acc: 28.53 %\n",
      "    Val Acc: 30.51 %\n",
      "Max Val Acc: 30.51 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.0\n",
      "  Train Acc: 25.97 %\n",
      "    Val Acc: 26.64 %\n",
      "Max Val Acc: 30.95 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.906\n",
      "  Train Acc: 25.63 %\n",
      "    Val Acc: 26.93 %\n",
      "Max Val Acc: 30.95 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.833\n",
      "  Train Acc: 30.1 %\n",
      "    Val Acc: 29.91 %\n",
      "Max Val Acc: 30.95 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.8\n",
      "  Train Acc: 30.28 %\n",
      "    Val Acc: 28.42 %\n",
      "Max Val Acc: 32.14 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.765\n",
      "  Train Acc: 31.29 %\n",
      "    Val Acc: 29.17 %\n",
      "Max Val Acc: 33.48 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 1.734\n",
      "  Train Acc: 36.76 %\n",
      "    Val Acc: 35.42 %\n",
      "Max Val Acc: 37.5 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.663\n",
      "  Train Acc: 38.76 %\n",
      "    Val Acc: 36.16 %\n",
      "Max Val Acc: 40.77 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.619\n",
      "  Train Acc: 39.4 %\n",
      "    Val Acc: 36.61 %\n",
      "Max Val Acc: 41.37 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.555\n",
      "  Train Acc: 45.13 %\n",
      "    Val Acc: 42.41 %\n",
      "Max Val Acc: 43.75 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.479\n",
      "  Train Acc: 46.58 %\n",
      "    Val Acc: 45.68 %\n",
      "Max Val Acc: 46.88 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.44\n",
      "  Train Acc: 50.04 %\n",
      "    Val Acc: 46.43 %\n",
      "Max Val Acc: 47.02 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.411\n",
      "  Train Acc: 48.96 %\n",
      "    Val Acc: 44.94 %\n",
      "Max Val Acc: 48.81 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.371\n",
      "  Train Acc: 51.71 %\n",
      "    Val Acc: 46.73 %\n",
      "Max Val Acc: 50.74 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.355\n",
      "  Train Acc: 52.98 %\n",
      "    Val Acc: 50.45 %\n",
      "Max Val Acc: 51.19 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.319\n",
      "  Train Acc: 54.39 %\n",
      "    Val Acc: 50.74 %\n",
      "Max Val Acc: 51.49 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.281\n",
      "  Train Acc: 54.24 %\n",
      "    Val Acc: 51.49 %\n",
      "Max Val Acc: 52.38 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 52.38095238095238 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.079\n",
      "  Train Acc: 13.88 %\n",
      "    Val Acc: 12.5 %\n",
      "Max Val Acc: 15.33 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.069\n",
      "  Train Acc: 17.89 %\n",
      "    Val Acc: 17.26 %\n",
      "Max Val Acc: 19.64 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.059\n",
      "  Train Acc: 22.69 %\n",
      "    Val Acc: 21.58 %\n",
      "Max Val Acc: 21.73 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.037\n",
      "  Train Acc: 24.37 %\n",
      "    Val Acc: 22.77 %\n",
      "Max Val Acc: 22.77 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 1.983\n",
      "  Train Acc: 28.35 %\n",
      "    Val Acc: 26.04 %\n",
      "Max Val Acc: 26.04 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.876\n",
      "  Train Acc: 32.03 %\n",
      "    Val Acc: 29.61 %\n",
      "Max Val Acc: 30.21 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.808\n",
      "  Train Acc: 33.44 %\n",
      "    Val Acc: 31.1 %\n",
      "Max Val Acc: 32.29 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.755\n",
      "  Train Acc: 32.66 %\n",
      "    Val Acc: 29.17 %\n",
      "Max Val Acc: 32.29 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.715\n",
      "  Train Acc: 34.26 %\n",
      "    Val Acc: 31.1 %\n",
      "Max Val Acc: 32.74 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 1.657\n",
      "  Train Acc: 36.87 %\n",
      "    Val Acc: 34.08 %\n",
      "Max Val Acc: 34.08 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.629\n",
      "  Train Acc: 36.46 %\n",
      "    Val Acc: 33.33 %\n",
      "Max Val Acc: 36.01 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.583\n",
      "  Train Acc: 42.6 %\n",
      "    Val Acc: 38.84 %\n",
      "Max Val Acc: 38.84 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.528\n",
      "  Train Acc: 45.28 %\n",
      "    Val Acc: 40.33 %\n",
      "Max Val Acc: 41.82 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.473\n",
      "  Train Acc: 47.58 %\n",
      "    Val Acc: 43.6 %\n",
      "Max Val Acc: 45.09 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.404\n",
      "  Train Acc: 47.95 %\n",
      "    Val Acc: 43.75 %\n",
      "Max Val Acc: 47.02 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.368\n",
      "  Train Acc: 53.27 %\n",
      "    Val Acc: 47.47 %\n",
      "Max Val Acc: 48.07 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.31\n",
      "  Train Acc: 53.46 %\n",
      "    Val Acc: 48.51 %\n",
      "Max Val Acc: 49.4 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.276\n",
      "  Train Acc: 54.32 %\n",
      "    Val Acc: 48.07 %\n",
      "Max Val Acc: 49.7 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.278\n",
      "  Train Acc: 56.21 %\n",
      "    Val Acc: 49.7 %\n",
      "Max Val Acc: 50.0 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.247\n",
      "  Train Acc: 54.46 %\n",
      "    Val Acc: 47.02 %\n",
      "Max Val Acc: 51.93 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 51.93452380952381 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.079\n",
      "  Train Acc: 20.83 %\n",
      "    Val Acc: 18.15 %\n",
      "Max Val Acc: 18.9 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.071\n",
      "  Train Acc: 20.39 %\n",
      "    Val Acc: 19.94 %\n",
      "Max Val Acc: 21.43 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.063\n",
      "  Train Acc: 23.4 %\n",
      "    Val Acc: 23.07 %\n",
      "Max Val Acc: 26.79 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.045\n",
      "  Train Acc: 30.84 %\n",
      "    Val Acc: 28.12 %\n",
      "Max Val Acc: 29.17 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.002\n",
      "  Train Acc: 30.06 %\n",
      "    Val Acc: 28.57 %\n",
      "Max Val Acc: 30.65 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.898\n",
      "  Train Acc: 28.35 %\n",
      "    Val Acc: 25.89 %\n",
      "Max Val Acc: 30.65 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.815\n",
      "  Train Acc: 32.25 %\n",
      "    Val Acc: 27.98 %\n",
      "Max Val Acc: 30.65 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.765\n",
      "  Train Acc: 33.15 %\n",
      "    Val Acc: 30.51 %\n",
      "Max Val Acc: 30.65 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.72\n",
      "  Train Acc: 34.3 %\n",
      "    Val Acc: 32.74 %\n",
      "Max Val Acc: 32.74 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 1.675\n",
      "  Train Acc: 35.16 %\n",
      "    Val Acc: 31.7 %\n",
      "Max Val Acc: 33.04 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.628\n",
      "  Train Acc: 36.53 %\n",
      "    Val Acc: 32.44 %\n",
      "Max Val Acc: 34.82 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.591\n",
      "  Train Acc: 38.58 %\n",
      "    Val Acc: 34.97 %\n",
      "Max Val Acc: 38.1 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.547\n",
      "  Train Acc: 42.3 %\n",
      "    Val Acc: 38.99 %\n",
      "Max Val Acc: 39.43 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.478\n",
      "  Train Acc: 46.13 %\n",
      "    Val Acc: 41.52 %\n",
      "Max Val Acc: 44.05 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.451\n",
      "  Train Acc: 46.5 %\n",
      "    Val Acc: 42.86 %\n",
      "Max Val Acc: 45.09 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.452\n",
      "  Train Acc: 50.56 %\n",
      "    Val Acc: 45.98 %\n",
      "Max Val Acc: 45.98 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.37\n",
      "  Train Acc: 52.34 %\n",
      "    Val Acc: 46.13 %\n",
      "Max Val Acc: 47.32 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.357\n",
      "  Train Acc: 52.34 %\n",
      "    Val Acc: 47.47 %\n",
      "Max Val Acc: 49.11 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.33\n",
      "  Train Acc: 53.5 %\n",
      "    Val Acc: 47.77 %\n",
      "Max Val Acc: 50.3 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.285\n",
      "  Train Acc: 52.23 %\n",
      "    Val Acc: 46.58 %\n",
      "Max Val Acc: 50.6 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 50.595238095238095 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.077\n",
      "  Train Acc: 15.92 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 22.38 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.07\n",
      "  Train Acc: 21.22 %\n",
      "    Val Acc: 20.12 %\n",
      "Max Val Acc: 22.38 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.058\n",
      "  Train Acc: 22.53 %\n",
      "    Val Acc: 22.5 %\n",
      "Max Val Acc: 23.81 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.025\n",
      "  Train Acc: 30.33 %\n",
      "    Val Acc: 30.24 %\n",
      "Max Val Acc: 31.19 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 1.926\n",
      "  Train Acc: 28.21 %\n",
      "    Val Acc: 28.93 %\n",
      "Max Val Acc: 31.43 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.813\n",
      "  Train Acc: 34.23 %\n",
      "    Val Acc: 35.24 %\n",
      "Max Val Acc: 35.24 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.75\n",
      "  Train Acc: 36.85 %\n",
      "    Val Acc: 35.95 %\n",
      "Max Val Acc: 36.31 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.683\n",
      "  Train Acc: 33.63 %\n",
      "    Val Acc: 30.83 %\n",
      "Max Val Acc: 37.02 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.633\n",
      "  Train Acc: 40.6 %\n",
      "    Val Acc: 37.38 %\n",
      "Max Val Acc: 39.76 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 1.577\n",
      "  Train Acc: 44.82 %\n",
      "    Val Acc: 40.6 %\n",
      "Max Val Acc: 43.1 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.505\n",
      "  Train Acc: 48.9 %\n",
      "    Val Acc: 43.45 %\n",
      "Max Val Acc: 44.88 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.44\n",
      "  Train Acc: 49.46 %\n",
      "    Val Acc: 47.26 %\n",
      "Max Val Acc: 47.26 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.389\n",
      "  Train Acc: 52.08 %\n",
      "    Val Acc: 46.79 %\n",
      "Max Val Acc: 48.33 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.354\n",
      "  Train Acc: 52.83 %\n",
      "    Val Acc: 45.0 %\n",
      "Max Val Acc: 49.88 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.305\n",
      "  Train Acc: 54.7 %\n",
      "    Val Acc: 47.86 %\n",
      "Max Val Acc: 49.88 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.267\n",
      "  Train Acc: 57.17 %\n",
      "    Val Acc: 50.12 %\n",
      "Max Val Acc: 50.83 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.247\n",
      "  Train Acc: 55.95 %\n",
      "    Val Acc: 51.79 %\n",
      "Max Val Acc: 52.26 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.21\n",
      "  Train Acc: 56.25 %\n",
      "    Val Acc: 49.29 %\n",
      "Max Val Acc: 52.38 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.185\n",
      "  Train Acc: 58.96 %\n",
      "    Val Acc: 52.98 %\n",
      "Max Val Acc: 52.98 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.186\n",
      "  Train Acc: 59.35 %\n",
      "    Val Acc: 50.24 %\n",
      "Max Val Acc: 52.98 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 52.976190476190474 %\n",
      "--- FINISHED TRAINING NETWORK ---\n"
     ]
    }
   ],
   "source": [
    "y_pred_NN2 = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    \n",
    "    inputs_train_d = inputs_train.drop(inputs_train.index[i-840:i])\n",
    "    targets_train_d = targets_train.drop(targets_train.index[i-840:i])\n",
    "    inputs_train_td = inputs_train[i-840:i]\n",
    "    \n",
    "    inputs_train_nn = inputs_train_d.reset_index(drop=True)\n",
    "    inputs_test_nn = inputs_train_td.reset_index(drop=True)\n",
    "    targets_train_nn=targets_train_d.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    NN_prob2 = nn_train_to_prob_mat(inputs_train_nn,\n",
    "                                    targets_train_nn, \n",
    "                                    inputs_test_nn, class_labels=classes, epoch_num=20, verbose=True)\n",
    "    y_pred_NN2 = np.append(y_pred_NN2, NN_prob2, axis = 0)\n",
    "\n",
    "dfNN2_train = pd.DataFrame(y_pred_NN2, columns = ['NN2_El', 'NN2_Exp', 'NN2_Flk', 'NN2_HH', \n",
    "                                           'NN2_Inst', 'NN2_Intr', 'NN2_Pop', 'NN2_Rck'])\n",
    "\n",
    "inputs_train_nnf = inputs_train.reset_index(drop=True)\n",
    "targets_train_nnf = targets_train.reset_index(drop=True)\n",
    "inputs_test_nnf = inputs_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "y_pred_test_NN2 = nn_train_to_prob_mat(inputs_train_nnf,\n",
    "                                    targets_train_nnf, inputs_test_nnf, class_labels=classes, epoch_num=20, verbose=True)\n",
    "\n",
    "dfNN2_test = pd.DataFrame(y_pred_test_NN2, columns = ['NN2_El', 'NN2_Exp', 'NN2_Flk', 'NN2_HH', \n",
    "                                           'NN2_Inst', 'NN2_Intr', 'NN2_Pop', 'NN2_Rck'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wide network\n",
    "class Net3(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "        self.fc1 = nn.Linear(len(X_train.columns), 60)\n",
    "        self.fc2 = nn.Linear(60, 2000)\n",
    "        self.fc3 = nn.Linear(2000, 600)\n",
    "        self.fc4 = nn.Linear(600, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.celu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_train_to_prob_mat(X_train, y_train, X_test, epoch_num = 20, class_labels=classes, verbose=False):\n",
    "    \n",
    "    y_train = y_train.replace(classes,range(0,len(class_labels)))\n",
    "    \n",
    "    # normalize data\n",
    "    std_scale = StandardScaler()\n",
    "    X_train = std_scale.fit_transform(X_train)\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = std_scale.transform(X_test)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    \n",
    "    # make dataset\n",
    "    dataset = AudioDataset(X_train,y_train)\n",
    "    \n",
    "    # split into train and validation set for nn training\n",
    "    num_train = int(len(X_train)*.8)\n",
    "    num_val = len(X_train)-num_train\n",
    "    batch_size = 100\n",
    "    num_batches = num_train//batch_size\n",
    "    train, val = random_split(dataset, [num_train,num_val])\n",
    "    \n",
    "    # make dataloaders\n",
    "    train_dl = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val, batch_size=num_val, shuffle=False)\n",
    "    #test_dl = DataLoader(val, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # make folder to save network params if does not exist\n",
    "    if not os.path.exists('./NN_CV_params'):\n",
    "        os.makedirs('./NN_CV_params')\n",
    "    \n",
    "    # train the network\n",
    "    if verbose:\n",
    "        print(\"--- BEGIN TRAINING NETWORK ---\")\n",
    "    net = Net3()\n",
    "    nn_train(net, train_dl, val_dl, './NN_CV_params/network_params.pth',epoch_num=epoch_num,\n",
    "             num_batches=num_batches,verbose=verbose)\n",
    "    if verbose:\n",
    "        print(\"--- FINISHED TRAINING NETWORK ---\")\n",
    "    \n",
    "    # generate probability matrix for test data\n",
    "    prob_matrix = []\n",
    "    with torch.no_grad():\n",
    "        for index in range(len(X_test)):\n",
    "            data = torch.tensor(X_test.loc[index].values, dtype=torch.float)\n",
    "            net.load_state_dict(torch.load('./NN_CV_params/network_params.pth'))\n",
    "            outputs = torch.softmax(net(data).unsqueeze(1).T, dim=1)\n",
    "            prob_dist = outputs.tolist()[0]\n",
    "            prob_matrix.append(prob_dist)\n",
    "            \n",
    "    return np.array(prob_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.108\n",
      "  Train Acc: 13.28 %\n",
      "    Val Acc: 12.95 %\n",
      "Max Val Acc: 14.43 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.113\n",
      "  Train Acc: 12.76 %\n",
      "    Val Acc: 12.95 %\n",
      "Max Val Acc: 17.11 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.1\n",
      "  Train Acc: 11.87 %\n",
      "    Val Acc: 11.61 %\n",
      "Max Val Acc: 17.11 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.061\n",
      "  Train Acc: 19.31 %\n",
      "    Val Acc: 17.56 %\n",
      "Max Val Acc: 22.77 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.031\n",
      "  Train Acc: 21.09 %\n",
      "    Val Acc: 18.75 %\n",
      "Max Val Acc: 26.64 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.94\n",
      "  Train Acc: 28.31 %\n",
      "    Val Acc: 24.55 %\n",
      "Max Val Acc: 29.02 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.849\n",
      "  Train Acc: 26.93 %\n",
      "    Val Acc: 23.81 %\n",
      "Max Val Acc: 31.4 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.794\n",
      "  Train Acc: 25.37 %\n",
      "    Val Acc: 26.19 %\n",
      "Max Val Acc: 33.04 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.77\n",
      "  Train Acc: 32.18 %\n",
      "    Val Acc: 30.21 %\n",
      "Max Val Acc: 35.71 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 1.706\n",
      "  Train Acc: 33.18 %\n",
      "    Val Acc: 31.55 %\n",
      "Max Val Acc: 35.71 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.682\n",
      "  Train Acc: 34.6 %\n",
      "    Val Acc: 33.93 %\n",
      "Max Val Acc: 39.29 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.642\n",
      "  Train Acc: 38.43 %\n",
      "    Val Acc: 38.1 %\n",
      "Max Val Acc: 40.92 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.599\n",
      "  Train Acc: 34.38 %\n",
      "    Val Acc: 33.33 %\n",
      "Max Val Acc: 40.92 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.569\n",
      "  Train Acc: 44.87 %\n",
      "    Val Acc: 40.92 %\n",
      "Max Val Acc: 42.41 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.541\n",
      "  Train Acc: 43.82 %\n",
      "    Val Acc: 38.84 %\n",
      "Max Val Acc: 44.2 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.483\n",
      "  Train Acc: 47.1 %\n",
      "    Val Acc: 45.39 %\n",
      "Max Val Acc: 45.54 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.46\n",
      "  Train Acc: 48.77 %\n",
      "    Val Acc: 45.83 %\n",
      "Max Val Acc: 45.83 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.408\n",
      "  Train Acc: 49.07 %\n",
      "    Val Acc: 45.39 %\n",
      "Max Val Acc: 47.47 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.375\n",
      "  Train Acc: 52.75 %\n",
      "    Val Acc: 47.62 %\n",
      "Max Val Acc: 47.62 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.336\n",
      "  Train Acc: 53.42 %\n",
      "    Val Acc: 47.32 %\n",
      "Max Val Acc: 50.15 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 50.148809523809526 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.09\n",
      "  Train Acc: 12.65 %\n",
      "    Val Acc: 11.01 %\n",
      "Max Val Acc: 17.86 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.096\n",
      "  Train Acc: 13.32 %\n",
      "    Val Acc: 12.2 %\n",
      "Max Val Acc: 17.86 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.068\n",
      "  Train Acc: 25.56 %\n",
      "    Val Acc: 25.15 %\n",
      "Max Val Acc: 25.15 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.061\n",
      "  Train Acc: 13.24 %\n",
      "    Val Acc: 10.86 %\n",
      "Max Val Acc: 30.21 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.022\n",
      "  Train Acc: 18.68 %\n",
      "    Val Acc: 17.86 %\n",
      "Max Val Acc: 30.21 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.936\n",
      "  Train Acc: 21.8 %\n",
      "    Val Acc: 25.74 %\n",
      "Max Val Acc: 30.21 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.865\n",
      "  Train Acc: 30.54 %\n",
      "    Val Acc: 29.32 %\n",
      "Max Val Acc: 31.55 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.801\n",
      "  Train Acc: 31.73 %\n",
      "    Val Acc: 32.44 %\n",
      "Max Val Acc: 32.44 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.775\n",
      "  Train Acc: 35.71 %\n",
      "    Val Acc: 34.38 %\n",
      "Max Val Acc: 34.38 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 1.728\n",
      "  Train Acc: 31.47 %\n",
      "    Val Acc: 29.91 %\n",
      "Max Val Acc: 34.52 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.694\n",
      "  Train Acc: 32.63 %\n",
      "    Val Acc: 32.29 %\n",
      "Max Val Acc: 36.46 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.664\n",
      "  Train Acc: 36.46 %\n",
      "    Val Acc: 33.93 %\n",
      "Max Val Acc: 37.8 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.633\n",
      "  Train Acc: 39.1 %\n",
      "    Val Acc: 36.46 %\n",
      "Max Val Acc: 38.84 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.584\n",
      "  Train Acc: 43.75 %\n",
      "    Val Acc: 41.07 %\n",
      "Max Val Acc: 41.52 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.548\n",
      "  Train Acc: 40.77 %\n",
      "    Val Acc: 38.69 %\n",
      "Max Val Acc: 44.49 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.494\n",
      "  Train Acc: 46.09 %\n",
      "    Val Acc: 43.75 %\n",
      "Max Val Acc: 45.83 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.454\n",
      "  Train Acc: 47.32 %\n",
      "    Val Acc: 42.26 %\n",
      "Max Val Acc: 47.92 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.427\n",
      "  Train Acc: 48.96 %\n",
      "    Val Acc: 47.47 %\n",
      "Max Val Acc: 47.92 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.386\n",
      "  Train Acc: 51.45 %\n",
      "    Val Acc: 48.51 %\n",
      "Max Val Acc: 49.7 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.347\n",
      "  Train Acc: 53.24 %\n",
      "    Val Acc: 48.51 %\n",
      "Max Val Acc: 50.3 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 50.29761904761905 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.109\n",
      "  Train Acc: 12.61 %\n",
      "    Val Acc: 14.14 %\n",
      "Max Val Acc: 15.33 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.103\n",
      "  Train Acc: 12.54 %\n",
      "    Val Acc: 14.29 %\n",
      "Max Val Acc: 21.58 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.082\n",
      "  Train Acc: 17.49 %\n",
      "    Val Acc: 18.9 %\n",
      "Max Val Acc: 24.11 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.066\n",
      "  Train Acc: 22.1 %\n",
      "    Val Acc: 18.9 %\n",
      "Max Val Acc: 29.17 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.01\n",
      "  Train Acc: 21.73 %\n",
      "    Val Acc: 21.43 %\n",
      "Max Val Acc: 29.17 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.924\n",
      "  Train Acc: 28.16 %\n",
      "    Val Acc: 27.08 %\n",
      "Max Val Acc: 29.46 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.854\n",
      "  Train Acc: 26.0 %\n",
      "    Val Acc: 25.3 %\n",
      "Max Val Acc: 33.18 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.828\n",
      "  Train Acc: 27.01 %\n",
      "    Val Acc: 26.34 %\n",
      "Max Val Acc: 33.78 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.798\n",
      "  Train Acc: 28.24 %\n",
      "    Val Acc: 27.38 %\n",
      "Max Val Acc: 37.05 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 1.757\n",
      "  Train Acc: 30.8 %\n",
      "    Val Acc: 31.4 %\n",
      "Max Val Acc: 37.05 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.723\n",
      "  Train Acc: 35.42 %\n",
      "    Val Acc: 34.38 %\n",
      "Max Val Acc: 37.05 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.7\n",
      "  Train Acc: 31.96 %\n",
      "    Val Acc: 34.23 %\n",
      "Max Val Acc: 37.05 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.655\n",
      "  Train Acc: 38.39 %\n",
      "    Val Acc: 39.73 %\n",
      "Max Val Acc: 40.33 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.624\n",
      "  Train Acc: 40.92 %\n",
      "    Val Acc: 40.48 %\n",
      "Max Val Acc: 41.37 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.576\n",
      "  Train Acc: 38.17 %\n",
      "    Val Acc: 37.95 %\n",
      "Max Val Acc: 43.6 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.505\n",
      "  Train Acc: 47.25 %\n",
      "    Val Acc: 44.64 %\n",
      "Max Val Acc: 45.09 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.462\n",
      "  Train Acc: 48.77 %\n",
      "    Val Acc: 46.28 %\n",
      "Max Val Acc: 46.73 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.419\n",
      "  Train Acc: 50.04 %\n",
      "    Val Acc: 46.43 %\n",
      "Max Val Acc: 48.36 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.395\n",
      "  Train Acc: 50.86 %\n",
      "    Val Acc: 46.28 %\n",
      "Max Val Acc: 50.15 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.344\n",
      "  Train Acc: 53.46 %\n",
      "    Val Acc: 48.96 %\n",
      "Max Val Acc: 50.15 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 50.148809523809526 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.101\n",
      "  Train Acc: 11.9 %\n",
      "    Val Acc: 11.01 %\n",
      "Max Val Acc: 13.84 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.105\n",
      "  Train Acc: 12.91 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 14.73 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.105\n",
      "  Train Acc: 12.95 %\n",
      "    Val Acc: 12.65 %\n",
      "Max Val Acc: 21.43 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.076\n",
      "  Train Acc: 28.91 %\n",
      "    Val Acc: 26.79 %\n",
      "Max Val Acc: 26.79 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.045\n",
      "  Train Acc: 23.25 %\n",
      "    Val Acc: 21.13 %\n",
      "Max Val Acc: 26.79 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.95\n",
      "  Train Acc: 25.26 %\n",
      "    Val Acc: 26.04 %\n",
      "Max Val Acc: 29.46 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.856\n",
      "  Train Acc: 23.44 %\n",
      "    Val Acc: 22.32 %\n",
      "Max Val Acc: 29.46 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.821\n",
      "  Train Acc: 27.64 %\n",
      "    Val Acc: 27.38 %\n",
      "Max Val Acc: 33.18 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.759\n",
      "  Train Acc: 32.66 %\n",
      "    Val Acc: 33.18 %\n",
      "Max Val Acc: 33.63 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 1.717\n",
      "  Train Acc: 32.03 %\n",
      "    Val Acc: 33.78 %\n",
      "Max Val Acc: 35.71 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.691\n",
      "  Train Acc: 34.52 %\n",
      "    Val Acc: 30.65 %\n",
      "Max Val Acc: 36.46 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.651\n",
      "  Train Acc: 36.24 %\n",
      "    Val Acc: 36.01 %\n",
      "Max Val Acc: 39.14 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.621\n",
      "  Train Acc: 41.0 %\n",
      "    Val Acc: 40.33 %\n",
      "Max Val Acc: 40.33 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.568\n",
      "  Train Acc: 37.57 %\n",
      "    Val Acc: 38.84 %\n",
      "Max Val Acc: 41.96 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.562\n",
      "  Train Acc: 45.42 %\n",
      "    Val Acc: 41.22 %\n",
      "Max Val Acc: 42.56 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.496\n",
      "  Train Acc: 47.28 %\n",
      "    Val Acc: 41.82 %\n",
      "Max Val Acc: 44.2 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.447\n",
      "  Train Acc: 48.77 %\n",
      "    Val Acc: 44.49 %\n",
      "Max Val Acc: 45.83 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.402\n",
      "  Train Acc: 49.96 %\n",
      "    Val Acc: 44.35 %\n",
      "Max Val Acc: 47.02 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.359\n",
      "  Train Acc: 52.34 %\n",
      "    Val Acc: 47.02 %\n",
      "Max Val Acc: 47.17 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.331\n",
      "  Train Acc: 54.35 %\n",
      "    Val Acc: 48.66 %\n",
      "Max Val Acc: 49.26 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 49.25595238095238 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.113\n",
      "  Train Acc: 13.1 %\n",
      "    Val Acc: 13.54 %\n",
      "Max Val Acc: 13.69 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.099\n",
      "  Train Acc: 14.4 %\n",
      "    Val Acc: 12.2 %\n",
      "Max Val Acc: 17.26 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.102\n",
      "  Train Acc: 18.97 %\n",
      "    Val Acc: 19.35 %\n",
      "Max Val Acc: 21.88 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.084\n",
      "  Train Acc: 17.45 %\n",
      "    Val Acc: 15.92 %\n",
      "Max Val Acc: 23.07 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.023\n",
      "  Train Acc: 23.55 %\n",
      "    Val Acc: 22.17 %\n",
      "Max Val Acc: 26.79 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.943\n",
      "  Train Acc: 21.95 %\n",
      "    Val Acc: 23.21 %\n",
      "Max Val Acc: 30.21 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.87\n",
      "  Train Acc: 28.12 %\n",
      "    Val Acc: 27.98 %\n",
      "Max Val Acc: 30.21 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.818\n",
      "  Train Acc: 31.77 %\n",
      "    Val Acc: 32.44 %\n",
      "Max Val Acc: 33.04 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.771\n",
      "  Train Acc: 30.65 %\n",
      "    Val Acc: 27.98 %\n",
      "Max Val Acc: 33.04 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 1.729\n",
      "  Train Acc: 31.58 %\n",
      "    Val Acc: 28.72 %\n",
      "Max Val Acc: 35.57 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.704\n",
      "  Train Acc: 33.59 %\n",
      "    Val Acc: 29.91 %\n",
      "Max Val Acc: 35.57 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.672\n",
      "  Train Acc: 34.78 %\n",
      "    Val Acc: 31.99 %\n",
      "Max Val Acc: 35.57 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.619\n",
      "  Train Acc: 38.28 %\n",
      "    Val Acc: 34.82 %\n",
      "Max Val Acc: 36.76 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.576\n",
      "  Train Acc: 42.04 %\n",
      "    Val Acc: 38.84 %\n",
      "Max Val Acc: 40.33 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.539\n",
      "  Train Acc: 44.72 %\n",
      "    Val Acc: 42.56 %\n",
      "Max Val Acc: 42.56 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.484\n",
      "  Train Acc: 47.92 %\n",
      "    Val Acc: 42.41 %\n",
      "Max Val Acc: 42.71 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.45\n",
      "  Train Acc: 47.25 %\n",
      "    Val Acc: 44.35 %\n",
      "Max Val Acc: 44.35 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.411\n",
      "  Train Acc: 50.26 %\n",
      "    Val Acc: 45.98 %\n",
      "Max Val Acc: 46.58 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.381\n",
      "  Train Acc: 51.93 %\n",
      "    Val Acc: 47.77 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.346\n",
      "  Train Acc: 52.83 %\n",
      "    Val Acc: 48.81 %\n",
      "Max Val Acc: 49.11 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 49.107142857142854 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.107\n",
      "  Train Acc: 12.77 %\n",
      "    Val Acc: 12.62 %\n",
      "Max Val Acc: 15.24 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.1\n",
      "  Train Acc: 15.86 %\n",
      "    Val Acc: 16.07 %\n",
      "Max Val Acc: 21.55 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.091\n",
      "  Train Acc: 21.16 %\n",
      "    Val Acc: 23.33 %\n",
      "Max Val Acc: 24.76 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.016\n",
      "  Train Acc: 21.9 %\n",
      "    Val Acc: 22.86 %\n",
      "Max Val Acc: 32.02 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 1.933\n",
      "  Train Acc: 21.58 %\n",
      "    Val Acc: 21.43 %\n",
      "Max Val Acc: 32.02 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 1.854\n",
      "  Train Acc: 26.67 %\n",
      "    Val Acc: 29.88 %\n",
      "Max Val Acc: 32.02 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 1.804\n",
      "  Train Acc: 28.42 %\n",
      "    Val Acc: 28.57 %\n",
      "Max Val Acc: 33.21 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 1.778\n",
      "  Train Acc: 31.99 %\n",
      "    Val Acc: 32.74 %\n",
      "Max Val Acc: 35.36 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 1.717\n",
      "  Train Acc: 33.18 %\n",
      "    Val Acc: 33.33 %\n",
      "Max Val Acc: 36.67 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 1.686\n",
      "  Train Acc: 38.84 %\n",
      "    Val Acc: 38.93 %\n",
      "Max Val Acc: 39.88 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.627\n",
      "  Train Acc: 38.12 %\n",
      "    Val Acc: 38.21 %\n",
      "Max Val Acc: 41.19 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.574\n",
      "  Train Acc: 41.4 %\n",
      "    Val Acc: 42.38 %\n",
      "Max Val Acc: 43.69 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.521\n",
      "  Train Acc: 44.64 %\n",
      "    Val Acc: 44.64 %\n",
      "Max Val Acc: 45.6 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.469\n",
      "  Train Acc: 49.73 %\n",
      "    Val Acc: 47.86 %\n",
      "Max Val Acc: 47.86 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.419\n",
      "  Train Acc: 50.27 %\n",
      "    Val Acc: 48.93 %\n",
      "Max Val Acc: 48.93 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.367\n",
      "  Train Acc: 52.05 %\n",
      "    Val Acc: 49.29 %\n",
      "Max Val Acc: 49.29 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.328\n",
      "  Train Acc: 53.45 %\n",
      "    Val Acc: 49.4 %\n",
      "Max Val Acc: 49.88 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.305\n",
      "  Train Acc: 54.91 %\n",
      "    Val Acc: 49.88 %\n",
      "Max Val Acc: 51.31 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.269\n",
      "  Train Acc: 56.76 %\n",
      "    Val Acc: 50.71 %\n",
      "Max Val Acc: 52.14 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.252\n",
      "  Train Acc: 56.16 %\n",
      "    Val Acc: 50.24 %\n",
      "Max Val Acc: 52.14 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 52.142857142857146 %\n",
      "--- FINISHED TRAINING NETWORK ---\n"
     ]
    }
   ],
   "source": [
    "y_pred_NN3 = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    \n",
    "    inputs_train_d = inputs_train.drop(inputs_train.index[i-840:i])\n",
    "    targets_train_d = targets_train.drop(targets_train.index[i-840:i])\n",
    "    inputs_train_td = inputs_train[i-840:i]\n",
    "    \n",
    "    inputs_train_nn = inputs_train_d.reset_index(drop=True)\n",
    "    inputs_test_nn = inputs_train_td.reset_index(drop=True)\n",
    "    targets_train_nn=targets_train_d.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    NN_prob3 = nn_train_to_prob_mat(inputs_train_nn,\n",
    "                                    targets_train_nn, \n",
    "                                    inputs_test_nn, class_labels=classes, epoch_num=20, verbose=True)\n",
    "    y_pred_NN3 = np.append(y_pred_NN3, NN_prob3, axis = 0)\n",
    "\n",
    "dfNN3_train = pd.DataFrame(y_pred_NN3, columns = ['NN3_El', 'NN3_Exp', 'NN3_Flk', 'NN3_HH', \n",
    "                                           'NN3_Inst', 'NN3_Intr', 'NN3_Pop', 'NN3_Rck'])\n",
    "\n",
    "inputs_train_nnf = inputs_train.reset_index(drop=True)\n",
    "targets_train_nnf = targets_train.reset_index(drop=True)\n",
    "inputs_test_nnf = inputs_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "y_pred_test_NN3 = nn_train_to_prob_mat(inputs_train_nnf,\n",
    "                                    targets_train_nnf, inputs_test_nnf, class_labels=classes, epoch_num=20, verbose=True)\n",
    "\n",
    "dfNN3_test = pd.DataFrame(y_pred_test_NN3, columns = ['NN3_El', 'NN3_Exp', 'NN3_Flk', 'NN3_HH', \n",
    "                                           'NN3_Inst', 'NN3_Intr', 'NN3_Pop', 'NN3_Rck'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep network\n",
    "# epoch num = 40\n",
    "class Net4(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net4, self).__init__()\n",
    "        self.fc1 = nn.Linear(len(X_train.columns), 800)\n",
    "        self.fc2 = nn.Linear(800, 100)\n",
    "        self.fc3 = nn.Linear(100, 500)\n",
    "        self.fc4 = nn.Linear(500, 100)\n",
    "        self.fc5 = nn.Linear(100, 500)\n",
    "        self.fc6 = nn.Linear(500, 100)\n",
    "        self.fc7 = nn.Linear(100, 500)\n",
    "        self.fc8 = nn.Linear(500, 100)\n",
    "        self.fc9 = nn.Linear(100, 500)\n",
    "        self.fc10 = nn.Linear(500, 100)\n",
    "        self.fc11 = nn.Linear(100, 8)\n",
    "        self.fc12 = nn.Linear(8, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.celu(self.fc1(x))\n",
    "        x = torch.celu(self.fc2(x),alpha=2)\n",
    "        x = torch.celu(self.fc3(x),alpha=3)\n",
    "        x = torch.celu(self.fc4(x),alpha=2)\n",
    "        x = torch.celu(self.fc5(x))\n",
    "        x = torch.celu(self.fc6(x),alpha=.5)\n",
    "        x = torch.celu(self.fc7(x),alpha=.25)\n",
    "        x = torch.celu(self.fc8(x),alpha=.5)\n",
    "        x = torch.celu(self.fc9(x))\n",
    "        x = torch.celu(self.fc10(x))\n",
    "        x = torch.celu(self.fc11(x))\n",
    "        x = self.fc12(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_train_to_prob_mat(X_train, y_train, X_test, epoch_num = 40, class_labels=classes, verbose=False):\n",
    "    \n",
    "    y_train = y_train.replace(classes,range(0,len(class_labels)))\n",
    "    \n",
    "    # normalize data\n",
    "    std_scale = StandardScaler()\n",
    "    X_train = std_scale.fit_transform(X_train)\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = std_scale.transform(X_test)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    \n",
    "    # make dataset\n",
    "    dataset = AudioDataset(X_train,y_train)\n",
    "    \n",
    "    # split into train and validation set for nn training\n",
    "    num_train = int(len(X_train)*.8)\n",
    "    num_val = len(X_train)-num_train\n",
    "    batch_size = 100\n",
    "    num_batches = num_train//batch_size\n",
    "    train, val = random_split(dataset, [num_train,num_val])\n",
    "    \n",
    "    # make dataloaders\n",
    "    train_dl = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val, batch_size=num_val, shuffle=False)\n",
    "    #test_dl = DataLoader(val, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # make folder to save network params if does not exist\n",
    "    if not os.path.exists('./NN_CV_params'):\n",
    "        os.makedirs('./NN_CV_params')\n",
    "    \n",
    "    # train the network\n",
    "    if verbose:\n",
    "        print(\"--- BEGIN TRAINING NETWORK ---\")\n",
    "    net = Net4()\n",
    "    nn_train(net, train_dl, val_dl, './NN_CV_params/network_params.pth',epoch_num=epoch_num,\n",
    "             num_batches=num_batches,verbose=verbose)\n",
    "    if verbose:\n",
    "        print(\"--- FINISHED TRAINING NETWORK ---\")\n",
    "    \n",
    "    # generate probability matrix for test data\n",
    "    prob_matrix = []\n",
    "    with torch.no_grad():\n",
    "        for index in range(len(X_test)):\n",
    "            data = torch.tensor(X_test.loc[index].values, dtype=torch.float)\n",
    "            net.load_state_dict(torch.load('./NN_CV_params/network_params.pth'))\n",
    "            outputs = torch.softmax(net(data).unsqueeze(1).T, dim=1)\n",
    "            prob_dist = outputs.tolist()[0]\n",
    "            prob_matrix.append(prob_dist)\n",
    "            \n",
    "    return np.array(prob_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.091\n",
      "  Train Acc: 13.17 %\n",
      "    Val Acc: 12.5 %\n",
      "Max Val Acc: 12.5 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.084\n",
      "  Train Acc: 13.17 %\n",
      "    Val Acc: 12.5 %\n",
      "Max Val Acc: 12.5 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.08\n",
      "  Train Acc: 13.28 %\n",
      "    Val Acc: 13.24 %\n",
      "Max Val Acc: 13.84 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.078\n",
      "  Train Acc: 13.17 %\n",
      "    Val Acc: 12.5 %\n",
      "Max Val Acc: 13.84 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.078\n",
      "  Train Acc: 12.98 %\n",
      "    Val Acc: 10.42 %\n",
      "Max Val Acc: 13.84 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 2.077\n",
      "  Train Acc: 13.13 %\n",
      "    Val Acc: 12.8 %\n",
      "Max Val Acc: 13.84 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 2.076\n",
      "  Train Acc: 17.26 %\n",
      "    Val Acc: 13.54 %\n",
      "Max Val Acc: 16.52 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 2.076\n",
      "  Train Acc: 17.22 %\n",
      "    Val Acc: 13.24 %\n",
      "Max Val Acc: 16.82 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 2.075\n",
      "  Train Acc: 16.63 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 16.82 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 2.072\n",
      "  Train Acc: 21.47 %\n",
      "    Val Acc: 19.79 %\n",
      "Max Val Acc: 19.94 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 2.063\n",
      "  Train Acc: 22.36 %\n",
      "    Val Acc: 20.24 %\n",
      "Max Val Acc: 20.68 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 2.029\n",
      "  Train Acc: 22.51 %\n",
      "    Val Acc: 21.13 %\n",
      "Max Val Acc: 21.43 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.96\n",
      "  Train Acc: 23.07 %\n",
      "    Val Acc: 21.43 %\n",
      "Max Val Acc: 21.58 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.908\n",
      "  Train Acc: 23.96 %\n",
      "    Val Acc: 21.13 %\n",
      "Max Val Acc: 21.73 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.86\n",
      "  Train Acc: 25.48 %\n",
      "    Val Acc: 22.17 %\n",
      "Max Val Acc: 22.17 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.828\n",
      "  Train Acc: 27.75 %\n",
      "    Val Acc: 22.92 %\n",
      "Max Val Acc: 23.81 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.802\n",
      "  Train Acc: 28.57 %\n",
      "    Val Acc: 23.36 %\n",
      "Max Val Acc: 23.81 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.777\n",
      "  Train Acc: 26.93 %\n",
      "    Val Acc: 23.07 %\n",
      "Max Val Acc: 24.7 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.768\n",
      "  Train Acc: 29.61 %\n",
      "    Val Acc: 24.11 %\n",
      "Max Val Acc: 25.74 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.758\n",
      "  Train Acc: 28.76 %\n",
      "    Val Acc: 24.4 %\n",
      "Max Val Acc: 25.74 %\n",
      "------------\n",
      "[EPOCH # 21 ]\n",
      "       Loss: 1.735\n",
      "  Train Acc: 32.22 %\n",
      "    Val Acc: 24.7 %\n",
      "Max Val Acc: 26.34 %\n",
      "------------\n",
      "[EPOCH # 22 ]\n",
      "       Loss: 1.705\n",
      "  Train Acc: 33.41 %\n",
      "    Val Acc: 28.12 %\n",
      "Max Val Acc: 30.21 %\n",
      "------------\n",
      "[EPOCH # 23 ]\n",
      "       Loss: 1.668\n",
      "  Train Acc: 37.83 %\n",
      "    Val Acc: 33.93 %\n",
      "Max Val Acc: 33.93 %\n",
      "------------\n",
      "[EPOCH # 24 ]\n",
      "       Loss: 1.629\n",
      "  Train Acc: 39.36 %\n",
      "    Val Acc: 34.23 %\n",
      "Max Val Acc: 34.67 %\n",
      "------------\n",
      "[EPOCH # 25 ]\n",
      "       Loss: 1.588\n",
      "  Train Acc: 43.08 %\n",
      "    Val Acc: 39.43 %\n",
      "Max Val Acc: 39.88 %\n",
      "------------\n",
      "[EPOCH # 26 ]\n",
      "       Loss: 1.518\n",
      "  Train Acc: 44.72 %\n",
      "    Val Acc: 36.9 %\n",
      "Max Val Acc: 40.48 %\n",
      "------------\n",
      "[EPOCH # 27 ]\n",
      "       Loss: 1.459\n",
      "  Train Acc: 46.84 %\n",
      "    Val Acc: 40.18 %\n",
      "Max Val Acc: 40.77 %\n",
      "------------\n",
      "[EPOCH # 28 ]\n",
      "       Loss: 1.413\n",
      "  Train Acc: 47.58 %\n",
      "    Val Acc: 37.5 %\n",
      "Max Val Acc: 41.67 %\n",
      "------------\n",
      "[EPOCH # 29 ]\n",
      "       Loss: 1.362\n",
      "  Train Acc: 47.21 %\n",
      "    Val Acc: 38.84 %\n",
      "Max Val Acc: 41.67 %\n",
      "------------\n",
      "[EPOCH # 30 ]\n",
      "       Loss: 1.368\n",
      "  Train Acc: 47.21 %\n",
      "    Val Acc: 38.99 %\n",
      "Max Val Acc: 41.67 %\n",
      "------------\n",
      "[EPOCH # 31 ]\n",
      "       Loss: 1.355\n",
      "  Train Acc: 50.0 %\n",
      "    Val Acc: 39.29 %\n",
      "Max Val Acc: 42.86 %\n",
      "------------\n",
      "[EPOCH # 32 ]\n",
      "       Loss: 1.3\n",
      "  Train Acc: 50.15 %\n",
      "    Val Acc: 42.26 %\n",
      "Max Val Acc: 44.05 %\n",
      "------------\n",
      "[EPOCH # 33 ]\n",
      "       Loss: 1.255\n",
      "  Train Acc: 53.46 %\n",
      "    Val Acc: 41.67 %\n",
      "Max Val Acc: 44.49 %\n",
      "------------\n",
      "[EPOCH # 34 ]\n",
      "       Loss: 1.266\n",
      "  Train Acc: 53.2 %\n",
      "    Val Acc: 41.07 %\n",
      "Max Val Acc: 45.09 %\n",
      "------------\n",
      "[EPOCH # 35 ]\n",
      "       Loss: 1.19\n",
      "  Train Acc: 56.81 %\n",
      "    Val Acc: 43.45 %\n",
      "Max Val Acc: 45.09 %\n",
      "------------\n",
      "[EPOCH # 36 ]\n",
      "       Loss: 1.145\n",
      "  Train Acc: 59.49 %\n",
      "    Val Acc: 47.32 %\n",
      "Max Val Acc: 47.32 %\n",
      "------------\n",
      "[EPOCH # 37 ]\n",
      "       Loss: 1.112\n",
      "  Train Acc: 58.56 %\n",
      "    Val Acc: 47.02 %\n",
      "Max Val Acc: 47.92 %\n",
      "------------\n",
      "[EPOCH # 38 ]\n",
      "       Loss: 1.097\n",
      "  Train Acc: 62.05 %\n",
      "    Val Acc: 50.0 %\n",
      "Max Val Acc: 50.74 %\n",
      "------------\n",
      "[EPOCH # 39 ]\n",
      "       Loss: 1.047\n",
      "  Train Acc: 65.14 %\n",
      "    Val Acc: 47.02 %\n",
      "Max Val Acc: 50.74 %\n",
      "------------\n",
      "[EPOCH # 40 ]\n",
      "       Loss: 0.993\n",
      "  Train Acc: 66.67 %\n",
      "    Val Acc: 49.55 %\n",
      "Max Val Acc: 53.27 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 53.273809523809526 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.096\n",
      "  Train Acc: 13.47 %\n",
      "    Val Acc: 9.97 %\n",
      "Max Val Acc: 12.95 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.087\n",
      "  Train Acc: 13.47 %\n",
      "    Val Acc: 9.97 %\n",
      "Max Val Acc: 12.95 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.082\n",
      "  Train Acc: 13.47 %\n",
      "    Val Acc: 9.97 %\n",
      "Max Val Acc: 12.95 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.079\n",
      "  Train Acc: 13.47 %\n",
      "    Val Acc: 9.97 %\n",
      "Max Val Acc: 12.95 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.078\n",
      "  Train Acc: 13.47 %\n",
      "    Val Acc: 9.97 %\n",
      "Max Val Acc: 12.95 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 2.077\n",
      "  Train Acc: 13.47 %\n",
      "    Val Acc: 9.97 %\n",
      "Max Val Acc: 12.95 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 2.076\n",
      "  Train Acc: 13.47 %\n",
      "    Val Acc: 9.97 %\n",
      "Max Val Acc: 12.95 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 2.074\n",
      "  Train Acc: 13.69 %\n",
      "    Val Acc: 10.42 %\n",
      "Max Val Acc: 15.33 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 2.069\n",
      "  Train Acc: 22.66 %\n",
      "    Val Acc: 22.17 %\n",
      "Max Val Acc: 22.17 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 2.048\n",
      "  Train Acc: 23.33 %\n",
      "    Val Acc: 23.21 %\n",
      "Max Val Acc: 26.19 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.959\n",
      "  Train Acc: 22.36 %\n",
      "    Val Acc: 23.36 %\n",
      "Max Val Acc: 26.19 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.87\n",
      "  Train Acc: 24.11 %\n",
      "    Val Acc: 25.6 %\n",
      "Max Val Acc: 28.42 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.833\n",
      "  Train Acc: 26.82 %\n",
      "    Val Acc: 27.23 %\n",
      "Max Val Acc: 28.42 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.795\n",
      "  Train Acc: 28.72 %\n",
      "    Val Acc: 29.32 %\n",
      "Max Val Acc: 29.32 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.769\n",
      "  Train Acc: 30.54 %\n",
      "    Val Acc: 27.38 %\n",
      "Max Val Acc: 29.76 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.731\n",
      "  Train Acc: 32.63 %\n",
      "    Val Acc: 30.8 %\n",
      "Max Val Acc: 31.4 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.678\n",
      "  Train Acc: 35.45 %\n",
      "    Val Acc: 33.18 %\n",
      "Max Val Acc: 33.33 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.629\n",
      "  Train Acc: 39.1 %\n",
      "    Val Acc: 37.8 %\n",
      "Max Val Acc: 37.8 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.574\n",
      "  Train Acc: 42.08 %\n",
      "    Val Acc: 39.73 %\n",
      "Max Val Acc: 39.88 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.543\n",
      "  Train Acc: 42.63 %\n",
      "    Val Acc: 40.77 %\n",
      "Max Val Acc: 41.22 %\n",
      "------------\n",
      "[EPOCH # 21 ]\n",
      "       Loss: 1.492\n",
      "  Train Acc: 44.87 %\n",
      "    Val Acc: 39.29 %\n",
      "Max Val Acc: 41.22 %\n",
      "------------\n",
      "[EPOCH # 22 ]\n",
      "       Loss: 1.482\n",
      "  Train Acc: 44.31 %\n",
      "    Val Acc: 38.1 %\n",
      "Max Val Acc: 41.82 %\n",
      "------------\n",
      "[EPOCH # 23 ]\n",
      "       Loss: 1.454\n",
      "  Train Acc: 46.17 %\n",
      "    Val Acc: 39.88 %\n",
      "Max Val Acc: 42.11 %\n",
      "------------\n",
      "[EPOCH # 24 ]\n",
      "       Loss: 1.405\n",
      "  Train Acc: 48.81 %\n",
      "    Val Acc: 41.82 %\n",
      "Max Val Acc: 43.45 %\n",
      "------------\n",
      "[EPOCH # 25 ]\n",
      "       Loss: 1.38\n",
      "  Train Acc: 50.6 %\n",
      "    Val Acc: 42.71 %\n",
      "Max Val Acc: 43.45 %\n",
      "------------\n",
      "[EPOCH # 26 ]\n",
      "       Loss: 1.362\n",
      "  Train Acc: 48.25 %\n",
      "    Val Acc: 42.26 %\n",
      "Max Val Acc: 44.2 %\n",
      "------------\n",
      "[EPOCH # 27 ]\n",
      "       Loss: 1.318\n",
      "  Train Acc: 50.0 %\n",
      "    Val Acc: 40.92 %\n",
      "Max Val Acc: 44.49 %\n",
      "------------\n",
      "[EPOCH # 28 ]\n",
      "       Loss: 1.305\n",
      "  Train Acc: 54.13 %\n",
      "    Val Acc: 42.11 %\n",
      "Max Val Acc: 44.49 %\n",
      "------------\n",
      "[EPOCH # 29 ]\n",
      "       Loss: 1.279\n",
      "  Train Acc: 53.39 %\n",
      "    Val Acc: 40.18 %\n",
      "Max Val Acc: 45.24 %\n",
      "------------\n",
      "[EPOCH # 30 ]\n",
      "       Loss: 1.287\n",
      "  Train Acc: 55.62 %\n",
      "    Val Acc: 43.75 %\n",
      "Max Val Acc: 45.24 %\n",
      "------------\n",
      "[EPOCH # 31 ]\n",
      "       Loss: 1.221\n",
      "  Train Acc: 57.48 %\n",
      "    Val Acc: 44.2 %\n",
      "Max Val Acc: 45.39 %\n",
      "------------\n",
      "[EPOCH # 32 ]\n",
      "       Loss: 1.177\n",
      "  Train Acc: 59.78 %\n",
      "    Val Acc: 46.28 %\n",
      "Max Val Acc: 46.28 %\n",
      "------------\n",
      "[EPOCH # 33 ]\n",
      "       Loss: 1.166\n",
      "  Train Acc: 58.15 %\n",
      "    Val Acc: 40.77 %\n",
      "Max Val Acc: 46.28 %\n",
      "------------\n",
      "[EPOCH # 34 ]\n",
      "       Loss: 1.147\n",
      "  Train Acc: 63.32 %\n",
      "    Val Acc: 45.83 %\n",
      "Max Val Acc: 46.88 %\n",
      "------------\n",
      "[EPOCH # 35 ]\n",
      "       Loss: 1.095\n",
      "  Train Acc: 65.36 %\n",
      "    Val Acc: 47.02 %\n",
      "Max Val Acc: 47.32 %\n",
      "------------\n",
      "[EPOCH # 36 ]\n",
      "       Loss: 1.063\n",
      "  Train Acc: 65.36 %\n",
      "    Val Acc: 45.39 %\n",
      "Max Val Acc: 47.32 %\n",
      "------------\n",
      "[EPOCH # 37 ]\n",
      "       Loss: 1.038\n",
      "  Train Acc: 66.15 %\n",
      "    Val Acc: 45.68 %\n",
      "Max Val Acc: 48.07 %\n",
      "------------\n",
      "[EPOCH # 38 ]\n",
      "       Loss: 0.986\n",
      "  Train Acc: 71.35 %\n",
      "    Val Acc: 46.73 %\n",
      "Max Val Acc: 50.45 %\n",
      "------------\n",
      "[EPOCH # 39 ]\n",
      "       Loss: 0.95\n",
      "  Train Acc: 68.56 %\n",
      "    Val Acc: 46.88 %\n",
      "Max Val Acc: 50.45 %\n",
      "------------\n",
      "[EPOCH # 40 ]\n",
      "       Loss: 0.966\n",
      "  Train Acc: 70.57 %\n",
      "    Val Acc: 46.28 %\n",
      "Max Val Acc: 50.45 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 50.44642857142857 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.089\n",
      "  Train Acc: 13.1 %\n",
      "    Val Acc: 12.8 %\n",
      "Max Val Acc: 12.8 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.081\n",
      "  Train Acc: 13.1 %\n",
      "    Val Acc: 12.8 %\n",
      "Max Val Acc: 12.8 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.078\n",
      "  Train Acc: 13.1 %\n",
      "    Val Acc: 12.8 %\n",
      "Max Val Acc: 12.8 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.078\n",
      "  Train Acc: 13.1 %\n",
      "    Val Acc: 12.8 %\n",
      "Max Val Acc: 12.8 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.078\n",
      "  Train Acc: 13.32 %\n",
      "    Val Acc: 14.29 %\n",
      "Max Val Acc: 16.52 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 2.078\n",
      "  Train Acc: 13.32 %\n",
      "    Val Acc: 14.29 %\n",
      "Max Val Acc: 16.52 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 2.077\n",
      "  Train Acc: 13.32 %\n",
      "    Val Acc: 14.29 %\n",
      "Max Val Acc: 16.52 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 2.077\n",
      "  Train Acc: 13.47 %\n",
      "    Val Acc: 14.29 %\n",
      "Max Val Acc: 16.52 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 2.076\n",
      "  Train Acc: 13.32 %\n",
      "    Val Acc: 14.29 %\n",
      "Max Val Acc: 16.52 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 2.076\n",
      "  Train Acc: 20.91 %\n",
      "    Val Acc: 18.3 %\n",
      "Max Val Acc: 18.3 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 2.073\n",
      "  Train Acc: 21.99 %\n",
      "    Val Acc: 19.79 %\n",
      "Max Val Acc: 19.79 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 2.066\n",
      "  Train Acc: 22.81 %\n",
      "    Val Acc: 20.98 %\n",
      "Max Val Acc: 20.98 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 2.029\n",
      "  Train Acc: 23.36 %\n",
      "    Val Acc: 23.51 %\n",
      "Max Val Acc: 23.51 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.91\n",
      "  Train Acc: 23.29 %\n",
      "    Val Acc: 23.36 %\n",
      "Max Val Acc: 23.66 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.843\n",
      "  Train Acc: 24.67 %\n",
      "    Val Acc: 23.96 %\n",
      "Max Val Acc: 23.96 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.801\n",
      "  Train Acc: 26.93 %\n",
      "    Val Acc: 25.74 %\n",
      "Max Val Acc: 25.74 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.767\n",
      "  Train Acc: 28.57 %\n",
      "    Val Acc: 24.7 %\n",
      "Max Val Acc: 28.42 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.742\n",
      "  Train Acc: 30.51 %\n",
      "    Val Acc: 27.38 %\n",
      "Max Val Acc: 28.42 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.718\n",
      "  Train Acc: 32.85 %\n",
      "    Val Acc: 28.42 %\n",
      "Max Val Acc: 30.51 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.693\n",
      "  Train Acc: 34.52 %\n",
      "    Val Acc: 29.61 %\n",
      "Max Val Acc: 31.25 %\n",
      "------------\n",
      "[EPOCH # 21 ]\n",
      "       Loss: 1.646\n",
      "  Train Acc: 36.24 %\n",
      "    Val Acc: 29.02 %\n",
      "Max Val Acc: 31.25 %\n",
      "------------\n",
      "[EPOCH # 22 ]\n",
      "       Loss: 1.593\n",
      "  Train Acc: 37.28 %\n",
      "    Val Acc: 28.42 %\n",
      "Max Val Acc: 31.7 %\n",
      "------------\n",
      "[EPOCH # 23 ]\n",
      "       Loss: 1.559\n",
      "  Train Acc: 39.99 %\n",
      "    Val Acc: 28.27 %\n",
      "Max Val Acc: 33.04 %\n",
      "------------\n",
      "[EPOCH # 24 ]\n",
      "       Loss: 1.539\n",
      "  Train Acc: 40.7 %\n",
      "    Val Acc: 33.33 %\n",
      "Max Val Acc: 34.52 %\n",
      "------------\n",
      "[EPOCH # 25 ]\n",
      "       Loss: 1.503\n",
      "  Train Acc: 39.99 %\n",
      "    Val Acc: 34.08 %\n",
      "Max Val Acc: 34.82 %\n",
      "------------\n",
      "[EPOCH # 26 ]\n",
      "       Loss: 1.476\n",
      "  Train Acc: 46.09 %\n",
      "    Val Acc: 35.57 %\n",
      "Max Val Acc: 36.31 %\n",
      "------------\n",
      "[EPOCH # 27 ]\n",
      "       Loss: 1.423\n",
      "  Train Acc: 46.09 %\n",
      "    Val Acc: 37.65 %\n",
      "Max Val Acc: 37.65 %\n",
      "------------\n",
      "[EPOCH # 28 ]\n",
      "       Loss: 1.383\n",
      "  Train Acc: 48.18 %\n",
      "    Val Acc: 37.65 %\n",
      "Max Val Acc: 40.48 %\n",
      "------------\n",
      "[EPOCH # 29 ]\n",
      "       Loss: 1.369\n",
      "  Train Acc: 49.67 %\n",
      "    Val Acc: 37.5 %\n",
      "Max Val Acc: 41.37 %\n",
      "------------\n",
      "[EPOCH # 30 ]\n",
      "       Loss: 1.329\n",
      "  Train Acc: 53.57 %\n",
      "    Val Acc: 39.73 %\n",
      "Max Val Acc: 41.37 %\n",
      "------------\n",
      "[EPOCH # 31 ]\n",
      "       Loss: 1.271\n",
      "  Train Acc: 55.39 %\n",
      "    Val Acc: 40.03 %\n",
      "Max Val Acc: 43.15 %\n",
      "------------\n",
      "[EPOCH # 32 ]\n",
      "       Loss: 1.257\n",
      "  Train Acc: 56.03 %\n",
      "    Val Acc: 41.22 %\n",
      "Max Val Acc: 44.2 %\n",
      "------------\n",
      "[EPOCH # 33 ]\n",
      "       Loss: 1.195\n",
      "  Train Acc: 59.49 %\n",
      "    Val Acc: 43.75 %\n",
      "Max Val Acc: 44.64 %\n",
      "------------\n",
      "[EPOCH # 34 ]\n",
      "       Loss: 1.15\n",
      "  Train Acc: 60.23 %\n",
      "    Val Acc: 44.05 %\n",
      "Max Val Acc: 45.39 %\n",
      "------------\n",
      "[EPOCH # 35 ]\n",
      "       Loss: 1.122\n",
      "  Train Acc: 61.9 %\n",
      "    Val Acc: 45.09 %\n",
      "Max Val Acc: 46.28 %\n",
      "------------\n",
      "[EPOCH # 36 ]\n",
      "       Loss: 1.07\n",
      "  Train Acc: 66.48 %\n",
      "    Val Acc: 47.17 %\n",
      "Max Val Acc: 48.07 %\n",
      "------------\n",
      "[EPOCH # 37 ]\n",
      "       Loss: 1.028\n",
      "  Train Acc: 65.44 %\n",
      "    Val Acc: 46.43 %\n",
      "Max Val Acc: 48.07 %\n",
      "------------\n",
      "[EPOCH # 38 ]\n",
      "       Loss: 0.994\n",
      "  Train Acc: 66.74 %\n",
      "    Val Acc: 45.39 %\n",
      "Max Val Acc: 48.66 %\n",
      "------------\n",
      "[EPOCH # 39 ]\n",
      "       Loss: 0.96\n",
      "  Train Acc: 68.01 %\n",
      "    Val Acc: 45.98 %\n",
      "Max Val Acc: 48.66 %\n",
      "------------\n",
      "[EPOCH # 40 ]\n",
      "       Loss: 0.923\n",
      "  Train Acc: 69.79 %\n",
      "    Val Acc: 46.58 %\n",
      "Max Val Acc: 48.66 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 48.660714285714285 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.094\n",
      "  Train Acc: 12.8 %\n",
      "    Val Acc: 13.39 %\n",
      "Max Val Acc: 13.39 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.083\n",
      "  Train Acc: 12.43 %\n",
      "    Val Acc: 11.76 %\n",
      "Max Val Acc: 13.39 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.08\n",
      "  Train Acc: 13.39 %\n",
      "    Val Acc: 14.43 %\n",
      "Max Val Acc: 15.77 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.079\n",
      "  Train Acc: 13.47 %\n",
      "    Val Acc: 14.43 %\n",
      "Max Val Acc: 15.77 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.079\n",
      "  Train Acc: 18.42 %\n",
      "    Val Acc: 19.49 %\n",
      "Max Val Acc: 20.98 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 2.078\n",
      "  Train Acc: 13.39 %\n",
      "    Val Acc: 14.43 %\n",
      "Max Val Acc: 20.98 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 2.077\n",
      "  Train Acc: 13.39 %\n",
      "    Val Acc: 14.43 %\n",
      "Max Val Acc: 20.98 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 2.076\n",
      "  Train Acc: 13.76 %\n",
      "    Val Acc: 14.73 %\n",
      "Max Val Acc: 20.98 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 2.072\n",
      "  Train Acc: 15.7 %\n",
      "    Val Acc: 16.37 %\n",
      "Max Val Acc: 20.98 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 2.057\n",
      "  Train Acc: 24.74 %\n",
      "    Val Acc: 26.64 %\n",
      "Max Val Acc: 26.64 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 1.979\n",
      "  Train Acc: 22.06 %\n",
      "    Val Acc: 23.51 %\n",
      "Max Val Acc: 26.64 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 1.884\n",
      "  Train Acc: 25.3 %\n",
      "    Val Acc: 25.74 %\n",
      "Max Val Acc: 26.64 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.846\n",
      "  Train Acc: 24.63 %\n",
      "    Val Acc: 23.66 %\n",
      "Max Val Acc: 26.64 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.82\n",
      "  Train Acc: 26.86 %\n",
      "    Val Acc: 26.04 %\n",
      "Max Val Acc: 27.38 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.805\n",
      "  Train Acc: 27.05 %\n",
      "    Val Acc: 24.11 %\n",
      "Max Val Acc: 27.38 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.788\n",
      "  Train Acc: 26.9 %\n",
      "    Val Acc: 24.7 %\n",
      "Max Val Acc: 27.38 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.775\n",
      "  Train Acc: 27.08 %\n",
      "    Val Acc: 25.74 %\n",
      "Max Val Acc: 27.38 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.755\n",
      "  Train Acc: 28.68 %\n",
      "    Val Acc: 26.19 %\n",
      "Max Val Acc: 27.83 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.74\n",
      "  Train Acc: 29.5 %\n",
      "    Val Acc: 26.79 %\n",
      "Max Val Acc: 27.83 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.73\n",
      "  Train Acc: 29.84 %\n",
      "    Val Acc: 25.74 %\n",
      "Max Val Acc: 27.83 %\n",
      "------------\n",
      "[EPOCH # 21 ]\n",
      "       Loss: 1.701\n",
      "  Train Acc: 31.29 %\n",
      "    Val Acc: 27.08 %\n",
      "Max Val Acc: 27.83 %\n",
      "------------\n",
      "[EPOCH # 22 ]\n",
      "       Loss: 1.685\n",
      "  Train Acc: 30.92 %\n",
      "    Val Acc: 25.6 %\n",
      "Max Val Acc: 28.12 %\n",
      "------------\n",
      "[EPOCH # 23 ]\n",
      "       Loss: 1.691\n",
      "  Train Acc: 30.95 %\n",
      "    Val Acc: 27.08 %\n",
      "Max Val Acc: 28.12 %\n",
      "------------\n",
      "[EPOCH # 24 ]\n",
      "       Loss: 1.665\n",
      "  Train Acc: 29.95 %\n",
      "    Val Acc: 24.55 %\n",
      "Max Val Acc: 28.12 %\n",
      "------------\n",
      "[EPOCH # 25 ]\n",
      "       Loss: 1.63\n",
      "  Train Acc: 36.9 %\n",
      "    Val Acc: 29.61 %\n",
      "Max Val Acc: 29.61 %\n",
      "------------\n",
      "[EPOCH # 26 ]\n",
      "       Loss: 1.603\n",
      "  Train Acc: 34.67 %\n",
      "    Val Acc: 28.87 %\n",
      "Max Val Acc: 30.8 %\n",
      "------------\n",
      "[EPOCH # 27 ]\n",
      "       Loss: 1.575\n",
      "  Train Acc: 33.89 %\n",
      "    Val Acc: 28.42 %\n",
      "Max Val Acc: 30.8 %\n",
      "------------\n",
      "[EPOCH # 28 ]\n",
      "       Loss: 1.58\n",
      "  Train Acc: 35.08 %\n",
      "    Val Acc: 29.91 %\n",
      "Max Val Acc: 31.85 %\n",
      "------------\n",
      "[EPOCH # 29 ]\n",
      "       Loss: 1.529\n",
      "  Train Acc: 36.53 %\n",
      "    Val Acc: 28.57 %\n",
      "Max Val Acc: 33.04 %\n",
      "------------\n",
      "[EPOCH # 30 ]\n",
      "       Loss: 1.502\n",
      "  Train Acc: 37.61 %\n",
      "    Val Acc: 31.7 %\n",
      "Max Val Acc: 33.04 %\n",
      "------------\n",
      "[EPOCH # 31 ]\n",
      "       Loss: 1.509\n",
      "  Train Acc: 36.64 %\n",
      "    Val Acc: 31.4 %\n",
      "Max Val Acc: 34.67 %\n",
      "------------\n",
      "[EPOCH # 32 ]\n",
      "       Loss: 1.464\n",
      "  Train Acc: 38.21 %\n",
      "    Val Acc: 30.8 %\n",
      "Max Val Acc: 34.67 %\n",
      "------------\n",
      "[EPOCH # 33 ]\n",
      "       Loss: 1.432\n",
      "  Train Acc: 39.92 %\n",
      "    Val Acc: 32.44 %\n",
      "Max Val Acc: 34.67 %\n",
      "------------\n",
      "[EPOCH # 34 ]\n",
      "       Loss: 1.412\n",
      "  Train Acc: 39.1 %\n",
      "    Val Acc: 28.87 %\n",
      "Max Val Acc: 34.67 %\n",
      "------------\n",
      "[EPOCH # 35 ]\n",
      "       Loss: 1.391\n",
      "  Train Acc: 41.93 %\n",
      "    Val Acc: 31.99 %\n",
      "Max Val Acc: 34.67 %\n",
      "------------\n",
      "[EPOCH # 36 ]\n",
      "       Loss: 1.377\n",
      "  Train Acc: 42.52 %\n",
      "    Val Acc: 32.59 %\n",
      "Max Val Acc: 34.67 %\n",
      "------------\n",
      "[EPOCH # 37 ]\n",
      "       Loss: 1.377\n",
      "  Train Acc: 42.49 %\n",
      "    Val Acc: 32.14 %\n",
      "Max Val Acc: 34.67 %\n",
      "------------\n",
      "[EPOCH # 38 ]\n",
      "       Loss: 1.328\n",
      "  Train Acc: 47.54 %\n",
      "    Val Acc: 34.97 %\n",
      "Max Val Acc: 37.8 %\n",
      "------------\n",
      "[EPOCH # 39 ]\n",
      "       Loss: 1.297\n",
      "  Train Acc: 45.94 %\n",
      "    Val Acc: 32.89 %\n",
      "Max Val Acc: 37.8 %\n",
      "------------\n",
      "[EPOCH # 40 ]\n",
      "       Loss: 1.256\n",
      "  Train Acc: 49.26 %\n",
      "    Val Acc: 33.93 %\n",
      "Max Val Acc: 37.8 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 37.79761904761905 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.087\n",
      "  Train Acc: 14.17 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 13.1 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.078\n",
      "  Train Acc: 14.17 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 13.1 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.076\n",
      "  Train Acc: 14.17 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 13.1 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.076\n",
      "  Train Acc: 14.17 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 13.1 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.076\n",
      "  Train Acc: 14.17 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 13.1 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 2.076\n",
      "  Train Acc: 14.17 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 13.1 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 2.075\n",
      "  Train Acc: 14.17 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 13.1 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 2.075\n",
      "  Train Acc: 14.17 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 13.1 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 2.074\n",
      "  Train Acc: 14.17 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 13.1 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 2.073\n",
      "  Train Acc: 14.17 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 13.1 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 2.071\n",
      "  Train Acc: 14.17 %\n",
      "    Val Acc: 13.1 %\n",
      "Max Val Acc: 13.1 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 2.064\n",
      "  Train Acc: 21.09 %\n",
      "    Val Acc: 18.6 %\n",
      "Max Val Acc: 18.6 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 2.043\n",
      "  Train Acc: 20.39 %\n",
      "    Val Acc: 20.24 %\n",
      "Max Val Acc: 20.24 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.972\n",
      "  Train Acc: 23.29 %\n",
      "    Val Acc: 22.02 %\n",
      "Max Val Acc: 23.36 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.87\n",
      "  Train Acc: 26.56 %\n",
      "    Val Acc: 23.36 %\n",
      "Max Val Acc: 24.85 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.803\n",
      "  Train Acc: 31.06 %\n",
      "    Val Acc: 27.83 %\n",
      "Max Val Acc: 27.83 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.737\n",
      "  Train Acc: 34.75 %\n",
      "    Val Acc: 31.85 %\n",
      "Max Val Acc: 32.14 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.64\n",
      "  Train Acc: 39.21 %\n",
      "    Val Acc: 34.23 %\n",
      "Max Val Acc: 35.57 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.549\n",
      "  Train Acc: 44.35 %\n",
      "    Val Acc: 36.61 %\n",
      "Max Val Acc: 37.2 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.494\n",
      "  Train Acc: 47.21 %\n",
      "    Val Acc: 40.33 %\n",
      "Max Val Acc: 41.37 %\n",
      "------------\n",
      "[EPOCH # 21 ]\n",
      "       Loss: 1.434\n",
      "  Train Acc: 50.19 %\n",
      "    Val Acc: 42.11 %\n",
      "Max Val Acc: 45.09 %\n",
      "------------\n",
      "[EPOCH # 22 ]\n",
      "       Loss: 1.371\n",
      "  Train Acc: 52.53 %\n",
      "    Val Acc: 42.86 %\n",
      "Max Val Acc: 45.54 %\n",
      "------------\n",
      "[EPOCH # 23 ]\n",
      "       Loss: 1.314\n",
      "  Train Acc: 54.91 %\n",
      "    Val Acc: 45.39 %\n",
      "Max Val Acc: 45.54 %\n",
      "------------\n",
      "[EPOCH # 24 ]\n",
      "       Loss: 1.285\n",
      "  Train Acc: 55.88 %\n",
      "    Val Acc: 44.49 %\n",
      "Max Val Acc: 45.68 %\n",
      "------------\n",
      "[EPOCH # 25 ]\n",
      "       Loss: 1.238\n",
      "  Train Acc: 57.66 %\n",
      "    Val Acc: 47.32 %\n",
      "Max Val Acc: 47.47 %\n",
      "------------\n",
      "[EPOCH # 26 ]\n",
      "       Loss: 1.201\n",
      "  Train Acc: 59.6 %\n",
      "    Val Acc: 46.58 %\n",
      "Max Val Acc: 47.47 %\n",
      "------------\n",
      "[EPOCH # 27 ]\n",
      "       Loss: 1.157\n",
      "  Train Acc: 59.93 %\n",
      "    Val Acc: 45.98 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 28 ]\n",
      "       Loss: 1.155\n",
      "  Train Acc: 61.35 %\n",
      "    Val Acc: 47.77 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 29 ]\n",
      "       Loss: 1.116\n",
      "  Train Acc: 63.95 %\n",
      "    Val Acc: 43.6 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 30 ]\n",
      "       Loss: 1.062\n",
      "  Train Acc: 64.77 %\n",
      "    Val Acc: 43.3 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 31 ]\n",
      "       Loss: 1.027\n",
      "  Train Acc: 65.07 %\n",
      "    Val Acc: 43.75 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 32 ]\n",
      "       Loss: 1.031\n",
      "  Train Acc: 66.41 %\n",
      "    Val Acc: 45.83 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 33 ]\n",
      "       Loss: 1.01\n",
      "  Train Acc: 67.97 %\n",
      "    Val Acc: 45.54 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 34 ]\n",
      "       Loss: 0.936\n",
      "  Train Acc: 69.12 %\n",
      "    Val Acc: 45.68 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 35 ]\n",
      "       Loss: 0.893\n",
      "  Train Acc: 70.05 %\n",
      "    Val Acc: 45.39 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 36 ]\n",
      "       Loss: 0.891\n",
      "  Train Acc: 70.76 %\n",
      "    Val Acc: 46.88 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 37 ]\n",
      "       Loss: 0.866\n",
      "  Train Acc: 73.4 %\n",
      "    Val Acc: 46.73 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 38 ]\n",
      "       Loss: 0.829\n",
      "  Train Acc: 70.68 %\n",
      "    Val Acc: 43.75 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 39 ]\n",
      "       Loss: 0.834\n",
      "  Train Acc: 75.48 %\n",
      "    Val Acc: 45.68 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "[EPOCH # 40 ]\n",
      "       Loss: 0.776\n",
      "  Train Acc: 77.49 %\n",
      "    Val Acc: 45.98 %\n",
      "Max Val Acc: 48.51 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 48.51190476190476 %\n",
      "--- FINISHED TRAINING NETWORK ---\n",
      "--- BEGIN TRAINING NETWORK ---\n",
      "[EPOCH # 1 ]\n",
      "       Loss: 2.088\n",
      "  Train Acc: 12.98 %\n",
      "    Val Acc: 11.79 %\n",
      "Max Val Acc: 11.79 %\n",
      "------------\n",
      "[EPOCH # 2 ]\n",
      "       Loss: 2.081\n",
      "  Train Acc: 13.87 %\n",
      "    Val Acc: 12.26 %\n",
      "Max Val Acc: 12.86 %\n",
      "------------\n",
      "[EPOCH # 3 ]\n",
      "       Loss: 2.079\n",
      "  Train Acc: 13.87 %\n",
      "    Val Acc: 12.26 %\n",
      "Max Val Acc: 12.86 %\n",
      "------------\n",
      "[EPOCH # 4 ]\n",
      "       Loss: 2.078\n",
      "  Train Acc: 13.87 %\n",
      "    Val Acc: 12.26 %\n",
      "Max Val Acc: 12.86 %\n",
      "------------\n",
      "[EPOCH # 5 ]\n",
      "       Loss: 2.078\n",
      "  Train Acc: 13.87 %\n",
      "    Val Acc: 12.26 %\n",
      "Max Val Acc: 12.86 %\n",
      "------------\n",
      "[EPOCH # 6 ]\n",
      "       Loss: 2.077\n",
      "  Train Acc: 13.87 %\n",
      "    Val Acc: 12.26 %\n",
      "Max Val Acc: 12.86 %\n",
      "------------\n",
      "[EPOCH # 7 ]\n",
      "       Loss: 2.077\n",
      "  Train Acc: 13.87 %\n",
      "    Val Acc: 12.26 %\n",
      "Max Val Acc: 12.86 %\n",
      "------------\n",
      "[EPOCH # 8 ]\n",
      "       Loss: 2.077\n",
      "  Train Acc: 13.87 %\n",
      "    Val Acc: 12.26 %\n",
      "Max Val Acc: 12.86 %\n",
      "------------\n",
      "[EPOCH # 9 ]\n",
      "       Loss: 2.075\n",
      "  Train Acc: 13.87 %\n",
      "    Val Acc: 12.26 %\n",
      "Max Val Acc: 13.93 %\n",
      "------------\n",
      "[EPOCH # 10 ]\n",
      "       Loss: 2.072\n",
      "  Train Acc: 13.87 %\n",
      "    Val Acc: 12.26 %\n",
      "Max Val Acc: 13.93 %\n",
      "------------\n",
      "[EPOCH # 11 ]\n",
      "       Loss: 2.062\n",
      "  Train Acc: 19.49 %\n",
      "    Val Acc: 18.45 %\n",
      "Max Val Acc: 18.45 %\n",
      "------------\n",
      "[EPOCH # 12 ]\n",
      "       Loss: 2.008\n",
      "  Train Acc: 24.23 %\n",
      "    Val Acc: 23.33 %\n",
      "Max Val Acc: 24.17 %\n",
      "------------\n",
      "[EPOCH # 13 ]\n",
      "       Loss: 1.878\n",
      "  Train Acc: 29.94 %\n",
      "    Val Acc: 28.81 %\n",
      "Max Val Acc: 28.81 %\n",
      "------------\n",
      "[EPOCH # 14 ]\n",
      "       Loss: 1.761\n",
      "  Train Acc: 35.62 %\n",
      "    Val Acc: 33.33 %\n",
      "Max Val Acc: 33.93 %\n",
      "------------\n",
      "[EPOCH # 15 ]\n",
      "       Loss: 1.669\n",
      "  Train Acc: 38.72 %\n",
      "    Val Acc: 35.12 %\n",
      "Max Val Acc: 35.36 %\n",
      "------------\n",
      "[EPOCH # 16 ]\n",
      "       Loss: 1.606\n",
      "  Train Acc: 40.51 %\n",
      "    Val Acc: 36.55 %\n",
      "Max Val Acc: 36.55 %\n",
      "------------\n",
      "[EPOCH # 17 ]\n",
      "       Loss: 1.564\n",
      "  Train Acc: 42.38 %\n",
      "    Val Acc: 35.95 %\n",
      "Max Val Acc: 37.86 %\n",
      "------------\n",
      "[EPOCH # 18 ]\n",
      "       Loss: 1.526\n",
      "  Train Acc: 42.8 %\n",
      "    Val Acc: 38.21 %\n",
      "Max Val Acc: 38.57 %\n",
      "------------\n",
      "[EPOCH # 19 ]\n",
      "       Loss: 1.503\n",
      "  Train Acc: 44.49 %\n",
      "    Val Acc: 36.55 %\n",
      "Max Val Acc: 38.69 %\n",
      "------------\n",
      "[EPOCH # 20 ]\n",
      "       Loss: 1.474\n",
      "  Train Acc: 44.67 %\n",
      "    Val Acc: 36.55 %\n",
      "Max Val Acc: 39.4 %\n",
      "------------\n",
      "[EPOCH # 21 ]\n",
      "       Loss: 1.451\n",
      "  Train Acc: 45.83 %\n",
      "    Val Acc: 36.19 %\n",
      "Max Val Acc: 39.4 %\n",
      "------------\n",
      "[EPOCH # 22 ]\n",
      "       Loss: 1.417\n",
      "  Train Acc: 48.07 %\n",
      "    Val Acc: 38.21 %\n",
      "Max Val Acc: 40.71 %\n",
      "------------\n",
      "[EPOCH # 23 ]\n",
      "       Loss: 1.4\n",
      "  Train Acc: 48.42 %\n",
      "    Val Acc: 38.69 %\n",
      "Max Val Acc: 40.95 %\n",
      "------------\n",
      "[EPOCH # 24 ]\n",
      "       Loss: 1.362\n",
      "  Train Acc: 50.62 %\n",
      "    Val Acc: 40.95 %\n",
      "Max Val Acc: 41.79 %\n",
      "------------\n",
      "[EPOCH # 25 ]\n",
      "       Loss: 1.324\n",
      "  Train Acc: 52.11 %\n",
      "    Val Acc: 41.19 %\n",
      "Max Val Acc: 43.33 %\n",
      "------------\n",
      "[EPOCH # 26 ]\n",
      "       Loss: 1.285\n",
      "  Train Acc: 53.93 %\n",
      "    Val Acc: 42.26 %\n",
      "Max Val Acc: 43.33 %\n",
      "------------\n",
      "[EPOCH # 27 ]\n",
      "       Loss: 1.258\n",
      "  Train Acc: 56.76 %\n",
      "    Val Acc: 44.29 %\n",
      "Max Val Acc: 44.88 %\n",
      "------------\n",
      "[EPOCH # 28 ]\n",
      "       Loss: 1.203\n",
      "  Train Acc: 58.81 %\n",
      "    Val Acc: 48.33 %\n",
      "Max Val Acc: 48.33 %\n",
      "------------\n",
      "[EPOCH # 29 ]\n",
      "       Loss: 1.157\n",
      "  Train Acc: 60.62 %\n",
      "    Val Acc: 47.62 %\n",
      "Max Val Acc: 50.0 %\n",
      "------------\n",
      "[EPOCH # 30 ]\n",
      "       Loss: 1.09\n",
      "  Train Acc: 64.17 %\n",
      "    Val Acc: 50.12 %\n",
      "Max Val Acc: 50.12 %\n",
      "------------\n",
      "[EPOCH # 31 ]\n",
      "       Loss: 1.076\n",
      "  Train Acc: 60.39 %\n",
      "    Val Acc: 49.17 %\n",
      "Max Val Acc: 51.43 %\n",
      "------------\n",
      "[EPOCH # 32 ]\n",
      "       Loss: 1.037\n",
      "  Train Acc: 66.43 %\n",
      "    Val Acc: 49.4 %\n",
      "Max Val Acc: 51.43 %\n",
      "------------\n",
      "[EPOCH # 33 ]\n",
      "       Loss: 0.992\n",
      "  Train Acc: 64.08 %\n",
      "    Val Acc: 48.57 %\n",
      "Max Val Acc: 51.43 %\n",
      "------------\n",
      "[EPOCH # 34 ]\n",
      "       Loss: 0.965\n",
      "  Train Acc: 67.83 %\n",
      "    Val Acc: 51.55 %\n",
      "Max Val Acc: 51.55 %\n",
      "------------\n",
      "[EPOCH # 35 ]\n",
      "       Loss: 0.929\n",
      "  Train Acc: 69.23 %\n",
      "    Val Acc: 49.88 %\n",
      "Max Val Acc: 51.55 %\n",
      "------------\n",
      "[EPOCH # 36 ]\n",
      "       Loss: 0.917\n",
      "  Train Acc: 71.07 %\n",
      "    Val Acc: 51.9 %\n",
      "Max Val Acc: 52.86 %\n",
      "------------\n",
      "[EPOCH # 37 ]\n",
      "       Loss: 0.894\n",
      "  Train Acc: 69.7 %\n",
      "    Val Acc: 48.57 %\n",
      "Max Val Acc: 52.86 %\n",
      "------------\n",
      "[EPOCH # 38 ]\n",
      "       Loss: 0.845\n",
      "  Train Acc: 73.24 %\n",
      "    Val Acc: 48.81 %\n",
      "Max Val Acc: 52.86 %\n",
      "------------\n",
      "[EPOCH # 39 ]\n",
      "       Loss: 0.812\n",
      "  Train Acc: 76.82 %\n",
      "    Val Acc: 51.55 %\n",
      "Max Val Acc: 52.86 %\n",
      "------------\n",
      "[EPOCH # 40 ]\n",
      "       Loss: 0.8\n",
      "  Train Acc: 71.46 %\n",
      "    Val Acc: 50.0 %\n",
      "Max Val Acc: 52.86 %\n",
      "------------\n",
      "Finished Training\n",
      "Max Validation Acc: 52.857142857142854 %\n",
      "--- FINISHED TRAINING NETWORK ---\n"
     ]
    }
   ],
   "source": [
    "y_pred_NN4 = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    \n",
    "    inputs_train_d = inputs_train.drop(inputs_train.index[i-840:i])\n",
    "    targets_train_d = targets_train.drop(targets_train.index[i-840:i])\n",
    "    inputs_train_td = inputs_train[i-840:i]\n",
    "    \n",
    "    inputs_train_nn = inputs_train_d.reset_index(drop=True)\n",
    "    inputs_test_nn = inputs_train_td.reset_index(drop=True)\n",
    "    targets_train_nn=targets_train_d.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    NN_prob4 = nn_train_to_prob_mat(inputs_train_nn,\n",
    "                                    targets_train_nn, \n",
    "                                    inputs_test_nn, class_labels=classes, epoch_num=40, verbose=True)\n",
    "    y_pred_NN4 = np.append(y_pred_NN4, NN_prob4, axis = 0)\n",
    "\n",
    "dfNN4_train = pd.DataFrame(y_pred_NN4, columns = ['NN4_El', 'NN4_Exp', 'NN4_Flk', 'NN4_HH', \n",
    "                                           'NN4_Inst', 'NN4_Intr', 'NN4_Pop', 'NN4_Rck'])\n",
    "\n",
    "inputs_train_nnf = inputs_train.reset_index(drop=True)\n",
    "targets_train_nnf = targets_train.reset_index(drop=True)\n",
    "inputs_test_nnf = inputs_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "y_pred_test_NN4 = nn_train_to_prob_mat(inputs_train_nnf,\n",
    "                                    targets_train_nnf, inputs_test_nnf, class_labels=classes, epoch_num=40, verbose=True)\n",
    "\n",
    "dfNN4_test = pd.DataFrame(y_pred_test_NN4, columns = ['NN4_El', 'NN4_Exp', 'NN4_Flk', 'NN4_HH', \n",
    "                                           'NN4_Inst', 'NN4_Intr', 'NN4_Pop', 'NN4_Rck'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:52:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:52:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:53:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:53:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:54:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:54:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:55:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:55:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:55:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:55:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:56:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:56:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#XGBoost1\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "y_pred_XGB = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    XGB = XGBClassifier(\n",
    "     learning_rate =0.1,\n",
    "     n_estimators=320,\n",
    "     max_depth=7,\n",
    "     min_child_weight=5,\n",
    "     gamma=0,\n",
    "     subsample=0.6,\n",
    "     colsample_bytree=0.5,\n",
    "     reg_alpha = 0.1,\n",
    "     reg_lambda = 1,\n",
    "     objective= 'multi:softmax',\n",
    "     num_class = 8,\n",
    "     n_jobs=-1,\n",
    "     scale_pos_weight=1,\n",
    "     seed=27)\n",
    "    XGB_prob = XGB.fit(inputs_train.drop(inputs_train.index[i-840:i]), \n",
    "                       targets_train.drop(targets_train.index[i-840:i])).predict_proba(inputs_train[i-840:i])\n",
    "    y_pred_XGB = np.append(y_pred_XGB, XGB_prob, axis = 0)\n",
    "    \n",
    "\n",
    "dfXGB_train = pd.DataFrame(y_pred_XGB, columns = ['XGB1_El', 'XGB1_Exp', 'XGB1_Flk', 'XGB1_HH', \n",
    "                                           'XGB1_Inst', 'XGB1_Intr', 'XGB1_Pop', 'XGB1_Rck'])\n",
    "\n",
    "XGB_fitted = XGB.fit(inputs_train, targets_train)\n",
    "\n",
    "y_pred_test_XGB = XGB_fitted.predict_proba(inputs_test)\n",
    "dfXGB_test = pd.DataFrame(y_pred_test_XGB, columns = ['XGB1_El', 'XGB1_Exp', 'XGB1_Flk', 'XGB1_HH', \n",
    "                                           'XGB1_Inst', 'XGB1_Intr', 'XGB1_Pop', 'XGB1_Rck'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:57:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:57:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:58:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:58:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:59:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:59:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:59:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:59:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:00:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:00:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:01:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:01:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#XGBoost2\n",
    "\n",
    "y_pred_XGB2 = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    XGB2 = XGBClassifier(\n",
    "     learning_rate =0.1,\n",
    "        n_estimators=320,\n",
    "        max_depth=7,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.2,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=0.4,\n",
    "        reg_alpha = 0.1,\n",
    "        reg_lambda = 1,\n",
    "        objective= 'multi:softmax',\n",
    "        num_class = 8,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "    XGB2_prob = XGB2.fit(inputs_train.drop(inputs_train.index[i-840:i]), \n",
    "                       targets_train.drop(targets_train.index[i-840:i])).predict_proba(inputs_train[i-840:i])\n",
    "    y_pred_XGB2 = np.append(y_pred_XGB2, XGB2_prob, axis = 0)\n",
    "    \n",
    "dfXGB2_train = pd.DataFrame(y_pred_XGB2, columns = ['XGB2_El', 'XGB2_Exp', 'XGB2_Flk', 'XGB2_HH', \n",
    "                                           'XGB2_Inst', 'XGB2_Intr', 'XGB2_Pop', 'XGB2_Rck'])\n",
    "\n",
    "XGB2_fitted = XGB2.fit(inputs_train, targets_train)\n",
    "\n",
    "y_pred_test_XGB2 = XGB2_fitted.predict_proba(inputs_test)\n",
    "dfXGB2_test = pd.DataFrame(y_pred_test_XGB2, columns = ['XGB2_El', 'XGB2_Exp', 'XGB2_Flk', 'XGB2_HH', \n",
    "                                           'XGB2_Inst', 'XGB2_Intr', 'XGB2_Pop', 'XGB2_Rck'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:02:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:02:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:02:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:03:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:03:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:04:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:05:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#XGBoost3\n",
    "\n",
    "y_pred_XGB3 = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    XGB3 = XGBClassifier(\n",
    "     learning_rate =0.1,\n",
    "      n_estimators=320,\n",
    "      max_depth=3,\n",
    "      min_child_weight=5,\n",
    "      gamma=0,\n",
    "      subsample=0.6,\n",
    "      colsample_bytree=0.5,\n",
    "      reg_alpha = 1,\n",
    "      reg_lambda = 1,\n",
    "      objective= 'multi:softmax',\n",
    "      num_class = 8,\n",
    "      n_jobs=-1,\n",
    "      scale_pos_weight=1,\n",
    "      seed=27)\n",
    "\n",
    "    XGB3_prob = XGB3.fit(inputs_train.drop(inputs_train.index[i-840:i]), \n",
    "                       targets_train.drop(targets_train.index[i-840:i])).predict_proba(inputs_train[i-840:i])\n",
    "    \n",
    "    y_pred_XGB3 = np.append(y_pred_XGB3, XGB3_prob, axis = 0)\n",
    "\n",
    "dfXGB3_train = pd.DataFrame(y_pred_XGB3, columns = ['XGB3_El', 'XGB3_Exp', 'XGB3_Flk', 'XGB3_HH', \n",
    "                                           'XGB3_Inst', 'XGB3_Intr', 'XGB3_Pop', 'XGB3_Rck'])\n",
    "\n",
    "XGB3_fitted = XGB3.fit(inputs_train, targets_train)\n",
    "\n",
    "y_pred_test_XGB3 = XGB3_fitted.predict_proba(inputs_test)\n",
    "dfXGB3_test = pd.DataFrame(y_pred_test_XGB3, columns = ['XGB3_El', 'XGB3_Exp', 'XGB3_Flk', 'XGB3_HH', \n",
    "                                           'XGB3_Inst', 'XGB3_Intr', 'XGB3_Pop', 'XGB3_Rck'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:06:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:07:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:07:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:08:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:09:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:10:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "y_pred_XGB4 = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    XGB4 = XGBClassifier(\n",
    "         learning_rate =0.1,\n",
    "         n_estimators=235,\n",
    "         max_depth=5,\n",
    "         min_child_weight=2,\n",
    "         gamma=0,\n",
    "         reg_lambda=1,\n",
    "         subsample=0.75,\n",
    "         colsample_bytree=0.75,\n",
    "         colsample_bynode = 0.75,\n",
    "         objective= 'multi:softmax',\n",
    "         num_class = 8,\n",
    "         n_jobs=-1,\n",
    "         seed=27)\n",
    "\n",
    "\n",
    "    XGB4_prob = XGB4.fit(inputs_train.drop(inputs_train.index[i-840:i]), \n",
    "                       targets_train.drop(targets_train.index[i-840:i])).predict_proba(inputs_train[i-840:i])\n",
    "    \n",
    "    y_pred_XGB4 = np.append(y_pred_XGB4, XGB4_prob, axis = 0)\n",
    "\n",
    "dfXGB4_train = pd.DataFrame(y_pred_XGB4, columns = ['XGB4_El', 'XGB4_Exp', 'XGB4_Flk', 'XGB4_HH', \n",
    "                                           'XGB4_Inst', 'XGB4_Intr', 'XGB4_Pop', 'XGB4_Rck'])\n",
    "\n",
    "XGB4_fitted = XGB4.fit(inputs_train, targets_train)\n",
    "\n",
    "y_pred_test_XGB4 = XGB4_fitted.predict_proba(inputs_test)\n",
    "dfXGB4_test = pd.DataFrame(y_pred_test_XGB4, columns = ['XGB4_El', 'XGB4_Exp', 'XGB4_Flk', 'XGB4_HH', \n",
    "                                           'XGB4_Inst', 'XGB4_Intr', 'XGB4_Pop', 'XGB4_Rck'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "y_pred_LDA = np.empty(shape = (0,8))\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    LDA = LinearDiscriminantAnalysis(solver = \"eigen\", shrinkage = 'auto')\n",
    "\n",
    "    LDA_prob = LDA.fit(inputs_train.drop(inputs_train.index[i-840:i]), \n",
    "                       targets_train.drop(targets_train.index[i-840:i])).predict_proba(inputs_train[i-840:i])\n",
    "    \n",
    "    y_pred_LDA = np.append(y_pred_LDA, LDA_prob, axis = 0)\n",
    "    \n",
    "dfLDA_train = pd.DataFrame(y_pred_LDA, columns = ['LDA_El', 'LDA_Exp', 'LDA_Flk', 'LDA_HH', \n",
    "                                           'LDA_Inst', 'LDA_Intr', 'LDA_Pop', 'LDA_Rck'])\n",
    "\n",
    "LDA_fitted = LDA.fit(inputs_train, targets_train)\n",
    "\n",
    "y_pred_test_LDA = LDA_fitted.predict_proba(inputs_test)\n",
    "dfLDA_test = pd.DataFrame(y_pred_test_LDA, columns = ['LDA_El', 'LDA_Exp', 'LDA_Flk', 'LDA_HH', \n",
    "                                           'LDA_Inst', 'LDA_Intr', 'LDA_Pop', 'LDA_Rck'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QDA\n",
    "\n",
    "#PCA data preparation\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "inputs_train_sc = scaler.transform(inputs_train)\n",
    "inputs_test_sc = scaler.transform(inputs_test)\n",
    "X_train_sc = scaler.transform(X_train)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 200)\n",
    "pca.fit(X_train_sc)\n",
    "inputs_train_pca = pca.transform(inputs_train_sc)\n",
    "inputs_test_pca = pca.transform(inputs_test_sc)\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "y_pred_QDA = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    QDA = QuadraticDiscriminantAnalysis()\n",
    "    QDA_prob = QDA.fit(np.delete(inputs_train_pca, slice(i-840, i), axis = 0), \n",
    "                       targets_train.drop(targets_train.index[i-840:i])).predict_proba(inputs_train_pca[i-840:i])\n",
    "\n",
    "    y_pred_QDA = np.append(y_pred_QDA, QDA_prob, axis = 0)\n",
    "    \n",
    "dfQDA_train = pd.DataFrame(y_pred_QDA, columns = ['QDA_El', 'QDA_Exp', 'QDA_Flk', 'QDA_HH', \n",
    "                                           'QDA_Inst', 'QDA_Intr', 'QDA_Pop', 'QDA_Rck'])\n",
    "\n",
    "QDA_fitted = QDA.fit(inputs_train_pca, targets_train)\n",
    "\n",
    "y_pred_test_QDA = QDA_fitted.predict_proba(inputs_test_pca)\n",
    "dfQDA_test = pd.DataFrame(y_pred_test_QDA, columns = ['QDA_El', 'QDA_Exp', 'QDA_Flk', 'QDA_HH', \n",
    "                                           'QDA_Inst', 'QDA_Intr', 'QDA_Pop', 'QDA_Rck'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_QDA2 = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    \n",
    "    LDA_transform = LinearDiscriminantAnalysis(n_components = 8 - 1)\n",
    "    LDA_transform.fit(np.delete(inputs_train_sc, slice(i-840, i), axis = 0), targets_train.drop(targets_train.index[i-840:i]))\n",
    "    inputs_train_lda = LDA_transform.transform(np.delete(inputs_train_sc, slice(i-840, i), axis = 0))\n",
    "    inputs_test_lda = LDA_transform.transform(inputs_train_sc[i-840:i])\n",
    "    \n",
    "    QDA2 = QuadraticDiscriminantAnalysis()\n",
    "    QDA2_prob = QDA.fit(inputs_train_lda, \n",
    "                       targets_train.drop(targets_train.index[i-840:i])).predict_proba(inputs_test_lda)\n",
    "\n",
    "    y_pred_QDA2 = np.append(y_pred_QDA2, QDA2_prob, axis = 0)\n",
    "\n",
    "    \n",
    "dfQDA2_train = pd.DataFrame(y_pred_QDA2, columns = ['QDA2_El', 'QDA2_Exp', 'QDA2_Flk', 'QDA2_HH', \n",
    "                                           'QDA2_Inst', 'QDA2_Intr', 'QDA2_Pop', 'QDA2_Rck'])\n",
    "\n",
    "LDA_transform = LinearDiscriminantAnalysis(n_components = 8 - 1)\n",
    "LDA_transform.fit(inputs_train_sc, targets_train)\n",
    "inputs_train_lda = LDA_transform.transform(inputs_train_sc)\n",
    "inputs_test_lda = LDA_transform.transform(inputs_test_sc)\n",
    "\n",
    "QDA2_fitted = QDA2.fit(inputs_train_lda, targets_train)\n",
    "\n",
    "y_pred_test_QDA2 = QDA2_fitted.predict_proba(inputs_test_lda)\n",
    "dfQDA2_test = pd.DataFrame(y_pred_test_QDA2, columns = ['QDA2_El', 'QDA2_Exp', 'QDA2_Flk', 'QDA2_HH', \n",
    "                                           'QDA2_Inst', 'QDA2_Intr', 'QDA2_Pop', 'QDA2_Rck'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "y_pred_KNN = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "\n",
    "    KNN = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "    KNN_prob = KNN.fit(np.delete(inputs_train_sc, slice(i-840, i), axis = 0), \n",
    "                       targets_train.drop(targets_train.index[i-840:i])).predict_proba(inputs_train_sc[i-840:i])\n",
    "    \n",
    "    y_pred_KNN = np.append(y_pred_KNN, KNN_prob, axis = 0)\n",
    "    \n",
    "dfKNN_train = pd.DataFrame(y_pred_KNN, columns = ['KNN_El', 'KNN_Exp', 'KNN_Flk', 'KNN_HH', \n",
    "                                           'KNN_Inst', 'KNN_Intr', 'KNN_Pop', 'KNN_Rck'])\n",
    "\n",
    "KNN_fitted = KNN.fit(inputs_train_sc, targets_train)\n",
    "\n",
    "y_pred_test_KNN = KNN_fitted.predict_proba(inputs_test_sc)\n",
    "dfKNN_test = pd.DataFrame(y_pred_test_KNN, columns = ['KNN_El', 'KNN_Exp', 'KNN_Flk', 'KNN_HH', \n",
    "                                           'KNN_Inst', 'KNN_Intr', 'KNN_Pop', 'KNN_Rck'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y_pred_LR = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    LR = LogisticRegression(max_iter = 50)\n",
    "    \n",
    "    LR_prob = LR.fit(inputs_train.drop(inputs_train.index[i-840:i]), \n",
    "                       targets_train.drop(targets_train.index[i-840:i])).predict_proba(inputs_train[i-840:i])\n",
    "    \n",
    "    y_pred_LR = np.append(y_pred_LR, LR_prob, axis = 0)\n",
    "    \n",
    "dfLR_train = pd.DataFrame(y_pred_LR, columns = ['LR_El', 'LR_Exp', 'LR_Flk', 'LR_HH', \n",
    "                                           'LR_Inst', 'LR_Intr', 'LR_Pop', 'LR_Rck'])\n",
    "\n",
    "LR_fitted = LR.fit(inputs_train, targets_train)\n",
    "\n",
    "y_pred_test_LR = LR_fitted.predict_proba(inputs_test)\n",
    "dfLR_test = pd.DataFrame(y_pred_test_LR, columns = ['LR_El', 'LR_Exp', 'LR_Flk', 'LR_HH', \n",
    "                                           'LR_Inst', 'LR_Intr', 'LR_Pop', 'LR_Rck'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "y_pred_NB = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "    NB = GaussianNB()\n",
    "    \n",
    "    NB_prob = NB.fit(inputs_train.drop(inputs_train.index[i-840:i]), \n",
    "                       targets_train.drop(targets_train.index[i-840:i])).predict_proba(inputs_train[i-840:i])\n",
    "    \n",
    "    y_pred_NB = np.append(y_pred_NB, NB_prob, axis = 0)\n",
    "    \n",
    "    \n",
    "dfNB_train = pd.DataFrame(y_pred_NB, columns = ['NB_El', 'NB_Exp', 'NB_Flk', 'NB_HH', \n",
    "                                           'NB_Inst', 'NB_Intr', 'NB_Pop', 'NB_Rck'])\n",
    "\n",
    "NB_fitted = NB.fit(inputs_train, targets_train)\n",
    "\n",
    "y_pred_test_NB = NB_fitted.predict_proba(inputs_test)\n",
    "\n",
    "dfNB_test = pd.DataFrame(y_pred_test_NB, columns = ['NB_El', 'NB_Exp', 'NB_Flk', 'NB_HH', \n",
    "                                           'NB_Inst', 'NB_Intr', 'NB_Pop', 'NB_Rck'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    }
   ],
   "source": [
    "#Extratrees \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "indices = pd.read_csv('Downloads/RF_indices.csv', index_col = 0, squeeze=True).to_numpy()\n",
    "i = 190\n",
    "ind = indices[0:i :]\n",
    "inputs_train_rf = inputs_train_sc[:,ind]\n",
    "inputs_test_rf = inputs_test_sc[:,ind]\n",
    "\n",
    "\n",
    "y_pred_XTR = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "\n",
    "    XTR = ExtraTreesClassifier(warm_start = True, n_estimators = 840, max_features = None, min_samples_split = 2, \n",
    "                          random_state = 102)\n",
    "    \n",
    "    XTR_prob = XTR.fit(np.delete(inputs_train_rf, slice(i-840, i), axis = 0), \n",
    "                       targets_train.drop(targets_train.index[i-840:i])).predict_proba(inputs_train_rf[i-840:i])\n",
    "    \n",
    "    y_pred_XTR = np.append(y_pred_XTR, XTR_prob, axis = 0)\n",
    "\n",
    "dfXTR_train = pd.DataFrame(y_pred_XTR, columns = ['XTR_El', 'XTR_Exp', 'XTR_Flk', 'XTR_HH', \n",
    "                                           'XTR_Inst', 'XTR_Intr', 'XTR_Pop', 'XTR_Rck'])\n",
    "\n",
    "XTR_fitted = XTR.fit(inputs_train_rf, targets_train)\n",
    "\n",
    "y_pred_test_XTR = XTR_fitted.predict_proba(inputs_test_rf)\n",
    "\n",
    "dfXTR_test = pd.DataFrame(y_pred_test_XTR, columns = ['XTR_El', 'XTR_Exp', 'XTR_Flk', 'XTR_HH', \n",
    "                                           'XTR_Inst', 'XTR_Intr', 'XTR_Pop', 'XTR_Rck'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_2 = pd.read_csv('Downloads/indices_1.csv', index_col = 0, squeeze=True).to_numpy()\n",
    "i = 190\n",
    "ind_2 = indices_2[0:i :]\n",
    "inputs_train_rf = inputs_train_sc[:,ind_2]\n",
    "inputs_test_rf = inputs_test_sc[:,ind_2]\n",
    "\n",
    "y_pred_XTR2 = np.empty(shape = (0,8))\n",
    "\n",
    "for i in [840, 1680, 2520, 3360, 4200]:\n",
    "\n",
    "    XTR2 = RandomForestClassifier(n_estimators = 900, min_samples_split = 2, random_state = 2, max_depth = 30)\n",
    "    \n",
    "    XTR2_prob = XTR2.fit(np.delete(inputs_train_rf, slice(i-840, i), axis = 0), \n",
    "                       targets_train.drop(targets_train.index[i-840:i])).predict_proba(inputs_train_rf[i-840:i])\n",
    "    \n",
    "    y_pred_XTR2 = np.append(y_pred_XTR2, XTR2_prob, axis = 0)\n",
    "\n",
    "dfXTR2_train = pd.DataFrame(y_pred_XTR2, columns = ['XTR2_El', 'XTR2_Exp', 'XTR2_Flk', 'XTR2_HH', \n",
    "                                           'XTR2_Inst', 'XTR2_Intr', 'XTR2_Pop', 'XTR2_Rck'])\n",
    "\n",
    "XTR2_fitted = XTR2.fit(inputs_train_rf, targets_train)\n",
    "\n",
    "y_pred_test_XTR2 = XTR2_fitted.predict_proba(inputs_test_rf)\n",
    "\n",
    "dfXTR2_test = pd.DataFrame(y_pred_test_XTR2, columns = ['XTR2_El', 'XTR2_Exp', 'XTR2_Flk', 'XTR2_HH', \n",
    "                                           'XTR2_Inst', 'XTR2_Intr', 'XTR2_Pop', 'XTR2_Rck'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability matrix combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_train_t = pd.concat([dfXGB_train, dfLDA_train, dfQDA_train, \n",
    "                              dfKNN_train, dfLR_train, dfXGB2_train, dfXGB3_train, dfNB_train, \n",
    "                                dfXTR_train, dfNN_train],\n",
    "                               axis = 1 )\n",
    "pred_proba_test_t = pd.concat([dfXGB_test, dfLDA_test, dfQDA_test,\n",
    "                            dfKNN_test, dfLR_test, dfXGB2_test, dfXGB3_test,  dfNB_test, \n",
    "                               dfXTR_test, dfNN_test], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-level classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy IS:  0.6302380952380953\n",
      "Prediction accuracy OS:  0.6394444444444445\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter = 200)\n",
    "Log_reg_fitted = log_reg.fit(pred_proba_train_t, targets_train)\n",
    "print('Prediction accuracy IS: ', Log_reg_fitted.score(pred_proba_train_t, targets_train))\n",
    "print('Prediction accuracy OS: ', Log_reg_fitted.score(pred_proba_test_t, targets_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy IS:  0.6204761904761905\n",
      "Prediction accuracy OS:  0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "LDA_reg = LinearDiscriminantAnalysis(solver = \"eigen\", shrinkage = 'auto')\n",
    "LDA_reg_fitted = LDA_reg.fit(pred_proba_train_t, targets_train)\n",
    "print('Prediction accuracy IS: ', LDA_reg_fitted.score(pred_proba_train_t, targets_train))\n",
    "print('Prediction accuracy OS: ', LDA_reg_fitted.score(pred_proba_test_t, targets_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:13:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:13:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction accuracy IS:  0.9997619047619047\n",
      "Prediction accuracy OS:  0.63\n"
     ]
    }
   ],
   "source": [
    "XGB_reg = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=320,\n",
    " max_depth=7,\n",
    " min_child_weight=5,\n",
    " gamma=0,\n",
    " subsample=0.6,\n",
    " colsample_bytree=0.5,\n",
    " reg_alpha = 0.1,\n",
    " reg_lambda = 1,\n",
    " objective= 'multi:softmax',\n",
    " num_class = 8,\n",
    " n_jobs=-1,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "XGB_reg.fit(pred_proba_train_t, targets_train)\n",
    "print('Prediction accuracy IS: ', XGB_reg.score(pred_proba_train_t, targets_train))\n",
    "print('Prediction accuracy OS: ', XGB_reg.score(pred_proba_test_t, targets_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy IS:  0.5919047619047619\n",
      "Prediction accuracy OS:  0.6016666666666667\n"
     ]
    }
   ],
   "source": [
    "NB_reg = GaussianNB()\n",
    "NB_reg.fit(pred_proba_train_t, targets_train)\n",
    "print('Prediction accuracy IS: ', NB_reg.score(pred_proba_train_t, targets_train))\n",
    "print('Prediction accuracy OS: ', NB_reg.score(pred_proba_test_t, targets_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy IS:  0.7904761904761904\n",
      "Prediction accuracy OS:  0.6244444444444445\n"
     ]
    }
   ],
   "source": [
    "RF_reg = RandomForestClassifier(n_estimators = 50, max_depth = 10, class_weight = 'balanced')\n",
    "RF_reg.fit(pred_proba_train_t, targets_train)\n",
    "print('Prediction accuracy IS: ', RF_reg.score(pred_proba_train_t, targets_train))\n",
    "print('Prediction accuracy OS: ', RF_reg.score(pred_proba_test_t, targets_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:13:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:13:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction accuracy IS:  0.9997619047619047\n",
      "Prediction accuracy OS:  0.6238888888888889\n"
     ]
    }
   ],
   "source": [
    "XGB2_reg = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    "    n_estimators=320,\n",
    "    max_depth=7,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.2,\n",
    "    subsample=0.6,\n",
    "    colsample_bytree=0.4,\n",
    "    reg_alpha = 0.1,\n",
    "    reg_lambda = 1,\n",
    "    objective= 'multi:softmax',\n",
    "    num_class = 8,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27)\n",
    "XGB2_reg.fit(pred_proba_train_t, targets_train)\n",
    "print('Prediction accuracy IS: ', XGB2_reg.score(pred_proba_train_t, targets_train))\n",
    "print('Prediction accuracy OS: ', XGB2_reg.score(pred_proba_test_t, targets_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:22:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:22:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction accuracy IS:  0.9252380952380952\n",
      "Prediction accuracy OS:  0.6327777777777778\n"
     ]
    }
   ],
   "source": [
    "XGB3_reg = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    "  n_estimators=320,\n",
    "  max_depth=3,\n",
    "  min_child_weight=5,\n",
    "  gamma=0,\n",
    "  subsample=0.6,\n",
    "  colsample_bytree=0.5,\n",
    "  reg_alpha = 1,\n",
    "  reg_lambda = 1,\n",
    "  objective= 'multi:softmax',\n",
    "  num_class = 8,\n",
    "  n_jobs=-1,\n",
    "  scale_pos_weight=1,\n",
    "  seed=27)\n",
    "XGB3_reg.fit(pred_proba_train_t, targets_train)\n",
    "print('Prediction accuracy IS: ', XGB3_reg.score(pred_proba_train_t, targets_train))\n",
    "print('Prediction accuracy OS: ', XGB3_reg.score(pred_proba_test_t, targets_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:14:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction accuracy IS:  0.9997619047619047\n",
      "Prediction accuracy OS:  0.6322222222222222\n"
     ]
    }
   ],
   "source": [
    "XGB4_reg = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "         n_estimators=235,\n",
    "         max_depth=5,\n",
    "         min_child_weight=2,\n",
    "         gamma=0,\n",
    "         reg_lambda=1,\n",
    "         subsample=0.75,\n",
    "         colsample_bytree=0.75,\n",
    "         colsample_bynode = 0.75,\n",
    "         objective= 'multi:softmax',\n",
    "         num_class = 8,\n",
    "         n_jobs=-1,\n",
    "         seed=27)\n",
    "XGB4_reg.fit(pred_proba_train_t, targets_train)\n",
    "print('Prediction accuracy IS: ', XGB4_reg.score(pred_proba_train_t, targets_train))\n",
    "print('Prediction accuracy OS: ', XGB4_reg.score(pred_proba_test_t, targets_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xtra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy IS:  0.9997619047619047\n",
      "Prediction accuracy OS:  0.635\n"
     ]
    }
   ],
   "source": [
    "XTR_reg = ExtraTreesClassifier(warm_start = True, n_estimators = 840, max_features = None, min_samples_split = 2, \n",
    "                          random_state = 102)\n",
    "XTR_fitted = XTR_reg.fit(pred_proba_train_t, targets_train)\n",
    "\n",
    "print('Prediction accuracy IS: ', XTR_fitted.score(pred_proba_train_t, targets_train))\n",
    "print('Prediction accuracy OS: ', XTR_fitted.score(pred_proba_test_t, targets_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB simple Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:20:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction accuracy IS:  0.9614285714285714\n",
      "Prediction accuracy OS:  0.6344444444444445\n"
     ]
    }
   ],
   "source": [
    "from xgboost import cv\n",
    "from xgboost import DMatrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(targets_train)\n",
    "label_encoded_y_train = label_encoder.transform(targets_train)\n",
    "\n",
    "xgb = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " objective= 'multi:softmax',\n",
    " num_class = 8)\n",
    "\n",
    "xgb_param = xgb.get_xgb_params()\n",
    "\n",
    "xgtrain = DMatrix(pred_proba_train_t, label = label_encoded_y_train)\n",
    "\n",
    "cvresult3 = cv(xgb_param, xgtrain, num_boost_round=xgb.get_params()['n_estimators'], nfold=5,\n",
    "        early_stopping_rounds=25, verbose_eval = 25, metrics = 'merror')\n",
    "\n",
    "xgb.set_params(n_estimators=cvresult3.shape[0])\n",
    "\n",
    "xgb.fit(pred_proba_train_t, targets_train)\n",
    "print('Prediction accuracy IS: ', xgb.score(pred_proba_train_t, targets_train))\n",
    "print('Prediction accuracy OS: ', xgb.score(pred_proba_test_t, targets_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB simple Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:44:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction accuracy IS:  0.9997619047619047\n",
      "Prediction accuracy OS:  0.5722222222222222\n"
     ]
    }
   ],
   "source": [
    "xgbCC = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " objective= 'multi:softmax',\n",
    " num_class = 8)\n",
    "\n",
    "xgbCC.fit(pred_proba_train_t, targets_train)\n",
    "print('Prediction accuracy IS: ', xgbCC.score(pred_proba_train_t, targets_train))\n",
    "print('Prediction accuracy OS: ', xgbCC.score(pred_proba_test_t, targets_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAALjCAYAAAARCcMwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1RURxvA4R8iSy+iYkMsoNh7w2gSK2o0lth711iixqgx9p5ijN3YC/beG5bYY03siAqIIChKVXr5/lh2BXcXFgSNfO9zTs4xe++dnbl3dpl973tnDJKSkpIQQgghhBDi/1yuj10BIYQQQggh/gtkYCyEEEIIIQQyMBZCCCGEEAKQgbEQQgghhBCADIyFEEIIIYQAZGAshBBCCCEEIANjIYQQQgghABkYCyGEEEIIAcjAWAghhBBCCEAGxkKID+zSpUtMmjSJVq1aUa1aNcqXL0/t2rXp2rUrixcvJjAw8GNXUS///vsvAwcOxMXFhYoVK9KgQQMWLFjwUeu0aNEinJ2dcXZ25smTJx+1Lhnl5+enrrvqP09PT72PDwoKomzZsupju3Tpkm11ffjwYaaPTdnOP/74IwtrJYTICrk/dgWEEP8fbt++zZQpU7h7967GttDQUK5fv87169dZsWIFQ4cOZeDAgRgYGHyEmqbv1q1b9OjRg9jYWPVrz549w8TE5CPWKudxd3endOnSeu17/PhxEhMTs7U+sbGxLFu2jJUrV3Lnzp1sfS8hxMchA2MhRLY7cOAA48ePJy4uDgAXFxdcXV1xdHTExMSEoKAgLl68yK5du4iKimLevHn4+voya9asj1xz7VatWqUeFA8fPpy6desSGxtL8eLFP27FcpgTJ04wdOhQvfY9duxYNtdGed2XLl2a7e8jhPh4ZGAshMhWly5dYty4cSQkJGBmZsb8+fP54osvNPZr1KgRvXr1on///jx58oSdO3dSrlw5unXr9hFqnTZvb28AqlatyrBhwz5ybd4aPnw4w4cP/9jVeG958+bl1atX3Lt3Dz8/P+zt7dPcPzg4mGvXrgFgZGSk/gGW1RISEt67DHt7ex48eJAFtRFCZAfJMRZCZJuoqCjGjx9PQkICCoWCZcuWaR0Uqzg4OLBs2TIUCgUACxYsICIi4kNVV2+RkZEA6Q7YROY0aNCAXLmUf55OnDiR7v7u7u4kJCRQunRp7Ozssrt6QogcTAbGQohss23bNgICAgDo0KEDderUSfcYR0dHOnbsCEBYWBgHDx7M1jpmRlJSEgC5c8tNt+yQL18+qlSpAigHvelRpVG4urpma72EEDmfDIyFENlmx44dABgYGDBgwAC9j+vUqRMdOnTgt99+o3Hjxlr3CQ4OZtGiRbRr147q1atTqVIlGjZsyLhx4/jnn390lt2jRw+cnZ358ccfAbh8+TLDhw+nfv36VKhQgc8//5yxY8fi4eGR6riUswn4+/sDsGfPHvVrqvJ2796tfu3ixYs669GlSxecnZ1p2LCh1u0PHjxg8uTJuLq6UqlSJapWrUqTJk0YP348V69e1XqMPrNSfOjzllmqQe6NGzd49eqVzv1CQ0O5fPkyAM2aNdOr7LNnzzJ+/HhcXV2pUaMGFSpUwMXFha5du7JixQpev36dan/VNV28eLH6tXevO0DDhg1xdnZm0aJFPH36lH79+lGlShVq1qxJp06d1Kkh2mal+OWXX9SvjxkzRmu9X79+TYMGDXB2dqZy5co8fvxYr/YKIfQn4Q4hRLZ49uwZjx49AqBUqVIUKlRI72NLly7NzJkzdW4/ceIE48ePJzw8PNXr/v7++Pv7s3fvXrp168aECRMwNDTUWc6iRYtYsmSJOgIM8Pz5c/bt28eBAwf4+eefad26td71zio7duxgypQpGjmtvr6++Pr6snv3bjp16sS0adMyNHPHp3TemjRpwpw5c0hMTOTUqVN06NBBZ5vi4+NxcnLCyckpzTJfv37NiBEjOH/+vMa24OBggoODuX79Olu3bsXNzY0iRYpkqu6vXr2ia9euvHjxAlCmFHl4eFC0aFHCwsK0HjNy5EhOnz6Nt7c3+/fvp127dri4uKTaZ86cOTx79gyAH374AUdHx0zVTwihmwyMhRDZ4t69e+p/V6tWLcvKvXTpEiNHjiQuLg4jIyO6du3Kl19+iampKffv32ft2rX4+vqyadMm4uLimDFjhtZyzp8/T1BQEAULFqRPnz5UrlyZN2/esG/fPvbv309iYiJTp06lfv362NraYmdnx969ewEYMGAAQUFBNGjQgBEjRgBgbW2dJe3z8vJi2rRpJCQkUKxYMQYMGICTkxMJCQl4enqyatUq/P392bZtGzVr1qRVq1b/6fOWWUWKFKF8+fLcvXsXd3d3nQNjVRqFPtHin376ST0o/uKLL2jTpg0FCxYkKiqKhw8fsn79ep49e4a/vz+//vqrel7qhg0bsnfvXrZs2cK2bdsA1H1B23Xftm0bSUlJ9O/fn4YNGxIQEEBAQACWlpY6B8bGxsbMmTOHrl27qs/hgQMH1Pn2Z86cYefOnQDUrVuX7t27p9teIUTGycBYCJEtVJEtgMKFC2dJmfHx8UycOJG4uDhMTExYu3ZtqkF31apVad26Nf379+fGjRts374dV1dX6tWrp1FWUFAQJUuWZMuWLdjY2Khfr1evHtbW1ri5uREZGcnx48fp3LkzCoWCsmXLAqgHKzY2NurXssqhQ4eIi4vD0NCQDRs2ULBgQfW2GjVq0KhRI1q1akVYWBi7d+/Wa2D8Mc/b+3B1deXu3btcvHiR169fY2FhkWp7REQEly5dUu+bFg8PD/Ugunnz5syfPz/V9s8++4z27dvTokULnj9/zunTp9U/ImxsbLCxsSF//vzq/dO67omJifTt21dnSoQuVatWpVevXqxduxYfHx/+/PNPvvvuO8LDw5k4cSIAVlZWzJkz5z87x7cQnzrJMRZCZIs3b96o/51yAPU+3N3d8fPzA+Dbb7/VGok2Nzfn999/x8jICIA1a9boLG/kyJFa65YyOvk+q5xlxsuXLwEwMzMjb968GtsLFCjA8OHDGThwIG3bttWrzE/1vDVt2hSAuLg4zpw5o7H95MmTxMXFUbJkyXQXAnn8+DHFihXDyMiIIUOGaN3HwsKCzz//HICYmBiCg4MzXffM/igYOXKkej7slStX4uvry5w5c9RpGVOmTEn1Y0kIkbVkYCyEyBaq6baALJtXVhUdBGjfvr3O/QoXLqyOdl69epWYmBit+9WtW1fr6ymnYVNNzfahlChRAlBGQ0eNGqX1AasePXowevRovv76a73K/FTPW4kSJShVqhSgfXaKo0ePAvrNRvHVV19x/Phxbt26leYgOl++fOp/p1zZMCOsra0pVqxYpo41MTFh9uzZ5MqVi9jYWIYOHcru3bsBaNGiBS1btsxUuUII/cjAWAiRLVLmXoaGhmZJmaooZOHChVMNYLSpVKkSoBzc+Pr6amy3srLC0tJS67FmZmbqf8fHx2e2upnSunVr9S17d3d3WrRogaurKzNnzuTMmTM6B6tp+ZTPmypqfObMmVQD1devX3PhwgVA/9ko4O0PtqSkJAIDA7l8+TLbt29n5syZfPPNNyxfvly9b2aXmC5QoECmjlOpXr06PXv2BMDT0xMAOzs7pk6d+l7lCiHSJznGQohskTJiproN/L5UA2x9HupKmYag7YEnU1NTncemzN9MOfPCh5AnTx5Wr17NmDFj1Cuk+fj44OPjg5ubG6ampjRo0IDevXtTuXJlvcr8lM9b06ZNWbJkCZGRkVy4cIEGDRoAcPr0afUy3GXKlNG7vBMnTrBlyxZu3LihNaqd8k5HZpmbm793GaNGjWLfvn2EhIQAMHjw4Cx7wFMIoZtEjIUQ2aJChQrqQYZqud6MmD59Olu2bEk1H69qsKXPg0dZsXxvdkpr4Ojs7My+fftYt24dXbp0STVtWFRUFIcPH6ZTp06sXLkyQ+/1KZ63MmXKqH9kpUynyMhsFKCM/o4ZM4ahQ4dy/vx5IiMjMTAwoGjRojRo0IDhw4fj5ubGoEGD3rvOWfFg3MWLF9WDYoANGzYQHR393uUKIdImEWMhRLawtLSkSpUq3Lhxg8ePH/P8+XO9bzE/ffqUTZs2AcqB0b59+4C3D/Hp81BUyn2y6uE/fegbNX13EQlt5bi4uKjnsn3y5Annz5/nxIkTXLx4kaSkJObNm0ejRo0oWbJkmmV9CuctLU2aNGHVqlWcOnWKhIQEYmNjOXfuHKD/anebNm1i//79AFSuXJmhQ4dSo0YNjeju6dOns7bymRAWFsbkyZMB5ecoIiICHx8f/vjjD8aPH/+RaydEziYRYyFEtkk5a8LmzZv1Pm7Lli3qf3/11Vfqf6semvL3909zNTSAW7duAWBkZJTqobDslnJhDF0RvqSkJJ3pJTExMXh4eGjM6lCsWDG6devG2rVrGT16NKCMgqrybNPyKZy3tKjyjENCQrhx4wbnzp0jOjoaBwcHypUrp1cZW7duBZS572vWrOGLL77QmvKgWsL8Y5o1axZBQUEAzJs3jy+//BJQRo1v3LjxEWsmRM4nA2MhRLZRLaAAyum/Ui76ocuDBw9wc3MDlNNnpZz2KuVKYLt27dJZhr+/v3rAWKVKFUxMTDJV/8ywsrJS/1vXIOv27ds6F3po0KABrVu3Zvr06TrfQzWlGOgefKf0KZy3tFSqVEndj06ePMmJEycA/aPFgPpBwqJFi2rMh6wSGhqaahnvdx8g/BBzB//111/qOyQtW7bk888/Z9KkSZiampKYmMj48eMlpUKIbCQDYyFEtlEoFOon6WNjY+nXr1+aEc7bt2/Tv39/9ewD48aNSzXQbNKkiXqxkKVLl3Lz5k2NMt68ecMPP/ygHtT06tUrq5qjl5RTge3YsUNjyq83b94we/Zsncd/8cUXgHK6NF239Q8dOqT+d4UKFdKt06dw3tJiYGBAkyZNAOXA+K+//gIyNhuFKi3k0aNHBAYGamx//fo1o0ePTvWD5d1pBlULu0DqebqzSnh4OJMmTQKUkW1V2oS9vT1Dhw4FlA9iqlbkE0JkPckxFkJkqwYNGjB69Gh+//13goOD6du3L3Xr1qV58+Y4OTlhaGiIn58fJ0+e5NixY+qBWY8ePejYsWOqsnLnzs3s2bPp27cvUVFRdO/eXevSxqoH9tq2baseUH0ohQsXpmrVqvzzzz94eHjQu3dv+vTpQ758+fDw8GDdunX4+PhQtGhRnj59qnF8//79OXjwILGxsQwfPpyOHTvy2WefkS9fPoKCgjhy5Ih6YFy5cuVU0WBdPoXzlp6mTZvi5uamjvza29vr9aNAxdXVFTc3N6Kjo+nRo4d6qe2oqChu3brFtm3bNCL87+aBp5zqbuHChbRs2RJTU1OcnJzeo2VvzZ49W51iM2bMmFTv16dPH/bv34+npyfr1q2jadOmVK1aNUveVwjxlgyMhRDZbuDAgRQuXJhZs2YRHBzMxYsXU92yTsnU1JTRo0fTo0cPrdtdXFxYtGgRY8eO5c2bN6xbt45169Zp7NezZ0/Gjh2blc3Q28yZM+nRowfBwcFcv36d69evp9reu3dvrK2ttUb+HB0d+e233xg7diwxMTFs2rRJ/SBiSmXKlGHp0qV61+lTOG9pqVGjBnnz5lXnSGckjQLgu+++4/Lly3h6euLr66uOzKZUsGBB+vTpw5w5cwDw8vKiRo0a6u0uLi6YmJgQHR2tPn/VqlVLlROfWWfOnGHPnj0A1KxZU2Mhlty5czN9+nS6dOmiTqnYt28fxsbG7/3eQoi3JJVCCPFBtGzZEnd3d6ZPn06jRo2wt7fH1NSU3LlzY2trS61atfj+++85efKkzkGxSuPGjXF3d2fw4MGUK1cOCwsLTE1NKVmyJB07dmT37t1MmDBBvbzxh+bk5MShQ4fo378/JUqUQKFQkCdPHj7//HNWrFiR7swCzZo14+DBg/Tq1YvSpUtjbm6OkZER+fPnp169esycOZNdu3alu1jHu/7r5y0tuXLlonHjxur/z0gaBShzv7dt28bw4cMpU6YMJiYmGBkZYWtrS40aNRg7diwHDx6kW7du6rSLI0eOpCqjUKFCrFy5kmrVqmFmZoaZmVmmV8dLKSIiQj0LhUKhYPr06VrzmatWraq+i+Lt7S0pFUJkA4OkDz17vRBCCCGEEP9BEjEWQgghhBACGRgLIYQQQggByMBYCCGEEEIIQAbGQgghhBBCADIwFkIIIYQQApCBsRBCCCGEEIAMjIUQQgghhABk5Tvxicjb8/1Xlvovuru4ffo7fYKsTHLuV4vPy8iPXYVskd8yZ66gZqLImfGfVxHvv7DIf1VeS8XHrkK2sDT+cH3RtOqwD/ZeUf8s/mDv9SHkzG8MIYQQQgghMkgGxkIIIYQQQiCpFEIIIYQQOYuBxD0zS86cEEIIIYQQSMRYCCGEECJnMTD42DX4ZEnEWAghhBBCCCRiLIQQQgiRs0iOcabJmRNCCCGEEAKJGAshhBBC5CySY5xpEjEWQgghhBACiRgLIYQQQuQskmOcaXLmhBBCCCGEQCLGQgghhBA5i+QYZ5pEjIUQQgghhEAixkIIIYQQOYvkGGeanDkhhBBCCCGQiLEQQgghRM4iOcaZJhFjIYQQQgghkIixEEIIIUTOIjnGmSZnTgghhBBCCCRiLIQQQgiRs3xiOcZHjhxh3bp1PHr0CENDQ6pWrcrQoUOpVKlSmsf5+fnRqFGjdMuvVasWbm5uetVFBsYiRyhgbcL4byrRpHIh8lgYExASxYFrT5m79w6vo+MzXF6lYnkY2aocdUrnx8ZcgX9wJPuvPOX3fXeIjE1I9/hBrs7M7laNFjPduez5MjNNAuDVyyBW/7mIvy+cIzwslHz5C/BFw8b06v8tZubmGS7vxLHD7NzixuNHnigUxjiXKUeXnn2oWeczncd4etxj47pV3P7nOhER4dgVKMiXjZrSo98gTE3NMtWuoKAXLF28kPPnzhAWGoqdXQEaNWnKwMFDMDe3yHB5Rw4fZPPGDTz0fIBCYUzZcuXp3bcfLnXr6XX8Jrf1zP11DmvWb6JqteoZfn+V4FdBbFmzjOuXzxMRHkbefHbU+bwhnXoOxNQs49crpQM7N7Fmye/MWriachWrat0nKiqSXRtXc/HsSYKeB2BhYUXZSlVp27kXpcqUf6/3f/kyiFXLFnHpwlllX7QrwJcNm9Ank33R/eghtqfsi2XL0a1nX2rp6IszJo/n2OH9Osur5fIZ8xatyHA9Xga9YNnihVw4f1bdFxs2bkr/wUMwz0S7jh4+xJaNG3j0UNUXy9GzT3/q1NXertjYWLZs3MDxo4fxffKExKREHByK4dr8K7p074mxsXGG6wDK744NK5dw5dJ5IsJDyZvfjnpfNKZbn0GZul6n3Y+wZ/tGvB89RGGswMm5HB279qZ67bo627Vn+0ZOHTvEM7+nWNnYUL5iFTr37E9Jp9KZahPk3Ov1/2zZsmXMnz8fe3t7OnbsSHh4OIcOHeL8+fP8+eef1K9fX+exVlZWDBs2TOf2TZs2ERISQp06dfSuj0FSUlJShlogxEeQt+cWndvyW5ngPrUpRfOZE/w6Bt+g15QqbI25cW48/MJoNv04ERkYHLd3KcaSgXXIbZiLgOBIQiNjKVXIityGubjpE0yrWSd5E6O7vColbNk3viEWJkbpDozvLm6vc1vwq5cM7t2F54EBWFlbU6hwEZ54exMdHUXxEo4sXbMJcwv9B5Eb165k5dIFGBgYULykEzHRUTzz98PAwIDR46fQqq1mXdyPHGTOtAkkJCSQL78dlpZW+D7xJiEhgVLOZVm4Yj1mZpqDYysT3b+5X718SfeuHQkMeIa1tTWFi9jj7e1FdFQUJR2dWL9xKxYZaNfqVctZvOAPDAwMcHR0Ijo6Gj+/pxgYGDBx8jTate+Y5vF3795mQJ9eREVF6jUw9nkZqfX10OBXjB3Sg6DngVhYWVOgYGH8fL2JiY6maLGS/LxkHWaZGPQDPHpwj0kjBxAdHaVzYBwTHcWPw/rg89iT3EZGFClajIjwMIJfBmFomJshP0yiYbNWOt8jv6XuP+jBr14yoFfnFH3RnifeXsq+WNKR5Ws2Z6gvuq1dyfIl8zEwMKBESeU1e+avvGZjfprC1207aBzTt1t7PB/cp1yFShgaGmpsL1+xMsNGjtF43UShO2Pw1auX9OrakcCAgLd90UvZrpKOjqxxy1hfXLtqBUsWKvtiyeS+6J/cF3+aNJW27/TFyMg3DO7fh3t3bmNgYEAR+6IYGIC/nx+JiYlUrFSZpSvWYKrlM/YqIlZnPUKCX/Fd/268eB6ApZU1BQsVwfeJFzHR0TgUL8n8FW4Z+gG6dcNq1i5fiIGBAcVKOBITHU3AM+V3x3djJ9Hi629S7R8VGclP33/Lvdv/AmDvUBxDQ0OeeD/G0DA3P0ycQcOmLXS+X15LhdbXP+XrBWBp/OGyV03rTfpg7xV1fkamj3306BGtWrXCycmJbdu2qf+e3L9/ny5dumBtbc3x48cz9YNj8+bNTJs2jS+//JI///wTAz2j6JJjLD55iwfUpmg+c7Zf8Kb8d3tpNOU4Vb/fz2XPIMrYWzO1s/bomjaOBS1Z2L82uQwM+NHtGhVG7qPeT0eo99NhvJ5HULm4LaNaldN5fNUStmwd/QUWJkbv3a450ybyPDCAJs1bsuvwaVZs2M62/ceoUKkKPt6PWbbwd73Lunv7JquWLcTc3ILFq9xYt3UPW/YeZcK0ORgYGLDgt1kEPPNPdczTJz78MmMSiYmJfPfDeHYeOsm6bXtZu3UPReyL8vDBfTauzXiEbvLE8QQGPOOrll9z/NQ5Nm/bxaGjJ6lcpSpejx8x//df9S7r1s1/WbJwPhYWFqzdsJkdew5w4Ig7M2f/ioGBAT/PnsEzfz/d5+XObYYPGURUlPbBbkYs/GUKQc8D+aJJC9bsOMbc5ZtYvuUQZcpX5ukTL9b/OT9T5T70uMuMH4cTHR2V5n5rls7D57EnJUuVYanbXuav3s7qHcf4dvREEhLi+XPeLF6+CMxUHWZNm8DzwABcm7di75G/WO22nR0HjlOxUhV8vB6zZMFcvcu6c/smK5YuwNzcgmWrN7Jh21627zvKpOk/Y2BgwB+/avbFxMREnvh4Y2xswp9rNrFs9UaN/7QNitMzbeJPBAYE0LxlK46cPIvb1p0cOHqCSlWq4vX4MQvm/aZ3Wbdv/svSRfMxt7Bg9YZNbNu9n32HjzN99i8YGBjw65yZPPNP3a5Ff/zOvTu3KVHSkW2797P30DH2HDzG5u17cChWjNu3brJwvv6fc5W5sybx4nkAjVy/YvO+Eyxes4UNO49QrmIVfH28WLVknt5l3b9zi3UrFmFmbsG8P9ez3G0X63YcYuzkWRgYGLB03hwCA1K368+Fv3Hv9r9YWdswd8kaVm/Zx4qNu5m/3A0LS0t+mzGBx54eGW5XTr1e/8/WrVtHYmIiQ4YMSRVkKVu2LO3btycwMJCTJ09muNzHjx8zZ84cbGxsmD17tt6DYpCBsfjElStqQ+PKhXkRFs2oNVeJjU8E4FVEDH0XXyA6NoGun5cgXxrRsJTGf1MRYyNDlhz1YKX7Q/XrDwMimLjpBgCd6pXQemyvBo4cmNCI/FYm79kqePzwAVcunSePrS1jfpqKQqGMoNjksWXaz/NQKBQcObCHkOBXepW3ZcMakpKS6DXgWypUqqJ+vWmLVrTp0Jm4uDh2bkmdf7X6z0XExcXRqVsvvunUTf3FUqx4SYaOGgfA8cMHMtQuzwcPuHjhHLa2eZk4Zbq6Xba2tvz6+3wUCgX79u4h+JV+7Vq/djVJSUkMHDyUylXe/gD6qtXXdOzclbi4ODZt3KBxXFJSEju3b6Vf7+6EBAdnqA3a+Dz25J8rF7HOY8u3oydilNwua5s8jJn6K0ZGCk4d3U9oiP7vlZSUxLH9O5k4oj/hoSFp7hsTE81Z98MAjPxpJvkLFFJva9qyHTVc6hMXF8u5k0cz3LZHDx9w+eJ58tjmZeyEt30xTx5bZvzyBwqFgsMZ6Iubk/tin3f6omuLVrTr0IW4uDi2b0l9zfz9nhITE41DseLkypU1f7Yeer7tixMmv+2LeWxt+WWusi8eyEBf3LBO2RcHDB5Kpcpv+2KLll/TIbkvbtm4Xv16VGQk+/fuxsDAgGmzfqako5N6m1Pp0kyf9QsA+3bvJDo6Wu92eT3y5NrfF7DJY8uIcZNTfXdMnPEbRgoFxw/tIzREv3bt2LSWpKQkuvcdRLkKldWvN3JtSat2nYiLi2PPtk3q11+9DMI9OeVl7KRZVKzy9g5M2QqVGDD0exITE1m19A+92wQ593r9v7t06RIAn32mmbpSt64yTefixYsZLnfWrFnExsYyZswY8ubNm6FjZWCcwu7du3F2dtbrv3Xr1gHQo0cPnJ2defLkyQep4/Hjx/HwyPgv7azm5+eHs7MzXbp0+aj1aO9SDID9V3yJjkud+xsYGsXJW89Q5DbEtWqRdMsyUxjiWqUIUbHx/LH/rsb203cCmb3rFvP23yXXO78+3ac0ZV6fWhjnNuS3vXfwDXr9Hq2CE0eVg5wvG7libJJ6oJ0vvx216tYjPj6ei+f+SresyMhILp47g4GBAU2bt9TY/tXX7QA4c8pd/VpUlPIYhbEx3fsM0DimZp269B00jO59BpCQkH7OtcqRwwcBaNLUFZN32mVnV4DP6n1OfHwcZ86c1qNdbzh75jQGBgZ81fJrje1t2ilTQ066H9fY1qNrR2bNmEpsbCwDBg2hUOHCerdBm7PJA866XzTG2Dh1u2zz5ada7c+Ij4/n2sWzepc5dkhP/vxjNnFxsXToMSDVYPddr8PD+dK1JfUbNqNo8ZIa24sWdwTgVdALvd9fxf3oIQAaNGqqtS/Wrluf+Ph4Lpz9K92yIiPfcOHsXxgYGODaQjOt46vWqr54ItXrXo+VP1KLldBsW2YdTe6LjbT0xfx2dtStV5/4+DjO6t0Xle1q8ZVmu1q3VaYanDrx9jN29+4dYmJisCtQkHLlK2gcU6FSZaytrYmNjcXH67He7T9J4tUAACAASURBVDqd/AOpfoMmGn0xb347atZR9sW/z59Jt6yoyEj+vnAWAwMDGrl+pbHdtWVbAM6feXu9bv1zjYSEeOwdilPTRTPHv1GzlpiZmfPPtcsZ+qGYU69XtjEw+HD/ZVJcXBz+/v7Y2tpiZWWlsd3BwQFQRn8z4sSJE1y4cIEyZcrwzTffpH/AO2RgrEWZMmUYNmxYmv9VqVIl/YKy2Ny5cxk+fDjBWRDhel+qhPfMdLqsVK2k8pfgtcfaowTXvZSv1ymdP/2yHPNiZpyba49eERYZp7E9Nj6R3/fdZe2pRyS+k5pfzTEvjwLCaffLaX7efTujzdBw/56yjHIVtD+RW6688vVb//6TblkPPe6RkBBP4SL25LHV/OVc0qk0xsYmBL14TmDAM+X7371DTEw05StWxtLKWuMYhUJBr/6DadO+s9Z8T13u3rkFQMVK2j8/FSoq2/XvjevplnX/3j3i4+Oxty+KrZaIQKlSpTExMeH580CevXNr/u6d2xQrXpw/V65lyLDv9K6/Lg897gBQulxFrdtLlVX+Ib1/J/3rpfLI4y6FixZj6txldO37bZr75s1vx6CR4/l+0myt270eKn9MFyhsr/f7q9y/q+yL5StW1rq9XAVlm2/dvJFuWZ4e99Psi47JffHF80B1XwTwfvwIgOIlHDNcf13u3la2q2Il7e2qkNzem/+k3y6Pe/dIiI+niI6+6FSqNMbJfVGVJuLo6MSv8xYw6oexWstMSEggOiZG+e/ExPQblOzBPWVfLKvju6NMch+9cyv9vvjIU3m9Cha2xyaPZrtKOJbC2NiEly+e8zxQeb1ePA8AwMm5rNYyc+XKRaEi9iQlJfHwwf30G5Qsp16v/2ehoaEkJSVhba35NwZQD5YjIiIyVO7y5csBGDx4cIZSKFRkVgotypYty/Dhwz92NTS8fJn52Q2ympWV1X/iHBXLr3wK+YmOCO3T5Aelitul/0BGmSLKD+fDgHAAGlUqRNvaDhS2NSMgJIrtF7w5c/e51mNHrL7M1vPexCdkzbOsAcl5sYWKaI90FyikjHA+83+ablmqHNuChbWXlStXLuwKFOSprw/P/J5SsFBhfLyUAxGHYsq0kb8vnOO0+1GCXjwnn50dTZu3okZtl4w1CvDzU9a3iL32AZoqcvv0afrt8k8uq3AR7WXlypWLAgUL8sTHB7+nTymcov2Tps6g1ddtMDJ6/1xwgOfJfzwLFNR+ju2So72Bz3TnO79ryA+TaODakty5M1/HN68j2LVpDTev/Y11Hlu+aKL7gSddVP2nkI7+U7Cg8pqprkfaZT1NLkv3NVP1RX8/Xwom93PVwLhQ4SLs3bmNq5cv8vp1BIUK29PYtQU1aun/xLmKv3/a/Uf13n5PffUoyy+5LN2fsQIFCuL7RNkXCxUuQh5bWxo2bqqzzCt/XyImOhpDQ0McHIqlWweVwOS+WLCQjr6YfL0C0si9V1Hto6usXLlykd+uAH5PnxDg/5QCBd/eeUmI1/2AcnzytheBz3Tu866cer2yzQdc4CO96dJ05Qir+oGu72FVukxM8g8OfVy9epVbt25RokQJXF1d9T4uJRkYi0+abXLucMhr7R+c0DfKJ7dtLdLPMS5ia6Y+ZsW3dfnGJfWXW+d6JVhx/AHjN2pGJDae8cpQvdMTlpxTamVto3W7paXyl3R4aKjeZVnrKAvAMvmXeViYsrwXzwPVr0+bMIZTx4+k2v/Yof2069SVET/8lO77pxQaEppmXaySo9OqeqRZlqpdNrrbpS7vnfPU7hvNWQ/eR0RyfS11RD7MLS2T9wvTu8wmX7XNdH08791m6e8zCPB7SmxsDEWLOzJqwiyd/SktYemc53f7TlpCQ9O+/qnLe3uuVKkUc3+eTlRkygclL3Nw3y5atGrLuInTMnT3QtUXbXS0yyoj7QrRpy/qX158fDxLFipzcGu71FWfE32EhSnrYqnjHFuovjv0qIeqrlY6+nXq8pTXSzWI9n78UOv+sbGx6sH769f6RwJz6vX6f6aaaSIuTvMOLSj7CqB15iNdtm/fDkDnzp0z/TyCDIyzyePHj1m6dCl///03YWFhFChQgKZNmzJ48GCN2wZJSUns2LGDnTt38ujRIxQKBc7OzgwcOFCdkO7s7Kzev0+fPgA8ePCAy5cv07NnT0aPHk1AQAB79+7FyMiI7777ju7duwPw119/sX79em7dukVsbCwODg60aNGCvn37Ympqqi73xx9/ZM+ePZw9exY3NzcOHTpEUFAQhQoVok2bNgwaNIjcuZVdRjWpdrVq1diy5e1Uavq0JSuZKpR/CKN0zC0cHav8RWpslP4HxDx5irFeDZywNjNi2rZ/2XjmMXHxibSu7cCc7tUZ2NSZhwHhrDn5KItaoJ3qF/K7OYIqqi+U2Nj0f0mrylLoKEu5LXV5qsHHgd07eP06gkHDRtGidTuMchtx+sRRFs79md3bNuNQrCRtO3TWs1XKh8QAjE20/1BRt0uPCEF0tHIfkzSm8VGVF6PHeXofqvOmUGivi0KhPPexcbqn2MpKvj6PeeL1to+GhQbz77VLlMjE/LHp98XktsWk37bYdK6/srzUfSA+Po6nvj4AFChYiOGjxlKpSjViYmI4feIYSxfM5fCBPeS3s2PAt/qnxaj7oo7+o6pjjB7tUpVlksZnTJWfrU/0a+7Ps/C4f4/cuY0YMnxkuvunFKu+Xml/xuJi9b9eijQ+Y+9+d1SpXgsjhQI/Xx/OnjrO5w1TR1kP7N6qPl/xOgZE2uTU65VtPmDEODOzRgBYWlpiaGioM1UiPFx591Zb/rE2sbGxnD59mly5ctG8efNM1Qkkxzhb/P3337Rv355jx45Rs2ZNevfuTfHixVmzZg0dO3bUyBEeOXIkkyZNIigoiJYtW9K8eXPu379Pv379OHRI+eDLsGHDKFOmDACtW7fWmNB6/fr1uLu707lzZ2rVqqXOgV68eDGDBg3i9u3bNGzYkE6dOmFgYMDChQvp1q0br19rpiAMHTqUXbt2Ub9+fTp37sybN29YuHAh8+enP92UPm3JSgmJaacu5MqlzC/SJ8HB2Eg5yM5racxve++w8NB9gl/HEhEdz8YzXkzdqpyT84fWFchtmL2rCqX3S1eV46xP/pTqHKQlKfk8GqDcV/VHLiwslJ79BtO1Vz9sbPJgbmFByzbt+fa70QBsWLWM+Hj9/7jlypV2RC8pSZmbp1+70v/6SkzO9VO1K7ukVxd1u7K1Fm/VcPmczYfOsXrnMQaO+JHY6Gg2LF/AtvUZn15P77bp0TgDPf5YJ73Tt2NjYuncvTfNW7Zm2eqN1Haph6mpGTY2eWjbvjNjJkwFYMvGdeq7CPpIty8m6v8Z06tdifr17aWL5rNz+1YAho0YRZmyuqeH1Cbd7w5V/qs+7dLjM/bu9bK2yUOb9l0B+GPOVI4d2kvkmze8jghn/66trF2+SP3cgirQoo+cer3+nxkZGeHg4MCrV6948+aNxnZfX2VajJOTk8Y2ba5cuUJERAQ1atSgQIECma6XRIy1uH//PosWLdK53dLSkt69e2vdFhMTww8//AAoQ/rlyr39kGzZsoWpU6cya9Ysfv9dOdfhwYMHOXr0KC4uLixevFg9OXmfPn1o27Yts2fPxtXVleHDh+Pv74+Hhwdt2rRRT2OiEhwczMGDB3F0fPtwys2bN1m0aBEODg6sXbsW++S8zvj4eCZOnMiePXuYO3cuU6dOTVVWREQER44cUd+y6tmzJ82bN2fbtm2MGDFCZz6Qvm3JyJdheiJjElDkNsTESPuXpiK38vVoPVarU+0TG5/A4sOaM3+s/+sRkzpWpoCNKZWL2aof7MsOJqZmvI4I1xk5VUV70ooCq6hWp0sruhyXHMlURUlUUcDcuXPTpUcfjf1btWvPiqXzCQ5+hafHfZ0PCWrWxZSIiDid7YqNjUt+//RTX1S319KKBqtu0aUVocwKxiamxL+O0BmFU51ffa5XVrDJYwuAqZk5zdt0xNLKmt9njGfv1vV81a6z+va3PtLri6rbnboiyimpFj5IKwr3tjzlNTMzN2fwsFE692/arCWrli3mmf9Trl+9TKMmzdKtB7zti7oijO/WIy1mGWqX9vOUlJTEgt9/Y+OGtQB06tqd7r00P3vpMTE15XVEhM4IvvozoUe7VN8daUWX1d9Firft6jVwGIEB/pw77c682VOYN3uKelvTr1pjamrGvp1bMrTgTU69XtlGj4DIf0GtWrXw9vbm0qVLNG7cONW2CxcuAFCzZk29yrp+XfnQtotLxp9/SUkGxlp4eHikOSVakSJFdA6MT506RVBQEP369Us1KAbo0qUL69at4+jRo0ybNg0LCwv27t0LKNMYUq7Y4+DgwPjx4wkLCyMyMjLdWwmlS5dONSgG2LlzJwCjRo1SD4pBOdj56aefOHnyJHv27OGnn35SJ7mDMjcnZR6Xg4MDjo6OPHjwgJCQEOzs7LTWIavakhEhr2OwMVdgY6F9pSTb5NdfRaR/Oyw8SvkHw+fFa42p3wDiE5LwfvGaSsXyYJ/PLFsHxlZWVryOCCc8XHtOqio/MK0cORVV3muEjrLgbR6dKvdTtYpZYfuiGlN0AeTObUThIkV55OlBYMAzvQfG1tbWRESEp8ofTVWP5BxUmzx50i1LlfcYnkberiqn1cYm/fLeh4WVNW9eRxARob0uqtzizOT4ZoV6DV1Zs/R3Ql69xOuhB5Wq1dL7WCsr63T6ovJ1ffqiKuc7rb74tm/rf81KlHTkmf9TngcG6H2MVXJfDA/XnkOq+kxkqC/q8RmzyaN5nhISEpg5bTIH9u4GoEOnLvwwLmP5+yqWlta8jkirL6ryhvX47lDNCpDW9QrXvP5GRkZMnDmXi2dPcfaUOyEhr7ArUJCGTb+iao3azJn6I4DWmUl0yanX6/9dhw4d2L59OwsWLKB27dpYJj+P4eHhwa5duyhYsKDGgFmX28kzl1Stqv+iXtrIwFiLtm3b8vPPP2fqWNWF8fb21hp1NjQ0JD4+ngcPHlC9enXu37+PmZlZqhxilfbtdS8X/K6iRYtqvHb3rnIuXm2/tqysrHB2dubq1at4eXmp0zQAihcvrnV/0J0kD2RZWzLiUWAEJQpYYp/XnGuPNAeq9nmVs1b4vEh/XuHHgco8p7QWSVfdhsyq2Sd0KVqsBM/8/XgRGABapjZTDQCK2Gte93epZpbQNWhITEzk5Qvl/LaFk8sr6lAcSPs2oqGh8nZkRu4AFCteAj+/pwQGBlAZzS+vgOSn1O2LOqRbVvHiynYFBuhuV9AL5SwiRfUo730UKVqM58/8ePk8EMprTielWnGuYCamS9NHQkI8LwKfkZiYRJGi2p+Iz1+gECGvXqofptOXQ7Hi6kFnhTT7Yvrn2KFY8eRjtK/Ap7xmL5LLS923Y2JidEYDVXmuGeuLxfH3e0pgQECqBR5UVP3KXo/PWDE9+uKL5HbZv3Oe4uPimPDjGE66HwOgR+++jPg+46v4qdg7FCfgmfK7I+WCHCqqB2sLF0m/XfbJ3wOqY96VmJionhu7kJby6n7ekLqfN9R4XbXqnUMGpt/Lqdcr23zAHOP3UbFiRfr06cOaNWto1aoVzZo14/Xr1xw8eJD4+Hhmz56tDtyFh4ezfr1y0RVts2Kp1pMoUUL7Ilz6+jTO3CdElSx+6tQpFi9erPGfaqJqVcQsNDQUc3PzTM21l9K7E54D6vxh1S+wd6lycKKiUi81q+2Pj6p+SWmMGrOqLRnxr7cyX1s1n/G7qjsqX7+hR3T3H2/lPiUKWGBpov0PbLH8ykiq70vNfKis5Fy2PKCcT1gb1dyyZXTMm5tSCUcnFAoFfr5PtD4F/vihJzEx0eTLb4ddgYKp3t//qS9vtOShJyUlpTsNnDaqifHv3L6ldfudW8rXK1RIv12OTqVQKBQ8eeKj9eGNh54PiI6OJr+dHQUKFtS7jpnhWFp5d+ihh+bCMACe95XXsVSZ8tny/sf272JI9zYs/0P7PMYAL5LnBc5jmy9DZZcpp6zzvbva5+e+lzw3dVktix68q2TyNXvq66OjLz7Q6It7d22ngUsVhg3spbNcr0fJC4AU1/8Poqov3r2jvV2qPlq+Yvp3Q5yS2+X7xIfXOvpijI6+OHPaZPUg69thI957kFWqjLIvPriv/bvDI3mOdOdy6V+v4iWdMFIo8H/6hDdarpf3I+V3R958+clvl/z3JDKSg3u2s2/nFo39AQID/Hn6xBvbvPnUP8D1kVOvl4Bx48Yxc+ZM8uTJw+bNmzl58iS1atVi8+bNqR7aDw8PV4+ltAkODiZ37tzkz5/+ugVpkYFxFjM3V0Yo//jjDx48eKDzv4YNG6r3f/PmjdYBZ0xMTIZWFXuXKp3h+XPtc++qBue6pr/JqOxsiy6HrysHZ+1qO2jMPFHQxpSGFQsRFRvPoevpz9n5wD8cz2dhKHIb0rOBZrJ/29oO5LEwxv/VG24/yVjULaPqf6nsH6fcj2jkwb0MesGVS+dRGBvzeYO0548EMDExpUbtuiQmJnL04D6N7YcPKG8HNmr69ineEo5OOBQvQXx8PAf27NA45pT7ESLCw8lvV4BSpctobNelQUNlfY8dPazRrhcvnnPxwjmMjY1p0KhJumWZmppSp+5nJCYmcmD/Ho3te/fsAqBZc80Vu7Ja7XpfAnD+9DGNXO7gl0H8c+UiCoUxtetrRs+yQoUqNQC4e/OG1rmSL545QWjIKywsrXDW48dUSvW/VF6zk8e198XL6r6Y/u1OExNTaib3xSNa+uKh5OvY2PXtfMulnMsQFxfHg/t38fXx1jjm6t8XeeLjhbW1DVWq6ZeLCPBl8mfnuJa+GPTiBZdUfbGhHu0yNaW2i7IvHty/V2P7/uRb7q7NUvfFbVs2qfcfOXos/QYO1rv+uqgitGdOHNXIC38V9IJrly+gUBhrjeS+y8TElOo1XUhMTMT9yH6N7ccOKev+ZZO33x0KhYLVyxawbP4vWlda3LFpHQDNv/4mQ0GUnHq9ss0nsPJdSh06dGDPnj3cunWLS5cusWLFCipVSv0jx97eXj2G0ub69evcvXs3Q9M2aiMD4yxWtqxytZ9bt7RHxJYuXcqyZcvUuY/Ozs5ERkbi6empse/cuXOpXLky165dA/R72jYlVY7z1atXNbbFxMRw8+ZNzM3NKaJjkvOMykhbssqtJyH8dSeQQrZm/DnIBbPk6dtsLRSsGfYZJgpDtp7z1sgxLm5nQalCluocZJU5u5TRiPHfVKRt7be30MoXtWFmV+Xtu4WH9F+tKbNKlylH9Vp1eBn0glmTfyQqSjl9WmhoCFN+/J7Y2FiatWytfshKxd/Plyc+XhpP53fp2ReAVUsXcP3K3+rXjx8+wN4dW1EoFLTr1C3VMX0HKWc+Wb18MSePH1a//sjTgyV//AZA1179MtQvy5YrT+06dQl68YIJ48eop4ULCQlh7OiRxMbG0qp1W2xtU7fr6VNfvL28CAlJ3a7effoDsHjBfC7/fUn9+qED+9m+dTMKhYLOXbvrXb/McixdlsrVaxP8Moj5syYSnXwXJjwshN+mjiUuLpYGzVpp5M0G+D/Fz9eb8LD3+6HlUMKR6rXrkZiYwNxp41INju/8e10dSe7YcwBGCu35+Lo4lylHjVouvAx6wYxJ41L1xUnjRhEbG0uLlm3Io2df7NpL2RdXLJnPtRR98djhA+zesQWFQkH7FH2xfIVKVKhUhcTERCb/NBp/v7cLOPx74xrTJo0DoPeAb/V68EqlTLny1KrjQtCLF0waP1bdF0NDQhj3g7Ivtvy6DXne6Yt+T33x8fZSz4Wr0qtPPwCWLJzPlRR98fDB/exI7oudur5tV2hICIvnzwOUSxBn1YNbpZzLUrVGHV69DOKX6T8RnXy9wkJDmDlpDHGxsTRp8bXGd8czv6f4PvHWSLXp0K03AGuXL+Kfa5fVr588dpADu7dhpFDQun0X9euGuXPjUu8LkpKSmP/LdN68Ud5xSkhIYPdWNw7t3YGVtQ1tOqb+vklPTr1e4r9HcoyzWOPGjbGxsWHTpk00b96cypXf5ngdPnyYBQsWULx4cQYNGgQo85mvXLnCb7/9xqJFi9TzCvv5+bFv3z4sLCzUZajy59LK803pm2++YceOHSxZsoQ6deqkmpVi1qxZhIeH06lTp1QP3r2PjLQlK41ac4UjkxrzdS0HPi9fEJ8XEZQqbI25cW5uPwlh8hbNpU/3jGuAQ34Lftlzm1/3vL3luP/qU+YfuMfIVuVYNfQzJnesTFhkHOWKWmOYKxd7Lj9h9UntE9dntTE/TWVo/x6cOeXO9auXKWJvzxNvb6Kjo3Aq5cyQET9oHPP9kP4EBjyj94Bv6TNwqPr1SlWq0a1XPzatX833Q/tTvIQjcXGx6tXKxkyYpl45SqVBY1ceetxj0/rVTJ8wlhWL52NhYYnX44ckJibSoLErbdrrP4exyqQp0+ndswsn3Y9z5e+/sS9aFG9vL6KjoijtXIbvR2suuTqof28Cnj1j0LdDGTzkbW5Z1WrV6dNvAGtXr2TwgD6UdHQiLjaWp8mrX02eOjPVinfZ6dvRExk/vA+Xzp7k1o0rFCxsj5+vNzHR0RR3LE3vwZozK0wZPZig5wF06jWQzr3fL/o0bNxUJo0awGPP+wzr2Y7CRYsRHx9HQPJAstnXHWjVPmODEZWxE6bybb/u/HXKnWtXL1PEvihPvL2UfbG0M0NHavbFEd/2IzDgGX0GDKHfoLd9sXKV6nTv3Z+N61Yxckg/ipd0JC72bV8cN3G6Rl+cMvNXhg3sxSPPB3T9phUOxYoTFx+Hn68yp7B1u4506JzxH0ATJk+nX6+unDpxnKuXk/uil7JdpZ3LMFJLX/x2QB8Cnj1jwOChDBrydtrMKtWq07vfANatXsmQgX0p6ehIbGyceiW2iVNnpFo9cM+uHeofGR7379Gvl+5rM+bHCRmaBmzkuEmMGtyb83+d4N/rlylUuCi+T7yIiY6mpJMzA4d9r3HMjyMG8jzwGd37DqZHv7dLkFeoXI1O3fuybeMafhwxEIfiJYmLiyMgeSW6H36ckmrFO4DBI8Zy88ZVrlw6R/c2TSlc1IGXL54TGhKMmZk5M39fon4QMyNy6vXKFp9IjvF/kQyMtUhvujZQzkzRrl07jdctLCz49ddfGTZsGF26dKFhw4YUK1aMx48fc+bMGczMzPj555/Vc022bduWkydPcuLECVq3bk39+vWJi4vj8OHDvHnzhhUrVqinRytUSLms7MKFC7l27RpDhw7VeP+UqlatytChQ1myZAlt2rShYcOGWFlZcfnyZTw9PSlfvjxjx2pf9z0zMtKWrOT78g0NJx9jXLuKNK1cmHJFbXgRFo3bX4/5Zc9tIvWYqi2lGTtucunBC75tVoaqJWyxtTDmlk8IG/56zIa/Hmd5/XUpVMSelW7bWbN8CX9fOMvjh57Y5s1Hyzbf0HvgEPVUSvoaOGwUJUs5s2vrRnVOZuWqNejaqx91Pquv85hKVauzffMGHty7S1hYKKWcy9KyTXtatW2fqXzyIvb2bN62iz+XLOLcuTM89PQkX758NPymA4O/Haae0ktf340cTanSzmzZ5MbDh8q7FdWq16BPv4HUq/95huuXWQUKFWHu8k1sXfsn1y+f54nXQ2xs89HkqwZ07j0YkxSL6WQHmzy2/Lp0A3u2buDiX+4E+PuiUBhTqVotWrTtRO16DTJdduEi9qzeuIPVyxdz6fxZHj98gG3efLRq+w19Bw7NcF8cPGwUjk6l2ZGiL1apVoNuvfrjoqUvFipchLWbdrJx/WrO/XUKv6dPMDYxpVqNWrRt35kGjTO39GsRe3s2bt3J8qWLOZ/cF/Pmy0fbRu0ZmIm+OGzE9ziVcmbrpg08eqhsV7XqNejVdwCfvdMXb/77dgXNBx5p34XSNt98WgoWtmfxmi24rV7GlYtn8X7sSZ68+fisVSN69BuMSQavV99vR1DCqTR7t2/C20vZropVqtOpe19qutTT2N/K2oaFKzexYfUyrl46h/ejh1jb5KFJ86/p2nug+iHfjMqp10v8txgkpfU01f+Z3bt3M378eL32rVWrFm5ubvTo0YMrV65w/PhxihV7+zS4h4cHK1as4PLly4SFhWFnZ0eNGjUYNGiQxrRqCQkJbNq0id27d+Pl5YWhoSGVK1dmyJAh1Kr1dlql0NBQxowZw5UrVzAyMmLr1q28evWKnj170qpVK+bOnau1ridOnGDDhg3cuXOHxMREHBwcaNmyJb17904VLVatfLd27VqNeZJV7Tx58iT29vY6V77Tty0Zlben9gc5PnV3F2fPbB0fm5WOhxdzAp+Xkenv9AnKb5m9cz1/LCaKnBk5exXxYVZR/BjyWmbNXcz/GkvjD9cXTZv88sHeK8p93Ad7rw9BBsbikyAD40+LDIw/PTIw/rTIwPjTIwPjT0PO/eslhBBCCPH/SHKMM03OnBBCCCGEEEjEWAghhBAiZ/mAC23lNBIxFkIIIYQQAokYCyGEEELkLJJjnGly5oQQQgghhEAixkIIIYQQOYvkGGeaRIyFEEIIIYRAIsZCCCGEEDmL5Bhnmpw5IYQQQgghkIixEEIIIUTOIjnGmSYRYyGEEEIIIZCIsRBCCCFEziI5xpkmZ04IIYQQQggkYiyEEEIIkbNIxDjT5MwJIYQQQgiBDIyFEEIIIYQAJJVCCCGEECJnkenaMk0ixkIIIYQQQiARYyGEEEKInEUevss0OXNCCCGEEEIgEWMhhBBCiJxFcowzTSLGQgghhBBCIBFjIYQQQoicRXKMM00GxuKT8HBZx49dhWzhMv3Ex65Ctjg1vsHHrkK2sTYz+thVyBbh0XEfuwrZwjCX4mNXIVsY5sq5t8qjYxM/dhWyhaWxDFY/BTIwFkIIIYTISSTHONPk4w6vawAAIABJREFU54sQQgghhBBIxFgIIYQQIkcxkIhxpknEWAghhBBCCCRiLIQQQgiRo0jEOPMkYiyEEEIIIQQSMRZCCCGEyFkkYJxpEjEWQgghhBACiRgLIYQQQuQokmOceRIxFkIIIYQQAokYCyGEEELkKBIxzjyJGAshhBBCCIFEjIUQQgghchSJGGeeRIyFEEIIIYRAIsZCCCGEEDmKRIwzTyLGQgghhBBCIBFjIYQQQoicRQLGmSYRYyGEEEIIIZCIsRBCCCFEjiI5xpknEWMhhBBCCCGQiLEQQgghRI4iEePMk4GxyBFeBgWxYtlCLp0/S1hYKPntCvBlwyb0HTgEc3PzDJd3/Oghtm3ewKOHnhgrjHEuW47uvfpR2+UzvY6PjHxDt/ZfExgYwL4jp7ArUDDDdQDIb6lgRNNSfFEmHzZmCp6HRXP8znOWnHjMm9iEDJX1S8cKtKleROf2cw9e0n/N9TTLMFMYcvD7zyiSx5TPZ//F87CYDNVB5dXLINYuX8zli+cIDwslX3476jdoQs9+gzHLxPU6eewwu7ZtxOuRJwqFgtJlytGpe19q1qmbar+jB/fy64xJepU5dtIMmrVsk6F65NR2pSX4ZRAbVi3l2qXzhIeHki+fHZ992YgufQZhZpbxNqe0d/tGViycy29L1lK+ctUsqnFqOfW749XLINatWMyVS+cJDwslb3476n/ZmB59M9cXTx0/zO5tG/F69BCFsYJSzuXo1L0PNWrX1bp/YmIiB3Zv5+jBPfj6eGOQy4DiJRz5qnV7mrVqm+mB28uXQaxatohLF84qP2PJ16tP/28z1S73o4fYvsWNx488USRfr249+1KrjvbrNWPyeI4d3q+zvFounzFv0YoM10P8d8jAWHzygl+9ZECvzgQGBmBlbY2jU2l8vL3Y7LaWSxfOsnLdFswtLPQub/2aFfy5eD4GBgaUcHQiJjqaa1f+5vrVy4ybMJXW7TqkW8byJQsIDAx4n2aR10LBtqF1KJLHlJA3sXgGRlDSzpx+X5Tg8zL56bTkb97E6D84LlXQEoB/fUNJSEjS2O75PCLdMka5lqJIHlP9G6FF8KuXDO3XjReBAVhZWVPCsRS+Pt5s37SOyxfPsXjVxgxdr83rVrFq2QIMDAwoXtKR6Ohobly9zD/XrjDqx8m0bNNevW8e27xUqKR7gBURHsYTHy8AChXW/SPi/6ldaQkJfsWoQT0Jeh6ApZU1xUuW4ukTL3Zt2cDVS+eZt3wDZub6tzklT4+7bFi5JMvqqk1O/e4ICX7F8AHdeRGovC7KvujFjs3ruXLpPAtXumGegeuyef0q1vy5EAMDA4qVcCQmJpp/rl3m3+tXGDluEl+1bp9q/8TERGZM/IFzp09gYGBAocL2ADy4fxePe3e4+c81fpwyO8PtCn71kkG9u/A8+XqVdCrNE28vtiRfr+VrNmfoermtXcnyJcnXq6QT0dHRXL/yNzeuXmbMT1P4uq3m9fJ+/BCAchUqYWhoqLG9pGOpDLdL/LfIwFh88mZM+YnAwACatWjF+MkzUCgUhIQEM+774dy++Q+L5v/GjxOn6VXWnVs3Wb5kAeYWFvyxaAUVK1cB4Oih/cyY8hO//zKTWnXqpjm4uHvnFju3bX7vdv3csQJF8piy78YzJuy8Q1xCEnnMjVjasyrViudh7FfOTNl9T6+yDAygZH5zomIT6Lz0Mkma4+J0VbS3pltdh4wf+I5fZ0zkRWAAjZu15IcJ01AoFISGBDNp7Aju3vqX5Yt+5/vxU/Qq697tm6z+cyHm5hb8vGAZ5Ssqr5f7kQP8Mn0ii+bOpkYtFwomX6/adetTu259rWUlJSUx9ruBPPHx4pvO3alcraa0Kx3zZk0m6HkADVy/YuS4KRgpFISFBDP9p1Hcv32T1Uv+YPhY/SLZKXnev8OUMcOJjorKsrpqk1O/O1L2xe/HT1X3xSnjRnL39r+sWDSPUT9O1quse3dusnb5IszMLfj5j2WUq1gZgBNHD/LrjIks/n0O1Wu5ULDQ23a5HznAudMnMDO3YNbcRVSsUh2Af65dZtLY7zhx9CA16/yPvfMOi+r4GvAL6gIiICioFBWpdqPGbjT23rvYe0s09hp7NOrPGjXGLnZjb7FFY0VT7IoFkSqg9LogfH/c3aXsLrtg55v3eXgevXPvuXP2nLk7e+6ZM3Vp3Lx1jvRaMGc6Ia+Cad6yLZNnzlXZa9r4Mdy7e5tfVi5l0vTZesm6f+8OG9auxNS0EMtW/0qFSpK9/jh5jAWzp7H85wV8XTOzvVJTU3np+wIjI2PWb96JoeHnu0xLpFLkns/XqgKBHjx74s2Na1ewtCrC5BnSZATA0tKKBT8vRyaTceLoIcLD3+glz3PbJtLS0hg0dKTqiw2gRet2dO7Wk+TkZPbs3K71+pSUFBbNkyYI74Jb8UJ842bN65gkZv7+gGRFhDciLpnvPe+QlPyWTtXssDLV7z4lrQpiIsvHi7C4XE2K8xkaML9zeeQpqTm/OAPPn3pz8/pVLC2tGD/1R5W9Clta8ePCZRSQyTh9/DARetprj+cW0tLS6Dt4uGryCNC0ZVvad+lBcnIyB/Z46iXr8IHd/HPzBvYOpRgycqzQSwcvnj3hH6+rFLa04rtJM1U+b2FpxbR5Syggk3H25BEiI8L1lpmWlsbJwweYNGoQUZER762vmsirzw6fZ0+4dUOyy7jJszL54swFSykgk/HHCf19cZ/nVskXBw1XTYoBmrRoQ7vOki8ezOKLF86cBKBn30GqSTHAV9Vr0r33AECaWOeEZ0+98VLYa9L02ZnsNW+xZK+Txw7prdeu7ZtJS0tjwJARqkkxQPNWbenUVbLXvt2Z7RUY4E9SUiIlS5X+rCfFgnfjs7TswYMHcXNz0+tv69atn7q7euHl5YWbmxsTJkz41F3JEXK5nA0bNvD2bc7yWTPSqFEj3NzcSElJeY89kzhz+oR0jybNMTY2ztRmbW1Drbr1SUlJ4cpfF3XKio+P48rlixgYGNC8VVu19rYdOgNw8cJZrTI8t23i2VNvBg4ZkQMt1GlTpQQAp++FkJRlMhoak8Rf3q+R5TekUTlrveS5FJdeLz4PjctVfwY3KI27rRm/nH+eq+uVnFd8YX7TuBlGWexV1NqGGrXrkZKSwvUrl3TKSoiP5/rlSxgYGNCkRRu19lZtOwFw+U/t9lISGRHOprWrABg9fgoyIyOd12Qkr+qVHRfPngKg3rdNMTLKrHORojZUr1mXlJQUvK7q1lnJuKEerFk6n+RkOT37D8WmeIn31t+s5NVnh9IXGzTS4ou1JF+8oa8vXpF8UVN0t2XbjgBcvngu0/HXYaEAOGpIK3BxKwtAWOgrPbRJ56zCXt9qGWM160j2uqqnva7+pd1erdtLY+zShcx6+SjSKEo5lslR3z8FBgYGH+0vr/FZToyVuLu7M3r06Gz/qlSpolvQZ4CdnR2jR4+mWbNmn7orOcLDw4Nly5aRlpsw40fg4f17AFSoWElje/kK0vG7/2W/qAzA+9Ej3qakYGtnj5VVEbV2J2dXjIyNCQ15RXBQoFq7v58vWzaux8nZlV4e/XOghTqVHCwAuOMXqbH9jn8UAFVLW+olz6WYcmIcm+O+lCpSkJGNnfAOjmHLX745vj4jjx/cB6T8PE2ULV8RgHu3/9Up64n3Q96+TaGEnT2WGuzl6OyCkZExYaEhvAoOylaW5+YNxMfHUb1mHWrUrqfz3lnJq3plh/cjSWf38pp1disn6fzg7n96y3zy6AF2DqVYsOJX+gwe+e6dzIa8+uzwfijpVVaLL7orfPG+HnZ5qvRFWy2+6JTuiyEZfLGoTTFAil5n5aWv9OO6qHUxnffPyKMHkl7lM0StM1KugqTX3Tt6jLHHj3j7VrKXJr2cnF0xMpLslXGMvXj+DIDSjk456rtAN6dOnaJ79+5Uq1aNGjVqMGzYMO7evZsjGefOnaNPnz5Uq1aNatWq0blzZw4dOkRqas7edH7WOcZly5ZlzJgxn7ob7wV7e/svUpfXr19/6i5kS2CgPwAl7Ow1thcvYSudF+CvU1aQQpatFlmGhoYUK1Ycv5e+BAb4q+UKLp4/h2S5nMnTZ5O/QAG9ddCEvVVBAALCNedYBkVIx0ta6bcQThkxDoxIoEdNe+q4FMXcJD8B4Qkcvx3MjefaX3fP7VQOWT5DZh18QErqu/1ACg4KAFAtxslKseKSvZS2yFZWoFKW5pxNQ0NDrIsVJ8DPl6BAf5UvZOVVcBDHDu0DYMDQUTrvq7EveVSv7Hil0LmYlvsro71KffThu8mzaNKyLfnzv9v40Ye8+uwIDpQm3hlzfjNSTGEXvXxRMYkvnq0vFiPA7yVBgf4qX2jZpiP/eF1jr+cWKlapSsXKVQEpd3739k0AtO3YLQdaQZCOcVG8eM7tpW28GhoaYlOsOP5+vgQG+Kl8QTkxLmFrx+EDe7nldY3Y2BhK2NrTpHkrqteolSOdPihfUCB33bp1rFixAnt7e7p160Z0dDQnTpzgypUrrF+/nvr1Na+fyMjy5ctZv3491tbWtG/fnrS0NM6ePcuUKVN48uQJkydP1rs/n/XEWCDQhTIP0cKisMZ2MzNz6bwozZHXjETqkJWdvKOHf+efv73o1LVHpvzC3GJpKn05RsYna2yPTpDSUgrrmWOsjBjP7lgOU6PMw75rDXt+vxXAjN8fkHXe2+VrO2o5F2HXdT9u+0XlRAWNKO1lbmGhsd3MXPp8o6N03ysqUrKBublue0VnY/8jB/aQnJxM+UpVtEbZdPclb+qVHcp7m2sZL4UUfYzRY+wpaaFIE/kY5NVnR1SU0hezt4t+vpi9LG3yGjZpTmhIMNs3ruWHEQOwtXPA0NCQAP+XmBYqxNjJs6jboJF+CmXpi0VhLfYyz4m9pHOytZdKXrpeylSKpYvmkhAfn+FsL44f+Z1WbTsyecYcjdUqBJp59uwZq1atwtXVlb1791KwoBQU8vDwoGfPnsyYMYMzZ85glE0a2PXr11m/fj1ly5Zly5YtWFpKb1LHjh1Lp06d2Lx5Mz169KBUqVJ69emzTqXQl9OnT+Pm5sa3335LXFzmHMrRo0fj5ubGmjVrgPT85RMnTuDp6UmzZs2oVKkSLVq0YMOGDRrzYCMjI1m8eDFNmjShQoUK1KlThx9++IHnzzPnWyrziDds2MCcOXP46quvqFGjBp6enhpzjKdMmYKbmxshISEsXryYb775hkqVKtGhQwcuXLgASK8GOnXqROXKlWncuDErVqxALper9fHSpUv079+f6tWrU6lSJdq3b8+OHTvUXiH06dOH6tWrExERwaxZs6hXrx4VK1akTZs27Ny5U02XQEX0oXz58vTp00fVHhoayqJFi2jVqhVVqlShYsWKNG3alPnz5xMR8WEXzWQkKUmqo6tt0Chz0TR9ZjmVlUleUrq88DevWbNiCUWLWjNi9Dj9Oq4D4wLSgzUxWXNut/K4UX7dQzi/oQGli0r1PYMiExm06W+qzDhHrTkXmH3oIXFJKXT+2p4xTZ0zXVekkIyJrdwIjU5k2emn76KOCrniM5ZlyUlVovzs5XLd9ZHlSYkKWdnYSykvSbP95XI5p48fBqBzDw+d99Tel7ypV3ak66xl7Kl01j32PgV59dkh16WXkVIvfXxRD720yLOzL0lxWzvS0tIIDPDD38+XtLQ0CpmZ56ikmpL0z1jbGFP/fLWhHGNGxvqMMem+KSnJ+Pv5AlLUfdnqXzl7+RbHz11h/JSZmJiYcPLYITZv+LAlBvXlS8kx3rp1K6mpqYwcOVI1KQYpY6BLly68evWK8+fPZytj8+bNACxatEg1KQawsLBg/PjxdO3aNdMPHF3kiYlxixYtaNu2LUFBQSxfvlx1fP/+/Zw9e5Zq1aoxYkTmBQ2bN29mwYIFlC9fnu7du5OWlsayZcsYPXp0pnza0NBQunTpwubNm7G1taVv377UrVuXs2fP0qVLF/75Rz3/bNu2bZw9e5YePXpQo0YNnXnQw4cP59SpU7Ro0YIWLVrg7e3N6NGj+fnnnxk7diyOjo706tULuVzOunXr2LhxY6brf/vtN4YOHYq3tzfNmzend+/epKamMn/+fMaOHauWH5ySkkKfPn24cuUKzZs3p2PHjgQFBTF37lx2794NpOdEm5lJtW9HjhxJx47SQouQkBA6derEjh07KFOmDB4eHnTq1Am5XM6OHTsYNGiQLpO9N3StDE7LQW6RoR4DXPlDI+Op//t5ITHR0YydOJVCis/rXXmrI2VB2Vd9Ur+N8huy5bIvB/8OpOdaL648eUNC8lsi4pPZfcOfWYqSbwO/KY1lwfTXuDPauVO4YAEWHH1MbOL7WTipy16pCr31edga6LEqPDVN3V4ZufznWaIiI6SNOBo01ilPG3lVr+zQqXOa/jp/CvLqs0OnXkrf0eNdu4Gh7nPSVHqln3to305+nDKW8DdvmDZnEcfO3+DwmSuMnzaH6KgoFsycxOH9u3XKzojeeunhbgYGusdYWhb/lSfJ6eHRn5Zt2rNukyc1a9fDxKQghQtb0rFLDyYqysTt9tyqeoMg0M3169cBqFtXfUOVOnWkzWOuXbum9fqkpCSuXbuGs7Mz7u7uau2tWrVi/vz5VKqk/1uzzzqV4tGjR6xevVpru5mZGf379wdg1qxZ3Lp1i507d9KmTRusrKxYuHAh5ubmLF26VO3Vxv3791mzZg1NmzYF4IcffmDEiBH8+eefHDt2jHbt2gEwZ84c/P39mTdvHt26pedEDRw4kO7duzNx4kTOnDlD/vzpH2V4eDjHjx/HySk9Qd/Ly0urHrGxsRw9ehRzxasbGxsbfvvtNzZt2sSmTZuoV09aNNO9e3eaN2/OkSNHGDlSWpjy8OFD/ve//+Hq6sr27dtVv5YmTpzIxIkTOX78OPv378/U94SEBMzNzdm/fz8mJlKOatu2bfHw8MDT05OePXuqcqIPHTpETEwMo0aNUum4YcMGwsLCWLx4MR06pO+glZiYSOvWrXnw4AFPnz7FxeXDFzo3MSlITEy01qiO8njWVcwaZSl26couQpScRd7Vy5c4f/Y0deo1oHHTFjnqe3YkyN8iy2+oNSIsUxzXFlHOSJz8Lf/LJuJ7/HYw3zdzpmSRgtRytuLU3RAauBelVeUS/PkolNP3QnKnhAaMTUyIjYnRGq1KTlZ8vnpUTzAxkaIL2dsrWSFPs/0v/ylFIup/24R8+XP/OMyremWHsbEJsbExqjGh3kfp+PushPE+yavPDl2+KM+BXdJ9UXt0WZ6cWV5kRDgb164EYOb8JXxVvabq3JZtO2JpacWMiWPYuHY5jZq10pp+lBVjk4LExkSrIrhq/VB+vlrGREZMFJHJJC2yMsuT9CpoasrwbKL6zVq0YeO6NQQF+vPPLa/3atPc8Ln+IM1IcnIygYGBWFlZqeY/GSlZUqqbn/XtfEaePn1KSkqK6g336tWruXz5MjExMTg5OdG/f3/at2+fo3591hPjx48f8/jxY63tdnZ2qomxubk5P/30EwMHDmT27NkULFiQ+Ph4VqxYga2t+uKQunXrqibFACYmJkydOpV27dpx6NAh2rVrx+vXrzl//jwVK1bMNLEEKczfvn179u3bx9WrV2nQoIGqzdXVNdOkWBfdunXL5BTVqlXjt99+o1y5cqpJMUDp0qUpUqSIKr0BpKh4amoqEyZMyPQKwdDQkEmTJmmcGAP0799fNSkG+PrrrzEzM+Ply5c6+9u6dWtcXFxUPx6UGBsbU6VKFQICAggP17926btgbmFBTEy01nw5ZR5k4cK6qzeYm1sortH+ykWZv2ZR2JL4+DiW/DQHExMTJkyZkdOuZ0tUQjIWBQtgUVDzQpzCBbPPQc4pz0JiKVmkICUKm1BQlo/ZHcsRl5TC3MOP3ot8JWbmFsTGxBATnb29LCx028tMYS9tsjLJ05CXmJKSzD83FdGKHOY7aupLXtQrOwqZWxAbq13nmGjdeZyfkrz67Ej3xWiN7Up7Weihl9IXo7XIAohR6Kz07b+9rpGUlIhr2fKZJsVKatVrgJOLG8+fenPrxhW9N/kwN7cgNiaaaK1jTKmXbn8zz9EY06/yD4BjGSeCAv0JecedC780GjfO/q2UtlSIyMhI0tLSsNDy40g5L4qJ0b4ra0iIFLgJCwujY8eOFC5cmBYtWhAbG8u5c+eYNGkSPj4+jBunf6rSZz0x7tixI4sWLdL7/Dp16uDh4cGOHTsA6Nq1Ky1bttR4bq1a6qtH3dzcMDU15eFD6dXygwcPSEtLQy6Xa4xcv3ol1WF8+PBhpomxg4OD3n0GcHR0zPR/ZZ6NJjnGxsa8eZNewPzePamEzeXLlzWWNjE2NubRo0ekpaVl+gVZunRptXPNzMyydUAlVatWpWrVqsTGxuLt7Y2fnx9+fn48evRIFRnPaXmU3FKyVGkCA6QHkaaFK8qtVe3sddukpOIz0bYda2pqKmGK+pz29g48fviAEIUPdGrTVOM1AO1bSpOTXzZspWr1Gjr7AfAiLE41UdW06K1EYSkq4vcmXq1NG7L8hlo36FDWSk55m0oFe3NsC0s/mv6c2kDj+QB/TWsIQJ9fb3LTR79Xhw4lSxMcGEDoq1coqkZlIlTxedrqYS+HUqWla0K020tZT9XWTl3evdv/ERcXi5m5OZUzbEKQG/KqXtlhX7IUr4ICCA15RdkK6iW0QkMknYtr6OPnQF59dih9MSQkONOGHEqUkzZtFTSyygIIy0YvlS/aS/LCQqWJir2D9oVODqUcef7UW3WuPpQsVVo16cy4IYeSEJW9dO/OWVIxxpQ2yEpqaiphoaEKeZntn5SUpPXNjzJqnv8DvaXJCV9CxFi5pquAlkosyk1csovsK9eV3bx5k4YNG7Jq1SqVffz9/enatSvr16+nUaNGVK6sudRfVj699d4zLVq0UE2Mq1XT/qVQooTmwvGFChVSlShTJmt7e3vj7e2tVVbWpO6sxeJ1kTHhPCMyPXZAUv6SV+qsjbi4OAplWPCgaWDrO5BiY2NZsmQJhw8fJjFRWsRgZWVF5cqVKVmyJI8fP/5odY/dy1Xg+tXLPHxwlybN1X8EPbwv/Vgop2m2kgUnJxdkMhn+fr7ExsSo5fw9e+pNUmIiRa1tsClWnIiIcCpVqapV3l1Fzdqy5StSoECBHC04uR8QTQN3ayo5WHDqrvrDu3JJ6Rf2XX/dCwq617RnRruyPAqKptsvmlN6XBXl3HzC4ohJTOGfF9onutUcLVX3Tk5JJSYH+cduZctz8/oVHj+8x7caXjU+eiDZy71cBZ2yHJ2cKSCTEeD3ktjYGAoVymwvn2dPSEpKpIi1DdbFimu9V/lKX71zukFe1Ss7XNzL8/eNqzx5eJ8GjZurtSvr6bqVLf/B+vAu5NVnh6u75IveD+/zbRN1X3ystEs53XqVVvqivw5fLGqDtY3kiwVNpbSSiDfaS32GK9pMtHz3acK9XHluXLvMwwf3aNxMu73Kltc9xso4Z7CXBr2eP/UmKSndXgCHf9/HyqULcXZ157dtezTK9Xmm2ACktKPG9ryKrsVx2lDOQ5KTNb/5VKazaJsjAZnSZGfPnp1pbuPg4MCQIUP4+eefOXbsmN4T4zyx+E5JUlISs2bNIn/+/JiZmfHTTz+pwuxZUU7oMpKWlkZMTIwqJcFUMcB79uypmhxr+psyZcqHU0oHyj5eu3Yt2z4WysUqYG1MmjSJPXv20KhRI7Zt28a1a9dU5VLKlPm4OwI1aCi9wjn7xym1X5VhYaHcuHYFmZERDRo10SnL2MSEGrXqkpqayknFiv6MHD9yEICmLVoB4OZejl83e2r9U7Jo6Up+3eyJm3s5vfU690Dy29aVi6vyiZXYmBlR37UoiclvOftAd8TlUVAMsvyGVLC3wLGo+gOmjksRnGwKEREn56ZPBI+CYui1/qbWPyWjd/xHr/U3eRSk+y2DEuWr/QtnT6vlCr4OC+XmjavIjIyo11D3gjFjYxOq16xDamoqZ04cVWs/dewQAI2aan5r9OyJlKb1PiZueVWv7Khd/1sA/jqvrvOb16H843UNmcyIOt98uHSOdyGvPjvqNpDs8qcWX7x14yoymRH19EizMTY2oXqN2qSmpnL2pLovKiufNMrwY7CS4i3FvTv/qmoPZyQowJ/His06KuXgjUZ9hb3On1G31+uwULyuS/b65ls97GVswteKMXbq+BG19hNHpTHWpHkr1TEXN3eSk5PxfvQAP98XatfcunGNl74+WFgUpkrVr/XW64Nh8BH/comZmRn58uXT+qZaGfjTlH+sRDm3sba21hjwrFBB+qHk6+urd7/y1MR42bJlPH/+nIEDBzJt2jSioqKYNm2axnPv3LmjduzRo0fEx8erflWULSttXalt95UTJ06wYsWKbPOgPzTKPmrSJzY2lgULFuDp6anWlluio6O5cOECdnZ2LF++nFq1alGkSPrOQc+eSQXQP1bE2K1sOb6uWZvXYaHMmTGZhAQptSAyIoLpk8Yhl8tp3bYDlpZWma4L8PfD94UPkVlKy3n0GwjA+jUruOV1XXX89Imj/L5vNzKZjK7de39greBhUAxXn76mmIUxS3pUxERRvs2yYAFWelTGqEA+Dv0dSERc5l/aDlYmlLE2zVRd4q5/FP++jCCfoQHLe1fGIcOmINUdLVnaQ4oc/XLuudZUi/eFq3s5qtWoxZuwUBb+OFVlr6jICOZMG0+yXE7z1u0pnMVegQH++Pn6qGqZKunhMQCAjetW8u+tG6rjZ08d48iBPRSQyejYrZfGvih35XJycRV65QJnt7JUqV6TN6/DWDJvOokJ0qYzUZERLJw5kWS5nCat2mGRRefgQH/8X75Q0/ljk1efHS5u5aj6dS3evA7lpzmZfXHe9Akky+U0a91OzReDAvzx81W3SzeFL24RdyWZAAAgAElEQVRavyqTL547fZyjv0u+2KFrui86OrlQu14DUlJSmDXpO176+qja/F++YM60H5DLk6hdv6HGLaO14eZejuo1JHvNm5nBXpERzJws2atVG3V7BQb48dLXR61SRC+FvTb8soK/b6br9cfJYxzcL9mrSwZ7la9QiQqVqpCamsqsaeMJDPBTtd3+92/mzJQ2kOg/ZIRei2wFUgpFyZIlefPmjVqpXQA/P+kzdnZ2VmtTogzGaSq1m/F4dlHnrOSZVIobN26wfft2HB0dGT16NEZGRhw/fpwrV66wc+dOevfO/EA6evQoXbp0UZVSi4uL46effgJQLVSztbWlbt26XL16lW3bttGvXz/V9T4+PsyZM4fY2Fi6dOnykbRUp0uXLvz+++8sWbKEihUrYm1trWpbtmwZu3bteqf+KXN/UlJSyJ8/PzKZDENDQxISEoiNjc0Uid6wYQNPnjxRnf+xmDJjDsMG9ObP82f4++YN7Owd8H3hQ2JiAi6ubowZN1HtmjHDB/IqOIhBQ0cyePho1fHKX1Wjz4DB7Niyke9GDMKxjBNyuVy1m9LUmXO17rz0vpn1+0N2j6xBi4rFqe1UBP/weMrYmFJQlp9HQdEsPqG+3erWIV9jb2XC6rPPWHMufSXvhN132TGsBmVtzTk1oR4vwuIokM8QR2vpjcOeG/7suOanJu9D8MPUH/luSF/++vMs//59A1s7B/x8X5CYmICTixvDvxuvds2E0YMJCQ6i7+AR9B+SvlVwxSpV6dl3ELu3b2LC6CGUcnQiOVlOkMJek6fN1roznPJ1ro2NejqC0Es/vps0iwkj+nP14jnu/O1FcTsH/F/6kJSYSBlnVwaP+kHtmqnfDyX0VTC9BgzDY9AIDVI/Hnn12TFuyizGDuvH5T/P8d/fXgpf9CExMREnFzeGjVH3xYljhhDyKog+g4bTL8N23BUrV6VHn0Hs2bGJSd8NlXxRLlftHjdp6my13Q8nzJjHpDFDef70MYN7daRk6TKkJCcTFOhPWloaTi7uTJg+N8d6TZo+mxGDPLh44Sx/3/LCzt6Blwp7Obu6MWrsBLVrvh8xiFfBQQwYMpJBw9J3gKxcpRoe/QfjuXUjY0cOonQZSS+lvSbPmKs2xn6c/zOjh/bj2RNvenVuS8lSpUlOSSbAT1q03r5TN7p+oLrhOeVLyDEGqFGjBi9evOD69es0aZI52n/16lVAKg6gDQcHB+zt7QkICOD+/fuqCLESZdBQUyk3bXzWE2Nd5dpAqkzRrFkzpk6dCsD8+fNVv9bmzp1L27ZtWbJkCXXr1s204Ewmk+Hh4UHz5s0pXLgwFy9eJCAggO7du9OwYUPVefPmzaN3794sXLiQP/74g8qVKxMZGcnp06eJj49n+vTp2NvrXsTwoahatSojR45k7dq1tG7dmkaNGmFpacmtW7e4d+8eZcqU4Ycf1L+c9KVEiRL4+voyadIkqlWrRr9+/WjZsiXHjx+nU6dOfPut9Nru5s2bPHz4kKJFi/L69euPusmHrZ09W3YeYOP6NVy9colnT70pUrQo7b7twuDho1Qlh/Rl5JgfcHZxY9+uHTxX5IxVqVqdvgMGU7vuNx9CBY0ERCTQadV1xjR1pqG7Na7FzXgdm8T+m4GsPvuMBD1KtSkJjEik48rrDGnoSJPyNpQuakqC/C03nr1h1w1//niPJdl0UcLWnvXb9rJ1wy/cuHYZn2dPsCpSlFbtO9N/yIgc22vIqLGUcXbl4N6dvFDsTFXpq2r07DuImnU0byX69u1b4mJjAShibfNuCinIq3plR3FbO1Zt2oXnpnXcun4Z3+dPsLQqSp22jeg9cDjGJvptWf6pyKvPjhK29qzdsodtG9fidVXyRcsiRWnVrjF9B+fcFweP/J4yzi4c3LcTX6UvVqlGj74DqVFb3RctLAqzcsM2Du3bxcVzp1UTxzLOrjRs0oKO3XphbJxz37C1s2eT5342/bqG61f+4vlTb6yKFKVtx84MHJpzew0fPQ4nZ1f27/FU5QdXqVqd3v0GU7uuul4lbO3YsvMAnts2cfniBQL8X2JkbELV6jXo2KUH3zZRz7UXZE/Xrl3Zt28fK1eupGbNmqq9Ex4/fszvv/9O8eLF1SbMWenTpw8//fQTc+fOZfPmzaqA3YsXL9iyZQvGxsaZSsvqwiDtY73zzgEHDx5UTXR1UaNGDezs7Dh06BAeHh7MnDkzU/u2bdtYuHAhVapUYdeuXRw5coSpU6cybNgwChUqxO7duwkPD8fJyYlevXppjK6Gh4fz66+/cv78eV69eoWFhQXu7u4MHDgwU1FqLy8v+vbtS9u2bVm6dGkmGZrapkyZwqFDh9iyZYuqkLUuOY0aNSIwMFBtMeD58+fZsWMH9+/fJzk5GVtbW5o1a8aAAQMonKF8TZ8+fbh58yZnzpxR2x5Rk+z79+8zbdo0fHx8KFGiBGfPniU+Pp7169dz6tQpQkJCKFy4MKVKlaJr167Y2trSu3dvWrZsyYoVKzLJffDgQa5X64bH6T8J/JKoPffcp+7CB+HC1G8/dRcEOUSfmthfIpYF9ds2/UsjLunjvZX72Ch3/sxrWJt9vFhk8SEHPtq9Xv32bm/NFy9ezObNmylRooSq1Nrx48dJSUnh119/Vc2zoqOj2bZtGwBjxoxRXZ+amsqYMWM4d+4cxYoVo1mzZsTFxXHmzBni4+OZO3cuXbt21bs/n+XE+EOinHQPHz48R3XtBJ8WMTH+shAT4y8PMTH+shAT4y8PMTHWzv79+9m1axfPnz/H1NSUihUrMnr06Ew71gUEBKhqJmcNDr59+5b9+/ezf/9+nj9/ToECBahYsSJDhgyhdu3aOerLZ51KIRAIBAKBQCDIGV9KjrGSrl276ozq2tvbay2dmy9fPnr06EGPHj3euS95qiqFQCAQCAQCgUCQW0TEWCAQCAQCgSAP8aVFjD8n/t9NjDt16kSnTp0+dTcEAoFAIBAIBJ8Z/+8mxgKBQCAQCAR5GhEwzjUix1ggEAgEAoFAIEBEjAUCgUAgEAjyFCLHOPeIiLFAIBAIBAKBQICIGAsEAoFAIBDkKUTEOPeIiLFAIBAIBAKBQICIGAsEAoFAIBDkKUTEOPeIiLFAIBAIBAKBQICIGAsEAoFAIBDkLUTAONeIiLFAIBAIBAKBQICYGAsEAoFAIBAIBIBIpRAIBAKBQCDIU4jFd7lHRIwFAoFAIBAIBAJExFggEAgEAoEgTyEixrlHRIwFAoFAIBAIBAJExFggEAgEAoEgTyEixrlHRIwFAoFAIBAIBAJExFggEAgEAoEgTyEixrlHRIwFAoFAIBAIBAJExFggEAgEAoEgbyECxrlGTIwFXwQFjfJ96i58ELxmN/nUXfgglKjz/afuwgfjjdfqT92FD0JE/KfuwYfBULwX/eIwlgmjCT4dYmIsEAgEAoFAkIcQOca5R/wsEwgEAoFAIBAIEBFjgUAgEAgEgjyFiBjnHhExFggEAoFAIBAIEBFjgUAgEAgEgjyFCBjnHhExFggEAoFAIBAIEBFjgUAgEAgEgjyFyDHOPSJiLBAIBAKBQCAQICLGAoFAIBAIBHkKETDOPSJiLBAIBAKBQCAQICLGAoFAIBAIBHkKkWOce0TEWCAQCAQCgUAgQESMBQKBQCAQCPIUImCce0TEWCAQCAQCgUAgQESMBQKBQCAQCPIUhoYiZJxbRMRYIBAIBAKBQCBARIwFAoFAIBAI8hQixzj3iIixQCAQCAQCgUCAiBgLBAKBQCAQ5ClEHePcIyLGAoFAIBAIBAIBYmIsEAgEAoFAIBAAIpVCIAAgLCyUX1av5Mpfl4iMjMSmWDGaNG3GsBGjMDUt9Mn69TosjF/XruLalb+IiozE2qYY3zZuyqBhIzE1Nc2xvD9OnWDvzu08e/oEmcwI93Ll8Og3iFp16mo8Pz4+jq0bN3Dh3BleBQdhZm5Ola+q0af/IMpVqJhrvYoXNWfWyDa0qFceK4uCBIVGcfj8bRZuOEVsfJJeMjza1uS3uX30OnfIrB14HvPS2m5qIuPf32dQsoQVzs1nEBgaqZfcrISFhbJ2zSquXL5EVGQkNjbFaNy0GUOHj8yVH506eZxdntt5+sQbmcyIsuXK03/gIGrXqafX9Tt3bGPpzz+xedtOvqpaLcf3z8ib12Fs+XUNXtcuEx0VSVFrG+p/25S+g4ZTMBe+eP6Pk/y+1xOfZ0+QyWS4upeju8dAvq5VJ9N5p48f5ud5M/WSOWnmPFq06ZCjfuTVMfbmdRhbN6zh5vUrREdFUsTahvoNm9BnYO7sdeHMSQ7u9cTn2VNkRjJc3MrR3WMA1WvW0Xh+amoqxw7u4/TxQ/j5vsDA0IDSjk60bt+FFm075vpV/+uwUNatWcVVhb1sbIrRqEkzBg/Pnb1OnzzBbs/tPHuqHGPl6DtgsFZ7yeVydntu58zpk/i9fElqWiolS5aiecvW9PToi5GRUa70et+ITIrcY5CWlpb2qTshEOgiMeXDyX7z+jW9e3QlODgIC4vC2Nnb4ePjQ2JCAmWcnNmxay+FCn2YyXFi8lvt/XrzmoEe3XkVHIy5hQW2dvb4+viQmJiAYxknNm7fnaN+bd20gXWrV2BgYEAZJ2cSExMJDPDHwMCAKTNm06Fz18x9S0hgcL9ePH3iTYECBShV2pGoyEjCwkLJlz8/02fNpXU7zZOQEnW+19oPGyszLntOpGQJK95ExuEb9AZ3x2KYmhjx8HkwDfstIyYuUac+zeqWY/Kg5lrbLS0KUrZMCQCaDl7BlX+eaT136cTOjOr1LYDOifEbr9Waj79+jUevbrwKDsJCYa8XL9L9aJvnnhzZa9PGX1mzcjkGBgY4KewVoLDXjFlz6NSlW7bXP3hwjyED+pGQEK/XxDgiPllrW/ib14wc2IvQV8GYm1tQ3NYOP98XJCYmUMrRiTUbPTHNgW67tm5k47qVGBgYULqME4mJiQQHBmBgYMC4KbNo06GL6lyva5fZueU3rbJioqN46esDwPJ1m6lc9etM7aZG+bRe+yWPsZgE7Q/FiPA3jBok2cvM3IIStnb4+fqQmJhIKUcnVv22I0c/1HZt28jm9aswMDCglKMTSUnp9ho7eSat23fJdH5qairzZkzg8p/nMDAwoIStPQDBQQGkpaXRpEUbpvy4UOv9CpsW0Hj8zZvX9OvVjVfBweljTGGvMk5ObN6RszG2ZeMGflm1XKO9ps2cTccsYyw+Po7hgwfw8P49DAwMsLN3wMAAAgMCSE1NpWKlyqzdsBmTggU13s/M6OO9pK848+xHu9e9eU0/2r0+BmJiLPgi+JAT45HDBnP1ymVat23H7LkLkMlkhIeHM27MSG7f/o/OXbsza/bcD3Lv7CbGY0cN5frVK7Ro3ZbpP85DJpMRER7OpHFjuHvnPzp07srUmXP0us+9u3cY0q8XBU1NWfnLBipWrgLAqRNHmTtzGvny5WPf4ZPY2tmprlk0fzaHDuzDzb0sPy9fTfEStgAc/n0/P837EZlMxoGjpyhWvITa/bKbGB9eM4Lmdcuz6/hNRszdhTw5haKWhdj3vyHUruLExgNXGLNgj156ZcfxdaNpXMud1Z4XmLTsoNbzqpcvxcVt48mXT/rSyu3EeNTwIVy7epnWbdoxa858lR/98P0o7tz+j85dujHjR/386O6d2/Tv0xNTU1PWrPuNylW+AuDEsaPMmjGFfPnycfjYKWzt7DVe/+D+PcaMGkZEeDjAO0+Mp4wdzs3rV2nSog0Tps9BJpMRGRHOzEnf8+Dubdp06MIPU3/US7eH9+4wZkgfChY0ZdHKdZSvKPni2VPHWDx3Bvny5WPbvmMUt7XTIQnS0tKY9N1Q/rl5g849PBg1brLaOdlNjL/kMZbdxHjquBHcuiHZ64eps1X2+nHyWB7cu03r9l0YN2WWXno9vH+H74f2xaSgKYuWr6NcxcoAnDt9nJ/nSfbasvcoxUuk6/XHiSMsmT+TgqaFWLB0NRWrSL73399ezJz0HYkJCUyd/RONm7fWeE9tE+PvRgzl2tXLtGzTlpmz56vsNX7saO7e/o+OXboxfZae9rpzm4F9JXutXreBSpWlMXby+FFmz5hKvnz5+P3oqUz2WrxgLvv37saxjBOLl62gjJMzAM+ePGHS+O/we/mSrj16MXma5jccH3NiXGnWuY92r7tzm3y0e30MRI6x4P81T7wfc/XKZayKFGHWbOmLEcDKyooly1cik8k4cuggb968+aj9evrEm+tXr2BpVYSpM+eo+mVpZcXCJcuRyWQcP3KI8HD9+uW5dRNpaWkMHjZS9YUN0LJ1O7p070lycjJ7dm5XHU9MTOT0iWMAzF6wWPWFDdChc1fqfdMQuVzOmVMnc6RXBRdbmtctT8ibaEbN3408Wfpyfx0RS+9Jm0lMSqZv+1pYW75bhH54929oXMudpy9Dmbn6qNbz8uUz5JdZPUmSv9svryfe3ly7ehkrqyLM+HFuJj/6edkKyY8OHyJcTz/atkWy19Dho1STYoDWbdvRrUcvkpOT2em5Xe26tLQ0Duzbw6D+HqpJ8bvy/Kk3N69fxdLSivFTf1TpVtjSih8XLqOATMbp44eJ0NMX93huIS0tjb6Dh6smxQBNW7alfZceJCcnc2CPp16yDh/YzT83b2DvUIohI8fmSK+8OsZ8nj3h1o2rFLa0YtzkWZnsNXPBUgrIZPxxQn977fPcKtlr0HDVpBigSYs2tOss2etgFntdOCP1uWffQapJMcBX1WvSvfcAQJpY54SnT9LH2PRZczPZa/FSaYwdy8EY266w15Dho1STYoBWbdrRVTHGdntuUx1PiI/n6OGDGBgYMGfBItWkGMDZ1ZW5CxYDcOTgARITdb/xEny+iIlxHsbLyws3Nzedf+3bt8+17AkTJqiOrV69Gjc3N/bv3/8+1fignDwhPZybNmuBsbFxpjYbm2LUrf8NKSnJXLp44aP268ypEwA0btpcrV/WNjbUrluflJQUrly6qFNWfHwcl/+6iIGBAS1at1Vrb9uhMwB/nk9/9RYdFUWrth1o1qJ1pi8AJcpjoaGv9NYJoHvL6gAcOvsfiUmZI5TBYVGcufoQWYH8tGqQ+9zKopaFmDNa0nP8z/uznfT+0K8JlVzt+em3U7m+H0i5wABNm6nby8amGHXrKfzo0p86ZcXHx/HXpT8xMDCgdZt2au0dOkmvrc+fPaPW1qdXNxbMm41cLmfIsJGUsLVVOyennFdMcr5p3AyjLLoVtbahRu16pKSkcP3KJZ2yEuLjuX75EgYGBjRp0UatvVXbTgBc/lP3a+DIiHA2rV0FwOjxU5DlMLczr44xpb0aNNJir1qSvW7oa68rkr00RXdbtu0IwOWLmaOTr8NCAXB0clG7xsWtLABhOdTrtGKMNdYwxqxtbKhTrz4pKcn8pfcYk+zVSoO92neU7HXhXLq9Hjy4T1JSEjbFilOufAW1aypUqoyFhQVyuRxfn+c50u1DYGBg8NH+8hpiYvz/ADs7O0aPHq31r0ePHp+6i5+M+/fuAlCpcmWN7RUVEZL//v33o/UJpFfhABUqVdLYXr6idPz2f//olOX96BFvU1Kws7fHyqqIWruziytGxsaEhrwiOCgQAJtixZg0bSbzFi3RKPPxo4cA2NmX1K1MBqqXLwWA1z1fje237kvH61RxypHcjEwZ3BzzQiacvfaIs9ceaT3PqaQ1U4e04N6TQFbsOJ/r+wE8uC/5UcVKVTS2V1Da61/d9nr08CEpKSnY2ztgVUTdXi4urhgbGxMS8ooghb3S+3GPUqVLs/63LYwc/V1O1dDI4wf3AShXQbMvli0v/Yi5d1v3GHni/ZC3b1MoYWePpQZfdHR2wcjImLDQEF4FB2Ury3PzBuLj46hesw41auu3GDEjeXWMeT+U9CqrxV7uCnvdv/ufTllPlfay1WIvp3R7hWSwV1GbYoAUvc7KS19p0ljUupjO+2fkwT1Jr4qVND+rKyie1Xf+0+2Hjx8+VNhL8xhT2iskg72cnJz5+X8rGTdhkkaZb9++JTFJWjj8NjVVt0KCzxZRleL/AXZ2dowZM+ZTd+OzJDAgAAA7LbmatoqIW4C/30frE0BQgL/i/pr7pXztGqg4LzsCdcgyNDSkWLHi+L30JTDAnxLZ5HbGREezbfNv3LxxDUurIrTUEG3JDkf7ogC8DNT8utMvWHr9X8ahaI7kKilZwpLBXaRJ0rx12b+qXTO9B0ay/IxZsIeUlHf7IgtQfMZ29po/Y2Xk1t8/B/bS4pOGhoYUK16cl76+BPj7Y5vBXjNnz6Ntuw4UKKA5RzM3BAdJY6SEFv8pVlzSLShQt27BgUpZmn3M0NAQ62LFCfDzJSjQP1N6QUZeBQdx7NA+AAYMHaXzvprIq2MsODBQ0X/N91DmK+tlL8WkUFu+t2SvYgT4vSQo0J9iis+sZZuO/ON1jb2eW6hYpSoVK1cFpPzy3ds3AdC2Y/aLR7MSGJj9uFDaS59ndaDCDzPmD2cko70C/CV7WVpZ0ahJM60yb964TlJiIvny5aNkyVI6+/ChyYOB3I+GmBgL/l8TEREBQOHChTW2m5ubAxAZmbvyXbklMlLql4WOfkXp0S+lLHMtsgDMdMi7f+8OP839EX+/lyQlJVHGyZk5C3/W2j9tFCks5Q6/iYrT2B4RHQ+AlUXOyy4BDOv2DUayAly//Zxb919qPa9fh9o0rOHGr/v+wuvui1zdKyOREdLnZmGhzV4WAERF6W+v7D5blbws9uqUperB+yBK6T8WFhrblb4THRWlhyypv+bm2fiimVKe9s/qyIE9JCcnU75SFa2RUV3k1TEWFaW0l+brCpnlxF7Zy9Imr2GT5oSGBLN941p+GDEAWzsHDA0NCfB/iWmhQoydPIu6DRrpp5AC5RjT9azWa4xF6DPG9JeXkpLCL6uWA1Czdh2VrQVfJiKVQpCJoKAgZs2aRYMGDahQoQJ169Zl/PjxPHumvdRVdiQlJdG/f3/c3NyYM2cOn1sRlKQkaZFE1lw8Jcrjcrl+tXXfF0mKV3LaamIaGSn7JX9nWRnlJWmR5/P8Gc+ePlHJiggPx+v6VZ33zoqJkRTJTEzSfJ8ERd6xsSznv9llBfLTp30tANbsvKj1PBsrMxaO7UBwWBSzslmYlxPS/UibvaTj8iTdfpSYKJ1jnK29pLakj+CXyj7LjLSMEaVuevRFrvicsssHTv+sNPuIXC7n9PHDAHTu4aHzntrIq2NMrrde+thLf72yyrOzL0lxWzvS0tIIDPDD38+XtLQ0CpmZ56i0nxLVGNOml2LsJWnxG02yjLX4tCRPYS89xuzSRQt4/Ogh+fMXYOSYnC0C/VCIHOPcIyLGAhWPHj2iX79+REVFUbt2bVq2bImvry8nTpzg/PnzrF27ljp1NBdz14RcLmfMmDFcv36dPn36MGPGjA/Y+9xhaJiP1GzywZRtBnzcwW9oaJh9v9IU/dKjW4Z6nJSmQ169bxpy4eotEuLjuXjhHGtWLGXNimUkJSUxeNhI3Z1Q8DY1VVUWLbu+5ub3U8fGVbC2NCMwJIIjf97Ret6ySV2wsjCl98RNRMe+n9Xjuvwo/fPVbQtDQ93xio/plzp9MVUylj66Geijmw5fvPznWaIiI6QNRho01ilPG3l1jOnSS9UPPXzHwFAPvVLVffvQvp38snwx5haFmTZnEbXrNeTt2xQuXzzPupVLWDBzElEREXTo2lOnfCU6x1hO/NBAtx9q0ksTa1ev4MA+qbzk6O/H4V62nE7Zgs8bMTH+f0BgYCCrV2uuvWpnZ0enTp1ITU1l4sSJREVFsXjxYjp0SC8q/9dffzFs2DDGjx/P+fPnKaileHlGUlJSGDduHJcuXWLAgAFMmTLlvenzPjEpaEJMdLLWSF6yIrqjLaL8oTAxKUhMTLTWaJWqX9lEPFSyCkppCdlFvuQ65CkXFJmamtKle08sChdmxuTxeG7dRLeevVWv9nURlyBHViA/RjLNObBGikhxQpL2mrraaN9YWnxz5MId3r7V/AXaol55ujSvxsm/7nPwnO7FR/piYmJCTIx2P5LLJX302RVLOb6yiwYnJyvkaYlQv0+MTUyIjYnRGmFMTlb6ju6+mJhIumXni8mqz0qzL17+U1ooWf/bJuTLn/uvsLw6xnTZS9kPfap4pNtLuy/KkzPLi4wIZ+PalQDMnL+Er6rXVJ3bsm1HLC2tmDFxDBvXLqdRs1ZaU3TU+yKNMW0R4fTPNwdjLJtosC57paWlsXLZEjy3bwGgey8PPPoN0Hnvj8WXFsg9deoUW7du5dmzZ+TLl4+vvvqKUaNGUUnL4tisLFq0iC1btmhtv3TpEsWLF9dLlpgY/z8gMDCQNWvWaGyrUaMGnTp14vbt2zx9+pT69etnmhQDfPPNN3To0IGDBw9y5swZtfasvH37lokTJ3Lu3DkGDRrEpEmaV/F+DlhYWBATHU2Ulny7yKjs89o+FOYWFsTERGvNA1TmKVoUttRLFmSfU6iUV1gPeQBNm7dkxdJFvA4L48njR1SvUUuv6yKi4rA0L6g1h7iI4vibyFi95CnJn9+QRjXdATj6512N55iayFg1rTux8UmMW7Q3R/J1YaGwlzY/Un2+lu/HXpE5tNe7YGZuQWxMDDHRmvujzAW2sNDdFzPF5E6brEzyNIy5lJRk/rl5HSDHOapZyatjLN1e0RrblZ+9Pnop7RWtRRZAjEJnpf3/9rpGUlIirmXLZ5oUK6lVrwFOLm48f+rNrRtXtG7ykRWVvaI15/wqc4FzNMay8cN0eep++PbtW+bPmcWxw9LGQV2792TC5Gk67yvQzLp161ixYgX29vZ069aN6OhoTpw4wZUrV1i/fj3169fXKePhw4cYGBgwcuRIjVH+nOyIKCbG/w+oUaMGO3bsyPachw8fqs7VRPXq1Tl48CCPHvvWv4EAACAASURBVD3SOTFeu3YtISEhADRq9G5fXh+a0qUdCfD3Jzg4ONNGCkpeBQcD4FAyZyWT3pWSpUoTGODPq1fBmTYLUPXrldQvewcHnbJKlSoNQIjimqykpqYSpqg7aqeQl5KSQnBQIGlpaZRUXJ+V4iVseR0WRngONpJ48jKUMg7WOBS31Ljozb6EFQA+Aa/1lglSeTcLMxPCo+K48q/mfPiq5UrhoJDvfXKeVlnP/pgPQLPBK7n8z1O97l+qtCMBCntVRt2Pgl9JpazsHXT7UenSjkC672UlNTWVsFBpfDnoIe9dcShZmuDAAEJfvaK8hvLSoa+kerS29rp90UHhS6Eh2nVT1sC1tVOXd+/2f8TFxWJmbk7lKtnv5KeLvDrGlPYKCQnOtCGHEmUftVV3yCoLICwbvVT2UlRkUfqmvYP2ygwOpRx5/tRbda4+lCqtsFdwcKYNOZQox4u9Hn5YSo8xFhoaqpCXeYylJCczfcpEzp/9A4A+/Qfy/Q8T9dbjY/Gl5P4+e/aMVatW4erqyt69e1XRfA8PD3r27MmMGTM4c+aMzjcBjx8/pmTJknz33buXqRSL7wQAxMTEANp/VRUrJtWcTEhI0CkrJCSEpk2lvdOnT5/+We8CpCzUrqxnnJV7d6Vc1Qq5XPmeW8oq+vXwvuZ+PVD0t5ymmUoWnJxdkMlk+L30JVZh54w8e+JNUmIi1tY2FCsmvWo6dGAfXdq1ZPEC7durBilKHhUtaq2zD0r+fSiVUqpeQfOXZg3F8b+zqSih8bqKpQG4fttHaxpFdGwC1/57rvVPyd/3fbn233OiY3X7uhJdfnT/rnS8QgX97fXypa9qXGbk6RNvEhMTsbaxoZierwbfBbey5QF4rKiPm5VHDyTd3Mupb3qQFUcnZwrIZAT4vSQ2Vl03n2dPSEpKpIi1DdbF1HVT3qt8pa/eKY0C8u4Yc3WX7OX98L7GdqUd3crp1qu00l7+OuxV1AZrG0mvgqbSW5+IN9p/3IYr2kz0SMtTohxjyvrTWVGOPWX96exw1mGvp0p7aRhj8+fMUk2KR4z+/rOcFH9JbN26ldTUVEaOHJkpTbNs2bJ06dKFV69ecf589nXmAwICiIqKomzZsu+lT2JiLADSJ8TKSG9WlK/S9Ekp6N69O2vWrKFz5874+vqycuXK99fR90yjxtIe76dPnVDLNwsNDeHqlcsYGRnRqEnTj9qvBt9Ki4rOnj6l1q+w0FBuXLuCkZERDRvp3qPe2MSEmrXrkpqayoljh9Xajx2RXgc2bdlKdaxa9a8B+O+fvzXWcT1/9g/C37zB3NycCloK7mvimGJRXNfm1VT5xEpKWFvQtE45EhLlHM1m8ZwmKrtJ0SrlxFsTd7wDaDxwudY/JT3Gb6TxwOXc8Q7Q+/7fNpLs9cfpkxr96NpVyY++bazbj0xMTKhVR7LXsaOH1NoPH/odgBYt9XsF/a4oUxYunD2tlkP9OiyUmzeuIjMyol5D3QvhjI1NqF6zDqmpqZw5oV4R5NQxSd9GTVtqvP7Zk8dA+mT9XcirY6xug28B+FOLvW7duIpMZkQ9PVJRjI1NqF6jNqmpqZw9qW4vZXWQRk1bqI5VUkTy7935VzWxz0hQgD+PH9zLdK4+NFTY64yGMRYWGsp15RjLob2OH1W311FFikTzFpnH2N7dO1Xnjx0/iUFDh+vd/4+NgcHH+3sXrl9XpEbVravWplzsf+3atWxlKN94i4mx4L1Srpy0kvbvv//W2H7jxg0AXF1ddcqqWFGKREyePJmiRYuybds27t7VHJX51JQtV55atesQFhrKtMkTiY+X6uhGRIQzcdz3yOVy2nXoiJWV1Uftl3vZctSoWZuwsFB+nD6ZhASpX5EREUybOA65XE7rdh2wzNKvAH8/fF/4qOp0KvHoPxCAdatXcMvruur4qRNHObB3NzKZjG49equOl3F2oU69b3j79i3TJv2Q6Yv7379v8fPCuQAMHDoSmUymt163Hwdw/sZjbG0Ks2VBPwoaS9cWKWzKzp8HYmxUgB3HvHgdkTnH2NG+KK6li1GksObc5AouUqH+e08CNbZ/aMqWK0/NWpIfTZ86kQSVH0UwafxY5HI5bdur+5G/vx8vfHxU9bSV9B8wGIA1K1fgdSPdXieOHWXfnl3IZDJ69Mp9qbKc4Opejmo1avEmLJSFP05V+WJUZARzpo0nWS6neev2FLbMrFtggD9+vj6qWrhKenhIC5Q2rlvJv7duqI6fPXWMIwf2UEAmo2O3Xhr7otxJzclF93NIF3l1jLm4laPq17V48zqUn+Zktte86RNIlstp1rqdmr2CAvzx832hZq9uCnttWr8qk73OnT7O0d8le3Xomm4vRycXatdrQEpKCrMmfcdLXx9Vm//LF8yZ9gNyeRK16zfUuGW0NtzLladGrdqEhYYyc+ok1RiLjIhg8gRpjLXJgb36DRgEwC+rVnAzwxg7efwo+xVjrHuvdHtFRkSwZsX/AGnL6M9pod2XSnJyMoGBgVhZWanqRmekpCKF8fnz7LfYVk6M4+LiGD58OHXq1KFy5cp07dqVY8eO5bhfBmmfW2FZwXvDy8uLvn376pVjnJqaSps2bXj+/DkLFiygS5cuqrZr164xdOhQTE1NuXDhAqampirZbdu2ZenSpQCsXr2aNWvWMH/+fLp2lTYaOHnyJOPGjcPFxYWDBw/m6AGfkcSUXF2mFwEB/vT36ElYWBhm5uY4ODjg4+NDYkICbm7ubPXcrVcljtyQmPxWa1tQYABD+vfmdVgYZmbm2Dk44OvjQ2JiAi6ubvy2badq1biSDi2bEBwcxOBhIxkyYnSmtl9W/Y/tmzcC4FjGieRkOQGKndhmL1hEy9btMp0fHv6GEYP74evjQ778+SlVqjTJycn4+0lpDp279mDS9Fka+16izvda9SplW4Q/t/5ACWsLIqLj8Ql4jbtjMUxNjLjjHUCj/v8jPjHzyvPHJ+ZQyrYI89efZMGvJ9U/q0s/Y2lekDq9FvPfI907emki4T9pgapz8xkEhmov6v/GS3OFl8CAAPr37amyl72DAy9eSH7k6ubO1u271F4dt2reiOCgIIaNGMXwkZl3p1y1YhlbNv0GQBknZ5LlcvwVu3rNX/gzrdtmtpcmlPI3b9vJV1Wzj85FxGuvBBIcFMB3Q/ry5nUYhczMsLVzwM/3BYmJCTi5uLHqt+1qvtizQ3NCgoPoO3gE/YdkLjf22y8rVDuglXKUfFG5E93U2Qtp2lLzbm/tmtQhNiaG9Vv34Kpn1NjUKJ/Wti95jMUkaH8oBgcFMHZYvyz28iExMREnFzdW/LpNTa/eHVsQ8iqIPoOG029wZnttXLuSPTsy2EsuV+2cN+XHhTRp0SbT+VFRkUwaM5TnTx9jYGBAydJlSElOJijQn7S0NJxc3Pl59QatG+IUNtVctSYwIIBB/XplHmMKe7m6ubNp2061Mda2RWOCg4IYMnwUw0Zmttealf9jq2qMOSGXJ6t2zpu7cDGt2qTba8vGDapNPNzcy2JsYqKxjwATp0zXWLbNzOjjxSK/XnDxo93r1vSGubouLCyMevXq4ejoyOnTp9XaQ0NDqV+/Pi4uLhw/rn0n02HDhnHx4kUMDQ1V5wcHB3P+/HkSExPp168f06bpvzhSLL4TAFLtyyVLltC/f3+mT5/O8ePHKVu2LL6+vly8eBEjIyOWLVuGqWnOdiRr1aoVR44c4eLFi6xdu5axYz+P4ucZsbd3YPf+g6xbs5q//rrIE+8nFC1alMaduzJ81JgPNinWha2dPdt2HWDDujVcu3yJZ0+8KVK0KO0bdWHI8FFqX2y6GPXdDzi7uLF31w6eP5UWlX1VrTp9BwymTr1v1M63sirC5h178dy2mfNnTuPv9xIjI2O+rlmLrt170UCPV5aaeBn0hjq9FjNjeGta1i9PRRdbQl5Hs+XgNeavP6k2KdaFoaEBFoWkkkrBYbp38/pQ2Nnbs2vv76z/ZTWXL1/i6RPJjxp17srwEaNzlE8J8N3Y8bi4urF75w6ePpUipVWrVWfAoKHUq69urw9JCVt71m/by9YNv3Dj2mV8nj3BqkhRWrXvTP8hI3Lsi0NGjaWMsysH9+7kxXPJFyt9VY2efQdRs47mFehv374lLlZ6k1DE2ubdFFKQV8dYCVt71m7Zw7aNa/G6KtnLskhRWrVrTN/BObfX4JHfU8bZhYP7duKrtFeVavToO5AatdXtZWFRmJUbtnFo3y4unjtNgGKiX8bZlYZNWtCxWy+MjbVPLLVhZ2+P554D/Lp2DVcUY6xI0aJ0bNyFobkYY6O/l+y1Z+d2ninsVbVadfoNHELdLGPszu1/Vf/2fvwoW7mxsTmrqvOl07hx9mlU2nKEU1KkH3fatrBXBtJ0bbIik8mws7Nj/vz5mfZa8PPzo1evXmzbto369evrVd0CRMQ4T5OTiLESf39/1q9fz+XLlwkPD6dIkSLUqVOHIUOGUKZMGTXZuiLGIO2m17p1a+RyOQcOHMhVHtCHjBh/SrKLGH/JZBcx/tLRFjH+0skuYvwlk13E+Esmu4jxl462iPGXzseMGNdYePGj3cvsvPYqP6B9YhweHk7t2rV1Rozd3d05cuRIrvq2d+9eZs2aRZs2bVi2bJle14iIcR6mZs2aeHt75+gaBwcHFixYkCvZY8aMYcyYMWrn2tra8t9/728zBYFAIBAIBJ8HuqpGaMPMzIx8+fJprL4D6Yv+NeUf60vlytLCVX9//VPsxMRYIBAIBAKBIA/xJdQxLlCgACVLlsTX15e4uDi1VE0/Pynf29nZWauM+Ph4nj59ioGBgcZd8pQL6vXZEVGJqEohEAgEAoFAIPjo1KhRg7S0NFXZtoxcvXoVgK+//lrr9a9evaJbt24MGTJElbOckZs3bwJQpYr6Jj7aEBNjgeD/2LvvqKiONoDDvwVZQBQUFRCwa7D3Eltijz3G3nuLJT2W2DW2xNijxt5LNPaKJbH3z4KiYEPpIF3aUvb7YwFFdmFZgSh5n3P2nOSWufM6O3eHuXNnhBBCiFzkQ5nHuFu3bigUCpYsWZJqSMXDhw/566+/sLOzo0UL3S+hli5dmkqVKhEaGsqyZanf/7h37x6rV6/G3Nycnj176p0nGUohhBBCCCFyXJUqVRg0aBDr16+nQ4cOtG7dmlevXnH48GHi4+OZM2dOyuwU4eHhbNq0CSDV+0xz5syhf//+rFq1imvXrlG9enW8vb05c+YMarWa3377DQcHB73zJLNSiA+CzErxYZFZKT48MivFh0Vmpfjw5OSsFPXnn8uxa10e/+7TR+7evZvt27fz5MkTLCwsqFKlCmPGjEk1btjLyytlari3X/738fFh5cqVnDt3jpcvX2JpaUmdOnUYOXJkygJm+pKGsfggSMP4wyIN4w+PNIw/LNIw/vBIw/jDIEMphBBCCCFykQ9gUor3lrx8J4QQQgghBNJjLIQQQgiRq3wI8xi/r6THWAghhBBCCKTHWAghhBAiV5EOY8NleY9xQkICISEhWZ2sEEIIIYQQ2crghnFwcDCrVq3iwYMHKdt27NhB3bp1adCgAa1ateLChQtZkkkhhBBCCCGym0FDKfz9/enatSsvX76kYMGCVKhQgQcPHjBz5kzUajWWlpa8ePGCkSNHsmfPHsqXL5/V+RZCCCGEEFrIy3eGM6jHePXq1QQGBtKyZUvq168PwM6dO1Gr1QwaNIhr166xatUq4uPjWbt2bZZmWAghhBBCiOxgUI/x+fPncXBwYPHixRgZadrWf//9NwqFggEDBgDQpEkTqlevzrVr17Iut0IIIYQQIl3SY2w4g3qM/f39qVSpUkqj2N3dnYCAAEqWLImdnV3Kcba2tgQHB2dNToUQQgghhMhGBvUY58uXj5iYmJT/P3dOsyZ3w4YNUx0XEBCAhYXFO2RPCCGEEEJkhnQYG86gHuNSpUpx48YNgoKCUKlU7Nu3D4VCQbNmzVKO+d///sft27flxTshhBBCCPFBMKjHuGvXrkyYMIH27dtjbm6Oj48PpUqVSnkRb9q0aRw4cACAnj17Zl1uhRBCCCFEumSMseEMahh36tSJ8PBwFi1aREhICKVLl2bx4sUpBXH9+nXi4+OZOHEibdq0ydIMCyGEEEIIkR0MXhK6f//+9OzZk1evXmFtbZ1q34wZMyhXrhwFChR45wwKIYQQQgj9SYex4QxuGAMolco0jWKAOnXqvEuyQgghhBBC5Di9GsaXL19+p4skjz0WQgghhBDZS8YYG06vhvGgQYMM/kdWKBS4uroadK4QyfxCYzI+6ANkaW7yb2chWwRdXfZvZyHbFGo87t/OQrYIufjrv52FbBETl/BvZyFbJCSq/+0sZJvcHJt4/+nVMJahEUIIIYQQHwbpMDacXg3jLVu2ZHc+hBBCCCGE+Fe908t3QgghhBDi/WIkXcYGM2jlu2RPnjxh+vTptG3blho1ajBhwgQAZs2axdatW1GrZZyQEEIIIYT4MBjcY/zXX38xY8YMVCpVyrbExEQArl27xvbt27l+/TqLFi3CyOid2t9CCCGEEEJP0mFsOINarDdv3mTKlCmYmZkxbtw4Dh8+nGr/119/ja2tLc7Ozhw8eDBLMiqEEEIIIUR2MqjHeM2aNRgZGbF27VqqVq2aZn+LFi0oV64c7dq1Y9euXXTq1OmdMyqEEEIIITIm8xgbzqAe41u3blGjRg2tjeJkJUqUoE6dOjx//tzgzAkhhBBCCJFTDOoxjo6OxtLSMsPjTE1NiYyMNOQSQgghhBDCAEbSYWwwg3qMHRwccHV1JSFB94pCcXFxuLq6Ym9vb3DmhBBCCCGEyCkGNYxbtmyJn58fCxYs0HnMwoULCQwMpHnz5gZnTgghhBBCZI5CocixT25j0FCKYcOGcfToUTZu3MiVK1dSloz28PBgyZIlnD9/nvv372Nra8uQIUOyNMNCCCGEEEJkB4Maxvnz52fLli388MMP3Lx5kwcPHgBw9+5d7t69C0DFihVZuHAhBQsWzLrcCiGEEEKIdOXCjtwcY/ACH0WLFmXbtm3cvXuXK1eu4OvrS0JCAjY2NtSpU4d69eplZT6FEEIIIYTIVgY3jJNVrVo13WnbhBBCCCFEzlEgXcaGeueG8dWrV7lx4wYBAQGYmJhgZ2dH3bp1pbEshBBCCCE+KAY3jF1cXJg4cSJPnjwBQK1WA69XW6lZsybz58/H0dExC7IphBBCCCH0IfMYG86ghrGHhwcDBgwgKiqK8uXL06RJE4oWLYparcbb25uTJ09y8+ZN+vfvz+7duylUqFBW51sIIYQQQogsZVDDePny5URFRTF27FhGjx6dZv+3337LnDlz2Lp1K8uWLWP69Onvmk8hhBBCCCGylUELfFy6dImPPvpIa6MYwMjIiEmTJlGiRAlOnz79ThkUQgghhBD6kwU+DGdQwzgqKorSpUune4xCoaB8+fKEh4cblDEhhBBCCCFykkFDKSpUqMDdu3eJj48nTx7dSbi7u1O2bFmDMyeEvoJeBrJ5ze9cu3yBiPBQChWxodGnLegzaAR5LSwynd7fJ4+x78+tPHv8CKWpkrJOFeneeyC16jXQerxKpWLfn1s5c+IIPl6eWBYoQKUq1enZfyily35kcFwvAwNZvXIply+cIywslCI2tjRp1pLBw0dhYUBczsePsGv7Zh4/csdUaYpThYr0HTCEevUb6nV+VFQkfbp2xM/PlwPHzmBja5fpPAAEBgawYvlSLpw/S1hoKDY2tjRv2YrhI0dhYZEv0+kdO3qY7Vs388jdDaXSlAoVKzFw8BDqN2ik1/nbtmxiwS9zWb9pGzVq1sr09ZPZFcrP1BGf0bpBeaytLPAJDGP/3y7MWXeKV1GxeqXRt11t1kztodexw2buYuuRGyn/rzQxZkyPxnRtWY1yxYtgZKTgsedLdjvfZtnO88Sq4g2KKysEBgbw+7IlXDh3ltDQUGxsbWnRshUjvhxtUJlnlZeBgfyxYimXLpwjLFRTx5o2b8mQEYbVsRPHjrBrm6aOKZWmlK+oqWMfN9Bex6KiItm4djVnTjnj5+tDfktLqteoRb+BQ6hYuYrBceXme2JuLK+slgs7cnOMQp08nUQmXLt2jcGDB9O2bVumTp1Kvnxpb2rz589n06ZNrFixgiZNmmRFXsV/mMfLGJ37QoKD+GpoHwL8fclvaYVdUQdePH9KbEwMxUuWZvHqLZn64d25eR0b/liKQqGgRKkyxMbE4OvjhUKh4KtxU2jbsUuq46Ojovjpuy9xdbkNgGPxkhgbG/P82ROMjfPww+RZNGvVVuu1LM1NdOYjOOglQ/r1wM/PF0srK+ztHfF49pSYmGhKlS7Dmo07sNBS93TZtH41q5YvRqFQUKpMWWJjYvD28kShUDB+0nQ+79wtwzQW/TqHP3dsBUi3YWxmovthVNDLl/Tt3R0/Xx+srKywd3Dk2bOnxERHU7pMWTZt3an1nqLLurV/sHzJIhQKBWXKlCUmJgavpLgmT51B567d0z3//n0Xhg0aQHR0lF4N40KNx2ndbmOdj/Prv6J40YIEhUXi4RNM+ZK2WJgrcX3qR5Ohy4mIzLhx3Kq+E+MHNde5v6BlXiqUsgWg5ciVXLj1FAALcyXHfx9B7UrFSUxM5Jl3MGrUlLIvhLGxEVddntN2zB9ExcRpTTfk4q8Z5s1QQS9f0qdnN3x9fbCyKoCDowNPn74u8y3bd2WqzDMjJi5Bd76CXjK4bw/8fJPqmIMjHk9f17G1m3dkKl8b161m5TJNHSud9F1MrmMTJk+nU5fUdSwmOpqhA3rzyN0NExMTSpQsRVhoKIGBARjnycOkqTNp17GT1muFRmovR/iw74kABSy03xc/5PICKGBurHfe3lWntTcyPiiL7B9aO8eulRP0ahiPG5f2h+D27dt4enpiaWnJJ598goODA6ampgQEBHDp0iVevHhBtWrVaNq0KSNGjMiWzIv/jvQaxpO+H8WNKxdp/lk7vpkwHaVSSWhIMDMmfoury23aft6Fr8dN1es6D+7d5duR/THPa8HshSuoWLkaAKdPHGbBz1MwNjZm7Y4D2BV1SDln0bwZHD+0F0urAkyds5Aq1WulpDVt/FdEhIexfN0OynxUPs310msYfztmOFcuXaB12w5MnDoLpVJJSEgw478bi8udW3zeuRsTJs/QK657d+8wfFBv8lpYsGjZaqpUqw7A8SMHmTXtJ4yNjdm17yhF7R10pnH/3l2GD+xNYmIiYHjDePTIYVy6eJ527TsydcbPKJVKgoOD+e7r0dy5fYsuXbszedpMveK6e+c2A/v1wsLCguUr11Cteg0Ajhw6yNTJEzA2Nmb/oWPYO2ifNvL+PRfGjh5BSHAwwDs1jPcvGsJnDcqz/dhNvpy9G1VcAoULWPDnLwOpX60ka/ddYey8v/SKKz2Hlw6jeb2PWLbjHOMWH0rZvujHLxjZtQEPnvnTe+JmHj4LAKBSGTt2zOtPueJFWLX7It8u2K813exsGI8aMZSLF87TrkNHps+cnVLm344dxe3bt+jSrQdTp+tX5pmVXsP4m9HDuXzxAq3bdWDStKQ6FhzMuG/HcvfOLTp16cbEKfrVMZe7dxg2QFPHlvz+uo4dO3KQmVM0dezP/Uexd3hdx+b9PJ19e/7EqXwFflm0DLui9gDs/2s3c2dNQ6lUsufgMWztiqa5XnoN4w/5ngi6G8YfcnlBzjaMO6+7mWPX2jvE8Kds7yO9xhgfPHgwzefFixeo1WrCwsI4dOgQq1atYsmSJezYsYPnz5+jVqu5ffs2ixcvzu4YxH/Y08fu3LhykQIFrfl6/FSUSiUABQpaM3nWr5golTgfOUBoSJBe6e3etgG1Wk3fwSNSfgAAmn/Wng6dexAXF8e+XdtStge9DOTk0YMAjJsyO+UHAKBC5aoMG/0diYmJrF2xKFNxPXZ348qlCxS0LsT4yTNS4ipY0JrZvyxCqVRy5OA+goP1i2vrpnWo1WqGDB+V8gMA0LpdR7p070VcXBw7t23WeX58fDzzZk3DJCkfhnJ3c+PSxfNYWxdi8rSZKXFZW1vzy2+LUSqVHNi/j+Ag/eLatEET1/CRo1MaxQDtOnSke8/exMXFsW1r2rjUajV7/tzJkIF9UxrF76Jy2aJ81qA8/sERjJ67B1VSY+xlaCR9ftpCTGwc/dvXpkjBzD/qfdPIrg1oXu8jHr0IZMqKYynb85qZMKB9HRITExk6fWdKoxjg/hM/hkzfAcDAjnUxM33ndZ0yxd3tIRcvnMe6UCGmTp+Vqsx/XbREU+b79hKkZ5lnlUfubly+qKljE6e8UcesrZnzq6aOHT6QiTq2UfNdHDoidR1r064jXXukrWMxMTEcP6L5w2b67PkpjSyATl260eiTJqhUKpyPHc1UXLn1nphby0u8f/RqGM+dO9fgz5w5c7I7hvfC3r17cXJyYsKECekeN2HCBJycnNi7d2+q/7906VKW5+nq1as4OTnRr1+/dI9btmwZTk5OLFu2LMvzkN3+Pqm5CTVu2hJTU7NU+woVsaHOxw2Jj4/nyoWzGaYVHRXFlYvnUCgUNP+sXZr9n7X/AoALZ0+lbLt76wYJCfE4Fi9Jnfppx7M2b92evHktuHXjKqEh+jfAnI8fAaBZi88wM0sdV5EiNnzcsDHx8fFcOPdPhmlFRUVy4fw/KBQKPmvbIc3+Dp00j0H/OXNSZxpbN63j8SM3Bg/7Uu8YtDl29DAALVuljcvGxpaGjT4hPj6Os2f/zjCtqKhIzp39G4VCQbv2HdPs79S5KwCnTzqn2devd3dmz5qOSqVi2IhRFLW3T3NMZvRopflh3Xf6LjGxqcfx+r4Mx/myG0qTPLRtVNHgaxQuYMGMUW0A+P63A6nGC9eqWAxzMxO8A8L430OvNOdev+9JUFgkZqYmlC9pa3AeDHH0SHKZRFINxgAAIABJREFUt9Ze5o2TyvyfMzmaL+djmjrWvKWWOmZjQ/3kOnb2nwzTioqK5Pw5TR1r3U53Hfv79Os6Fh4WRtsOnWjVuh2ly6R9Fyd5W0CAn94xQS6+J+bS8souCkXOfXIbvRrGX3zxxTt9hG4tWrRgzJgxFCtW7N/OygfJzfUeoOmJ0KZ8Rc3LEPfu3sowrcfuD0hIiMfO3pECBdMuSlOqTDlMTc14GeCPv58PAAH+vgCUdaqgNU0jIyOKOjiiVqt55PYg44CSuN5zAaByFe1xVUqK9+6tjB+XuT14QEJ8PPYOjlhbp42rTNmPMDUzI8DfD18f7zT7PV94sGHtKsqU/YjefQfqHYM29+/dBaBK1epa9yfHe/t/Gcf1wNWV+Ph4HB2LYa1lEaFy5T7CzMwMf38/fN6K6/49F0qULMmqNRsYNearzIaRRu1KxQG4eu+F1v3X72u2N6heyuBrTBjcHEsLM05ecePkFbdU+x489afn+E1MWHJY67lGRgrMTTWPp41zeEmsey6aMq9arZrW/VWqaLbf+t//cixPoPkOAFSuqqOOJX8XM1HHHBy117Gy5dLWMRtbW8b9NIVZ87QPYXn4wBUAB8fiGQfzZl5y6T0xt5aXeP8YNF1bZiQk6B7fJTQN47Fjx0rD2EB+STetN8e3vcnGTtMT6OudthftbcnH6ErLyMiIIja2Scd6ptqXEK/7bf/4pH0BST8c+vBOSr+ojrGxyY/xvL08te5/k09SWrrG2RoZGWGbNFZYW3rzf55BnErF+EnTyWOie0y0PryS0nfQsVR8cs+tp2fGcSXnNd247DRxeb2V3pTps9i99xB1632sX8YzUMreGoDnPtp7wF74hQBQ2sGwVUCL2xVg6Bf1AZi1+kSa/S9DIznwzz32nrmr9fxmdcqR10xJfHwCjz1fGpQHQ3l7aeqVg45ysk8qcy9P7X9UZBef5O+P/bvXMe8M0sqojr0pIjyc5Yt/49qVSxS0LkQbLT2a6cmt98TcWl7ZReYxNpzBg82ioqI4c+YMXl5eqFQq3nyHLzExEZVKRWBgIBcvXuTy5ctZklkh3hYWpmlw5LcqoHV/vvyWAISHheqRluYYSysrnce8Ti8MeP2D8ezJI63Hq1SqlB+qV68iMsxDSl5CNXFZ6Ygrf1I+wvSIKzSDtNJL7+D+v7h54yqdu/VMNQ7PUKEhoenmxdLSSms+tKaVHFcB3XGlpBeaOr3OXTKegSMzChXQjB0OCovUuj8kPBoAa6u8BqU/omtDTJV5uHzHg+v3M/7hf5OxsVHKEIxT19wJe6X7RdbsEBKiKacCOsrJ0lLz3QsNzbjMs1JG35/kfL393UkvLct0vov5M0jvnssd5s6chueL58TGxlK6TFlmzPkl3e+3Nrn1nphby0u8fwxqGPv7+9OrVy98fX1TbVer1an+enj7/0VaEyZMYN++fWzYsIEGDTTzQTo5OdGoUSN++OEH5s6dy927d7GwsKB+/fp89dVXFC+eM49qEhIS2LZtG/v27ePJkycYGxvj5OREr169+Pzzz1Md26xZM5RKJWvWrGHOnDlcvXoVExMTatasydixY6lY0fCxlelRxWqmvzI1NdW6P3l7nEqlR1qaBoNSR1pv7lOpNNetXqsuJkolXi88OHfGmU+atUp1/KG9O4lNSjc+Tvdb5G+LzSiupDF2Kj3iyiitVOnFvk4vOOglyxf/SuHCRfhyzLf6ZTzDvMQkXS/98kou1/TExGiOMUsvrqR9sSr95hA2VPIwhZhY7WUcnbTdTJn5HneliTH92mumQ1q+83ymz//tu8+pWd4RVVw801cez/T57+p1mZtp3f/6u5y9ZfS2DOuYaRbXsaT0YnWk9/TJYx4/ck/5/5DgYK5evshHTtpnbtDlP3tP/EDLK7tI08twBg2lWLVqFT4+PhQtWpT+/ftTt25dFAoFI0aMoG/fvpQtWxa1Wk25cuWkt9hAXl5e9O3bl7CwMHr37k3FihU5dOgQ3bt358mTJ9l+fZVKxfDhw5k9ezYRERF07tyZNm3a4Onpybhx45g6Ne1UP69evaJv3748fvyYHj16UK9ePc6ePUvv3r25du1atuTTyCj9r3Dy1GL63CUUGaQFpDwZSf6Dz6pAQTp17Q3AornTOXFkP1GRkbyKCOfgXzvZ8Mcy8if1Wqa3GM7bMopLnRyXPmnpEXvyv9Obhy78ZQ4R4eF88+NE8uXPr/f10s2LUfrTFanVyfnIOM8Z/RvBG3GRvb8SCRmUh1HSuF4Dpo3ni6ZVKFIwH94BoRw4ey9T504b8Rkjumr+4J664hh33PV/dJ1VMirznCqjt2V471CnrRM609LjIHUG6TX6pAlnLl7nyMmz/DhxCjEx0Sxf/Btr/1iRcQbezMt/9J74oZaXeP8Y1GN84cIFzM3N2b17N4UKFeLs2bNcu3aNTz75hFq1apGYmMjkyZPZt28fV65coXXr1lmd7/fWgwcP0p3d4cED/V428PDwoGXLlixZsgRjY80Py65du5g6dSo///wzGzZs0DtP3t7e6eZJW6N148aNXLhwgaZNm7Jo0SLMzc0BCA4OZtCgQezatYuPP/6Ytm1fT9IeGBhI9erV2bRpU8pbw2fPnmXkyJFMmTKFY8eO6dWYyQwzc3NeRUSk6ul8U1xSj0R6PQPJzM01j7nT60lJ3qdUvu79GjB8DH6+3pz/+yQL50xj4ZxpKftatfscc/O8HNizg7yZmFDf3DwvERHhOns/krfr6oVLlVZei1TnaBP3VnoXz5/l9MnjNGj0Kc1bZl39NTc3JyIiTmePsEqlf3nlzaspr/R6g1PKX0cPdVaJjFahNMmDqY4eYVMTza02WkePcno+b6p5WerA3/dISND/D6K5X7Xnmz6fArBi1wWWbD+X6WtnBfO85kSE6y7zt797OSWjOpaSL9OsqWOqDNJLfgnMwsKCrj16YVWgAJPHf8/Wjevo3qtPyrCgjPxX74kfanllF30a/0I7gxrGAQEB1KxZk0JJb4JXrFgRtVrN3bt3qVWrFkZGRkydOpWTJ0+ye/fu/1TD+OHDhzx8+PCd0zExMWHixIkpjWKAHj16sGvXLi5fvoyfnx92dvotx+vt7c3y5cszdf2//voLIyMjZsyYkdIoBs3co5MmTaJfv37s2rUrVcMYYPz48amm0vn0009p0aIFzs7O3Lp1i1q1snYi8Pz5rXgVEUFERJjW/REpY+QyHveVPKYsIlx7WgDhSfveHEdmYmLC5J8XcOncGc6dOUlISBA2tnY0a9WOGrXrMXe6Zgq/glreftbF0sqKiIjwlHF7afKRFFeBAgUzTivpBq0rLXg9ltCqQEGioiL5da6m3H+YMFnvPOvDKimuMB15SR7PV6CgHnFZZRxX8rhVff6d3kVIeDQFLfNibal9DHGhpLHFusYg65LH2IhmdcsBcFDP3mIjIwUrfurKgA51AVi15xLfLzyQqetmJSsrKyLCdZd5aMp3OWfHZmZUx5K/i1b61DE9vothmfwutvysDYsXzONlYCDuDx9Qu65+L4r+V++JH2p5ifePQQ1jIyMjrN4YjF+kSBHy5s3Lo0evB9ubmZlRo0YNHj9+/O65/IB88cUXzJs3T+f+5DHFGSlWrBgODmnfBK5Zsyb379/H1dVV74Zx3bp12bJli879y5YtS9VwjoyMxMPDg1KlSmFrm3bO05o1a2JsbJym99vMzIyaNWtqPd7Z2RlXV9csbxg7Fi+Jr48XAX6+qSafTxbgr5lT0t4h41k/HIuXTHXO2xITEwkK1CycUFRLeg0+aUaDT5ql2f7EXfOHUvFSZTLMQ7LiJUri7eWJv5+v1pfe/Pw04/sdHDOOq3jJkqnOeVtiYiKBSXE5Ohbjoet9/P00/wad27fUme7nbTSx/r56IzVr180wHwAlSpbCy8sTPz9fqlEjzX7fpLfUHYtlPI6+ZEnN1Gd+vunEFeAPQDE90nsX7i8CKO1YiGJ2Bbh673ma/Y52mkbDU6/MLWLRoHoprPKZExwWxYXbzzI8Po+xEZtm9aZzc01dWLjlHyYtP5Kpa2a1kiVL4eXpia+vb6pFWJIll1+xHHp3IllyHfPLoI456jFjUIkSJQHw16OOOSSlFx8fj6+PN2q1muJJ57/Nrqg9LwMDCc7EIjS5/Z6Y28oru0h/seEMeq5tY2ODt3fqeUGLFy+Ou7t7qm1KpTLHVzPKLYoW1b6kpIWF5hFQeHg44eHhLFu2LM3n6tWr73TtV69eAZBfx7jSPHnyYG1tTVRUVKrtuhrqyWvXh4eHv1O+tClXXvNSn9sD7b1pD101c186VaycYVolS5fFRKnE2/M5kVreln722J3Y2BgKFS6SMkVRdFQUh/f9yYE9O7Sm6efrjefzZ1gXKkyxpB8ZfZRPyq/rfe3Tb7kmzQdcsVKVDNMqU6YcSqUSzxcevIpIG9fjR27ExsRQuIgNNrZ2WOTLR9XqNXV+klWoVIWq1WtikU//x6EVK2niSp7b9m337mq2V66sR1xlNXE9f+5BhJa4Hrm7ERMTQxEbm5Rp27LL/x5oprWqXVH7j3LdpHmOb7hmbkaJ5PMu3/XQaxjFip+6pTSKp6089q83iiHjMne5eweAyjrm3c0uFZLylVyX3nbfJRN1LOm7+OK5jjrmrqljRYrYpEwDtm/Pn3Tt2Ib5s3UvYeyTNF1a4cJFMsxDstx6T8yt5SXePwY1jOvVq8e9e/c4der1ajcVKlTg4cOHeHh4AJrlE2/fvk2RIvIFMUR0dLTW7cmNS2tra8LDw1m+fHmaz7u+6Jbc+Pb399e6PzExkVevXqV59Kkrz8mPUK2trd8pX9ok90acPXU8zRjGoMAAbly9iFJpqrXX4m1mZubUqlOfxMRETh47mGb/iSP7AWjSsk3KNqVSybqVS1i5eH5Kz8mbdm/bCECbjl0yNUPLp02aA3DyxLGUN6iTBQYGcOXSBZSmpnzarEWGaZmZm1P344YkJiZy9PD+NPsPH9CswtiytWZYjFP5ivyxfqvOT7J5C5bwx/qtOJXXf8aRps00cZ04fjRNXAEB/ly6eB5TU1OaNtfdU53M3Nycjxto4jp0MO1TmP37/gKgdZu0K3ZltUNn7wPQrWV1TJWpH8QVLWxJy4+diI6J4+A/mXt5rtpHmrlZkxve6RnZtUHK7BUTlhzil405u5KcLs2aa76jx48d0VrmFy9oyrxZi4zLPCt92jSpjh3XUscCNHXM1NSUJnrWsXr1Nd/FI4fS1rFDyXWszeuhZ7Vq1wHg1s0bWufKPX3yBMFBQVhaWlK5qvbFUbTJtffEXFpe2UXmMTacQQ3jwYMHY2pqytixY5kyZQoA3bp1Iz4+nsGDBzNv3jy6d+9OUFAQ9evXz9IM/1e4uWl6u9528+ZNjI2NqVy5Mo6Ojri5uaX5jB079p2unS9fPkqUKEFAQAAvXqSddP/u3btER0fj5OSUaru/vz9+fmkfud28qVmJqHr1d58H923lnCpQo/bHBL0MZP7Mn4iJ1vRih4WG8POUH4lTqWjZtiMFCqZulPt4efLi+bOU+YKTdeszEIANfyzj1o3XPe+nTxzm0N5dmCiVfN61V8p24zx5qN/oU9RqNYvnzyQyUtPbnpCQwN6dWziyfzeWVgXo1L1PpuJyqlCROvXq8zIwgBmTxxOdFFdoSAiTxn2LSqWiXYdOFHwrLi/PF3g8e0poSOq4+g4YDMCq5Yu5fvX1TDHHjxzkrz93oFQq6dYjc3k0RIWKlaj3cQMCAwKYNPFHopOeOoSEhDDu+29QqVR0+PyLNH9EeXq+4NnTpylz4iYbOGgoAMuXLObqlddxHTl0kD93bkepVNKzd99sjgpuu3lz+qo79jZWbJjRi7xmmpfwClnlZducfpiZmrDlyA1ehqYeY1zKoRAflSiSMgb5bZXLap4cuTxKfzaJQlZ5mTVa8yO+4cDVf+1FO20qVKzEx/U1Zf7T+B9TnjSFhATz47dfo1Kp6NgpbZlnt/IVKlK3Xn0CAwOYNil1Hfvpx6Q61rETBa31rGMDNXVs5bLUdezYkYPs2aWpY917vq5jpcuWo0GjT0hISOCncd+lamz978Z1fpkzE4DBw0ehVCr1jiu33hNza3mJ949BY4xLlizJ2rVrmTFjRsrKdjVr1qRXr17s2LGDjRs3AppH6+/aSPuvioyMZNGiRUyYMCHlL7KtW7fi5ubGZ599lu0/Il26dGHhwoXMnDmTZcuWpbyAFxISwuzZswG0Lvc9d+5cFixYgEnSCmmnT5/mn3/+oXLlylSooH2J0Hf1zfgpfDtyIBf+OcXtm1cpal+MF8+fEhsTQ+myTgwf812acyZ8PRx/Px/6Dh5JvyFfpmyvXK0mPfoOZtfW9Uz4ejjFS5YmLi4uZVWnHyZMwzZp5ahkI78ex53/Xefa5fP07dQK+2LFeRngT2hIMHnzWvDzb78b9IbyhMkzGDGoD3+fdubGtSs4OBbD49lTYmKiKfeRE2O//THNOWNHDsbP14chw0cxdOSYlO3VatSi36ChbNmwlq++HEKp0mVQqVQpN/eJU2ZS1F776lZZbcq0mQzs34vTJ525duUKjsWK8ezZU2Kio/nIqTzffT8uzTkjhg7E18eHEV+OZuSo1/eUGjVrMWjIMDasW8PIYYMoXaYscSoVnkmrqE2d/jP2ORTX6Ll7+HvNaL5oVpUmtcvy1DuI8iVtsTBXcsfdh4lLD6U559jy4ZSwt+bnNc7MXnsyzX7bQprhTF4B6S9aMKhTPfLl1cwyUN3JgdOrR+k89rsF+3N82rYp02cysG8vTp08wdWrlylWrBhPn2rK3MmpPN/9MD5H85Ns4tQZDBvYh79POXPj6hUcihXD4+nrOvbVd2nr2Jjhg/H19WHoiFEM+/J1Hateoxb9Bw9l8/q1jBmhqWNxcaqUVRd/mpa2jk2ZOZsvhw7goet9unVqR4kSJYmLi8PzhWacepduPenVt3+m48qt98TcWl7ZIYdXfn9nx44dY+PGjTx+/BhjY2Nq1KjB6NGjqapjCfCMXLt2jQEDBtC0aVNWrMjcFHoGr3xXu3ZtDh06lGqc6bRp02jbti23bt3C2tqa1q1bp4wvFZljamrK9u3buXXrFjVr1sTd3Z2LFy/i6OjIpEmTsv36gwcP5vLly5w/f54OHTrQqFEj4uLiOHv2LIGBgXTr1o327dunOe/ixYt07tyZ+vXr4+3tzZkzZ7CysmLOnDnZllc7e0eWr9/BlnUruXbpHM+euFOwUGEadmhOvyEjMTPP3Gpjg7/8mlJlP2L/n9t49lTzQmmV6rXo0Xcwdeo3SnO8pVUBlq7ZxuZ1K7l++TzPHj/CqkBBWrbpSO+Bw7HX4wU5bewdHNmwbQ9rVy3n4oWzPH7kRqHChenYtCtDR45OmUpJX6PGfkfZck78uX0LTx5r4qpeszb9Bw2lfsNPDMqjIRwcHdm+6y9W/b6M8+fP8sjdncKFC9OsSzdGfjkG87yZi+urb76n3EdO7Ni2hUdJE+7XrFWbQUOG06hxzsX13DeEBgOWMHl4K9o0qECVskXxD4pgw4Gr/LzGmaiYzE3VZmSkwCqfZoYX38D0x+fXr1oy5b9rlNe+zG0yy3w5Oy0aaF7q3LF7LyuXL+PcuX9wd9OUefMu3Rg5emzK1Hs5zd7BkU3b97B65XIunT/LY3dNHfu8WVeGGVDHRn+lqWO7tm/hSdLL6DVqaepYg0Zpv4vW1oVYv2UXWzet57TzcTxfPMfU1Iw69T6mW4/eeg2V0iY33xNzY3n9161cuZLFixfj6OhI9+7dCQ8P58iRI1y4cIFVq1bRuHHjTKUXERHB+PHjX8/ZnUkKtSEzzos09u7dy8SJE/WelWLu3Ll07txZ58p3tra2LFq0iF9//RVXV1cKFixIy5YtGTVqlN69xVevXk1ZgEWfWSnGjBmTqoc/Li6OrVu3sn//fp49e4ZSqaRChQr06tUrzTRtzZo1w9vbmwMHDvDrr79y8+ZNLCwsaNy4MaNHj6aYHm8Kp8fjZc4uY5tTLM0zvxLah8DMJGvnq36fFGqctkc7Nwi5+Ou/nYVsEROX8G9nIVuERmZ+TuwPRQGL3HlfLGCe/mI3Wanv1js5dq2tfQ0fU/348WM6dOhA2bJl2bVrV8ofyQ8ePKBXr15YWVnh7Oys17zbyX788UcOHtSMiW/evHmme4z1ahh7embuTeq3vWuj6L8muWF87tz7M04wI8kN4/v372dqNSN9ScP4wyIN4w+PNIw/LNIw/vBIwzityZMns3v3bhYvXkybNm1S7fv555/ZsmULixYtStMZp8uxY8f45ptvaNGiBadOnTKoYaxXC6Zly5YGv3moUChwdXU16FwhhBBCCJE5H8pkEZcva158bNiwYZp9DRo0YMuWLVy6dEmvhrG/vz/Tp0+nXr169OvXL9XMaZmhV8PY3t4+44OEEEIIIYTQQ1xcHN7e3lhbW2OZtMrim4onLfrz5MmTDNNSq9VMnDiR+Ph45s2b904jHfRqGJ85837MhymEEEIIIdKXk/MLN2/ePN39p0+f1ro9NDQUtVqdaiXlNyU3lrUt4PS2LVu2cPHiRebOnYu9vX32N4xFznJzc/u3s5Bp8seTEEIIIfQVHx8PkDK969uS54N+e0GXtz1+/JgFCxbQokULOnfu/M75koaxEEIIIUQukpPzGOvqEc5I8kwTcXHaXyRVqVQA6U7nGBcXx48//oiFhQUzZ840KB9vk4axEEIIIYTIUfnz58fY2FjnUInwcM387drGHydbunQprq6u/P777xQqVChL8iUNYyGEEEKIXCQnxxgbysTEhOLFi+Ph4UFkZCQWFhap9r94oVnBtGzZsjrTOHLkCACjR4/Wuv/06dM4OTlluJ7Dm6RhLIQQQgghclzdunV59uwZly9fpkWL1CsHXrx4EYA6deroPL9///5ae5y9vb3Zt28fpUqVol27djg4OGg5WztpGAshhBBC5CLvf3+xRrdu3fjzzz9ZsmQJ9erVI3/+/AA8fPiQv/76Czs7uzQN5jcNHDhQ6/arV6+yb98+SpcunWpFX31Iw1gIIYQQQuS4KlWqMGjQINavX0+HDh1o3bo1r1694vDhw8THxzNnzpyU2SnCw8PZtGkTQKYbu5mhV8M4MTHxnS5iZJR7l4cVQgghhBCGGT9+PKVLl2b79u1s374dCwsL6taty5gxY6hatWrKceHh4Sxfvhx4DxrGlSpVMvgCsiS0EEIIIUTOMfoAXr57U7du3ejWrVu6xzg6Ouq9zkO9evUMXhNCr4axWq1Od7+JiQl2dnYYGxsTGBhIZGQkAIULF053/jkhhBBCCCHeF3o1jB8+fJjq/0NDQ+nbty9RUVH89NNPNGnShDx5Xid1/fp1ZsyYQWxsrN7TYwghhBBCiHf3gXUYv1cMGvy7cOFCvL292bx5My1atEjVKAbN1BobNmwgODiY+fPnZ0lGhRBCCCGEyE4GzUpx8uRJ6tWrh6Ojo85jihQpwscff8yFCxcMzpwQQgghhMicD2GBj/eVQT3GKpWKhISEDI9LHmsshBBCCCHE+86ghnG5cuW4evUqjx490nnMzZs3uX79OpUrVzY4c0IIIYQQInMUipz75DYGNYwHDBiASqWiX79+bNmyhefPnxMbG0tsbCxPnjzhjz/+YNiwYajVaoYNG5bVeRZCCCGEECLLGTTGuE2bNri7u7Nq1SrmzJnDnDlzUu1Xq9WYmJgwdepU6tevnyUZFUIIIYQQGfvQ5jF+nxi8JPTXX39Ns2bN2LlzJzdu3CAgIAAAOzs7GjRoQO/evSlTpkyWZVQIIYQQQojsZHDDGDRrXFepUiWr8iKEEEIIId6RdBgb7p0axgBxcXE8ePAAX19fChcuTK1atfDx8cHe3j4r8ieEEEIIIUSOMLhhHB8fz++//862bduIiIgAoEOHDtSqVYvx48cTGRnJokWLKFGiRJZlVgghhBBCpE/mMTacQQ3j+Ph4RowYwaVLl8iTJw+VK1fGxcUlZX9kZCSurq706dOH/fv3U7hw4SzLsPhvMlMa/9tZyBZPAl7921nIFnZWZv92FrJN0Plf/u0sZAu7AVv/7SxkC58Nff7tLGSLQvmV/3YWsk1CovrfzoL4DzNourZt27Zx8eJFGjZsyOnTp9m9e3eq/du3b6dTp068fPmSdevWZUlGhRBCCCFExoxy8JPbGBTTvn37KFCgAEuWLMHGxibNfjMzM2bNmoWNjQ3nzp1750wKIYQQQgiR3QxqGHt4eFC7dm0sLCx0HmNiYkLVqlXx8fExOHNCCCGEECJzFApFjn1yG4Maxnny5CE8PDzD40JDQ8mT550nvhBCCCGEECLbGdQwrlChAi4uLnh7e+s8xtPTExcXF8qXL29w5oQQQgghROYYKXLuk9sY1DDu1asX0dHRjBo1CldX1zT73dzcGDt2LCqViq5du75zJoUQQgghhMhuBo1zaNu2LZcuXWLPnj106dKF/Pnzo1AoOH/+PE2aNMHf3x+1Wk27du34/PPPszrPQgghhBBCh9zYk5tTDB4A/PPPP1O9enXWrVvHs2fPAAgJCQHA3t6eAQMG0L9//6zJpRBCCCGEENnsnd6M69q1K127diUwMBBfX18SExMpUqQIDg4OWZU/IYQQQgiRCblxtoicYlDDeNu2bbRr144CBQoAUKRIEYoUKZKlGRNCCCGEECInGfTy3axZs2jcuDGjR4/m5MmTxMXFZXW+hBBCCCGEAWRWCsMZ1GPcq1cvTpw4wenTpzlz5gyWlpa0bt2azz//nJo1a2Z1HoUQQgghhMh2BvUYT5s2jfPnz7NmzRo6dOhAfHw8u3btok+fPrRs2ZLly5fz4sWLrM6rEEIIIYTIgEKRc5/cxuCX74yNjWncuDGNGzdGpVJx+vRpjhw5wrlz51i+fDm///471aorzqcvAAAgAElEQVRVo1OnTvTs2TMr8yyEEEIIIUSWy5L1mpVKJW3atKFNmza8evUKZ2dnli5dyu3bt7lz5440jIUQQgghcohRbuzKzSFZ0jAGUKlUnD17luPHj3Pu3DkiIiJQKBQy5lgIIYQQQnwQ3qlhnJCQwIULFzh69CinT58mMjIStVpNiRIlGDBgAJ06dcLR0TGr8iqEEEIIIUS2MahhfOXKFY4ePYqzszNhYWGo1WqsrKzo3r07nTp1okaNGlmdTyGEEEIIoQeDZlYQgIEN44EDB2pOzpOHpk2b0qlTJ5o2bYqJiUlW5k0IIYQQQogcY1DDuHLlynzxxRepVr8TQgghhBD/Pnn3znAG9babm5vj5uYmjWIhhBBCCJFrGNRj7OLigrGxcVbnRQiDBb0MZN2qZVy5eJ7wsFAKF7Hl02YtGDD0S/JaWGQ6vVMnjrJnxxaePHZHqTTFqXxFevUfRJ2PG+o8x/2hK1s3rsXl1k0iIsKxsbWjSfNW9BsyAnPzvAbFFRL0kj2bV3Hn+iVeRYRRsFAR6jRsxhd9hmCeN/Nxven4vh1s/WMRUxasxqly9VT7zjkfZvXCmXqlM/y7qXzSqn2mrh30MpCNq5dz7fIFwsNCKVTEhsZNWtBv8EiDyuuM81H27trK08ePUJoqKedUkR59B1G7XgOtxycmJnJo758cP7yPFx7PUBgpKFmqDO0+70rrDl+gMLC7JTAwgBXLl3Lh/FnCQkOxsbGlectWDB85CguLfJlO79jRw2zfuplH7m4olaZUqFiJgYOHUL9BI73O37ZlEwt+mcv6TduoUbNWpq//JtsC5kzqWo2W1e2xzmeKb0gUB6958su+u7yKic90etVKWvNtx0rUd7KhgIUS76Ao9l97zoL9LkTFJqQ5XpnHiJGty9Pl45KUKZofI4WCp34R7LnswcrjD4iNSzQortxaZi8DA1i5fCkXL5xLiatZi1YMHTkKCwPq2PGjR9ixdTOPHyXHVZH+g4bycQPt90SVSsWOrZtxPn6UF8+fk6hOpHjxEnzWph29+vbH1NTUwLgC+WPFUi4lxVXExpamzVsyZIRhcZ04doRd2zbz+JHmXl++YkX6DhiiM66oqEg2rl3NmVPO+Pn6kN/Skuo1atFv4BAqVq5iUEzZQaZrM5xCrVarM3tSw4YNKVu2LJs2bcqOPAmRhl94nM59wUEvGTmwF/5+vlhaWVHU3oHnz54RExNNyVJlWLF+Gxb59P+B27phDWtWLEGhUFCydFliY6Lx8fZCoVDw/cRpdPiia5pzTh47zNwZk0hISKBwERvy57fkxfNnJCQkUM6pAktXbyJv3rSNY8+gKJ35CAsJYurXgwgK8CNffkuK2Nnj88KD2NgYHIqXYtqideQ14Icb4Km7K7PHfUlsTLTWhvGd65c4sGODzvNfvQrH58UzACb9sooKVVNPy2hnZabz3JDgIEYP6U2Any/5LTXl9cLjKTExMZQoVYala7ZkqkGyfdNa1q9aikKhoESpMsTGxuCbVF7fjJ9Cu89Tl1diYiKzJv/A+b9PoVAoKGqvmTnH18cLtVpNi9btmTBtjs7rFcqn1Lo96OVL+vbujp+vD1ZWVtg7OPLs2VNioqMpXaYsm7buJF8mvofr1v7B8iWLUCgUlClTlpiYGLy8PFEoFEyeOoPOXbune/79+y4MGzSA6OgovRpZ9oO26dxXxNKMM7NaU6xwPoIjYnke+IqP7K2wMMvDA69QWk0/QUS07jr6tm4NSrJyZAPyGBvhExxFaKSKj+wtyWNsxJ1nwbSd5Uxk7OvGtoVpHg5OakGtMoVJTFTjEfAKNWpK2uTD2MiIa48C6TT3lNYGtc+GPjrz8SGXWUI6P91BQS8Z0Ls7fr6+r+N6+pSYmGhKlynD+i2Zi2vD2tX8vlQTV+mkuLyT4vppynS+eCuuqKhIRg4dhOs9FxQKBQ6OxVAowNvLi8TERKpUrcaK1esx13JPBEhI1B5bUNBLBvftgZ+v5l5v7+CIR1JcpUqXYe3mHZmKa+O61axctlhrXBMmT6dTl26pjo+JjmbogN48cnfDxMSEEiVLERYaSmBgAMZ58jBp6kzadeyk83oFzHOuQ3HK8Uc5dq1Zrcvl2LVygkFDKb788kuuXbvG+vXrUalUWZ0nITJl7ozJ+Pv50rJNe/46+jerN//JroMnqFy1Oh7PnrBy6W96p3Xf5Q5rVy7FwiIfy9duYePOfezYf5xJM+aiUChY8utsfH28U53j+dyD+bOmkJiYyFc/TGTPkdNs3LWfDTv34eBYjEduD9i6YXWm4/rjt5kEBfjRsFkblm07yqxlm1m06QDlKlbF+8Uzdqxdluk0AZ64ubJgyrfExkTrPKZanQZMXbhG62fKb6uxLlQEgNZf9EzTKM7IL7MmE+DnS4vW7dl16DQrNuxk697jVKpSnefPnrB62UK903K9d4cNfywjr0U+lvyxmbXb9rJlz1EmTJuDQqFg+W9z8fNNXV4njx3i/N+nyGuRj4Ur1rN5zxE27znCL0tXY2Zuzqnjhzl94kimYgKYOnkifr4+tGvfEecz59m+6y+OHD9Nteo1ePrkMYt/+0XvtO7euc3vSxeTL18+Nmzezu59hzh07CQ/z/kFhULBvDmz8PH20nn+/XsujB01guho3X94ZcaKkfUpVjgfuy48pfyYv2g65RhVv9nHFfcAKjgWYGYv/b8DZezys3x4fYwUCsZtuk7FsXtpMOEw9ccf5qlfBNVKWfPd55VTnTO9Vw1qlSnMQ+9Q6k84TM3vD1Dr+4M0/ukoj33DqVuuCNN7Zn7O/NxaZjMm/4Sfry9t2nfg2OlzbNm5h0PHT1G1eg2ePnnCkoW/6p2Wy53brFi2GIt8+Vi3eRu79h7kwFFnZs6Zj0Kh4Je5P+PjnbqOLVv0G673XChVugy79h5k/5ET7Dt8gu1/7qN4iRK43L3D0sX635eTzZqqiat1uw4cOXmWTdt3s//oSapWq8Gzp09YtigTcd29w6rlS7DIl481G7exfc8B9h4+wfTZ81AoFCyYlzauxb/N55G7G07lK7Dn4DG27d7P4ZP/MHHKDBLi45n383T8/XwzHVd2kCWhDWdQw9jT05MSJUrw66+/UrNmTdq1a0evXr3o06dPmk/fvn2zOs9CpHjyyI1rly9Q0NqaH3+ajlKp6c0rUNCaGfMWolQqOXZoHyHBQXqlt2PzetRqNQOGfUnlqq97UVu17UCnbj2Ji4tjz44tqc5Zt2oZcXFx9OgzgC49+qQ8hi9RsjSjvx0PgPPRQ5mK68XTR9y9cRnLAtYM+XoiJklxWRYoyFeT5mJiouTcyUOEhQbrnaZareb0kb38/OMIwsNCMpWfN508tJt7t65h51CM7oNGZ+rcp4/duX7lIgUKWvPt+KmpymvK7AWYKJWcOLJf7/L6c+tG1Go1/YeMpGKVainbW7RuT8cumvLau3NrqnPOOB8FoFf/IVSp/rpHrkbtevToMwiAU8cPZyoudzc3Ll08j7V1ISZPm5kSl7W1Nb/8thilUsmB/fsIDtIvrk0b1qFWqxk+cjTVqr+e/rJdh45079mbuLg4tm3dnOY8tVrNnj93MmRgX0KC9f9upKdSsQK0rOZAQFg0X6+9iipeM2QhKCKWgUvOE6NKoM+npSlsqd+j8UndqmFqYszyow9Y7eyWsv2Rbzg/bb0BQM/GpVK25zU1pu+nZUhMVDNy5SXcvMNS9rl6hjJi5UUA+jcpi5mJ/j1yubXMHrm/jmvS1NdxFbS2Zv4CTVyHMhHX5o2auIaNHE3Vaq/jatu+I92S4tqx9fXT4+ioKA7u34tCoWDG7HmULlM2ZV/Zjz5i5uz5ABzYu4eYmJhMxXX54gUKWhdi4pQZqeKa8+silEolhw/sI1jPe8fWpLiGjhhFlWqv7/Vt2nWka49exMXFsXPb6/KKiYnh+BHNfXz67PnYFbVP2depSzcafdIElUqF87Gjesck3k8GNYw3bdqEh4cHarWa+Ph4njx5wq1bt7h586bWT1ZycnLCyckpS9NMz4MHDzh58mSOXe995OzszMOHDw0+f8KECTg5OXHp0qUszJXGqeOam1CT5p9hapb68X3hIjbUbdCI+Ph4Lp3/J8O0oqKiuHT+LAqFglZt0o6ZbdexMwBnz7z+PkRHa85RmprSd9CwNOfU+bgBg0eMoe+gYSQkpH3Mq8ulf04AUK9xc5SmqeMqWKgIVevUJyE+nltXzuud5rSvB7Fh2Tzi41R06j2EwjZF9T43WXhoCH9uXAlAvy9/QKnM3DjB00mN0k+btdJeXh9ryuvKhbMZphUdFcXlC5ryav5ZuzT723T4AoDz/5xKtf1lYAAApcqkffxXzqkCAIEBfnpE89qxo5qGdMtWn2H2Vlw2NrY0bPQJ8fFxnD37d4ZpRUVFcu7s3ygUCtq175hmf6fOmqEhp086p9nXr3d3Zs+ajkqlYtiIURS1t09zTGZ1bVASgP1XXxATl/o77Bcazak73ijzGNOmRsaLOeU1NaZ1DUeiVfH8duBemv1nXHyZvfsOv+2/lzJGsmbpwpgr8+AdHMXtZ2kbjjefBBEcEYuZ0hgnByu948qtZXY8Ka7mWuIqYmNDg0aNiY+P45zecf2DQqGgbbsOafZ//kUXAM6cen1PvH//HrGxsdjY2lGxUuU051SuWg0rKytUKhUeT5/oHZfzMc1TnOYttcdVv2Fj4uPjuXD2H73iOn9OE1drLXF16KSJ6+/Tr+MKDwujbYdOtGrdLlVjP1nytoBM3juyi5Ei5z65jUEN482bN+v9+ZDHIZ89e5bOnTtz717aG/h/xYIFCxg7dizBWdT7lNUeuLoAULFyVa37K1bSbL97+1aGaT166EpCQjz2Do4UtC6UZn/psh9hampGYIA/fr4+muvfv0dsbAyVqlQjv2XaH2WlUsmAoSPp1LVnpl5Yfep2H4Ay5dP+sACUcdJsd7t/R/803V2xcyjOhLnL6dp/hN7nvWn/jvXEREVSpWY9qtWun+nz3ZLKq4KO8ipfSfPyyr27epSXm6a8itprL69SZcqllJd/UnkBFLaxBTS912977qH5oS5cxDbD67/p/r27AFSpWl3r/spVNPHe/l/GHQUPXF2Jj4/H0bEY1oXSxlWu3EeYmZnh7++Hz1vDeu7fc6FEyZKsWrOBUWO+ylQMutQqUxiAG49fat1/44mmh+5jJxu90sprmofrj14SFpV2GJ4qPpFf97uw/vQjEpPG0D7wCqXforNM3qb9385IocBMqalbRpn4lc6tZXbfRVPHqlStpnV/5aQnK3du/S/DtB66upIQH4+DjrjKlvsI06S4koeYlSlTll8WLuHbH8ZpTTMhIYGY2FjNfyfq/8Lk/XuauCpX1X7vqJRcXrcyLi+3Bw+S4nLEWsu9IzmugDfisrG1ZdxPU5g1T/twjYcPXAFwcCyecTDivWbQrBR169bN6ny8l4KCgkjMRMXNjV6+1P5j+L7wTRqzV9TBQet+26THXT7enhmmlTz+z85ee1pGRkbY2Nrh+cIDHy9P7Ira4/H0MQDFS2ge/V65eJ6/Tx4nMMCfwjY2tGrTgdr1Mt+ADEhqyNnYae89Kmxjl3Sc7jGLbxvy9U80btmePHkMWwn+pb8vZ47uBaCLgQ1r36Qxe3ZFdZSXnaYXW5/ySv7BSq+8itja4vXiOT7eninfhTbtv+Dm1Uvs2rqBKtVrUqWaZmyqq8sddmxeB0CHL9J/SeptXl6a/Do4au81Te4F9PTMOC7vpLTsHbSnZWRkhK2dHc89PPDy9MT+jfinTJ9Fh46dsnSxpZI2mpeZnge+0rrf82UkAKVsM37pqXxSj667j2Y4RItq9nT+uAT21nnxDY5i54VnnL2fusctKCKWQzd0/7s1qWxHXtM8xCck8tQvPOOAkuTWMvP2Tj8vyUMAvDxf6JGWV1JauuuYra0dL55r4ipq70BBa2uatWilM81rVy4TGxODsbExxYuXyDAPyXyS/43t048ruSzS451BWm/G5e2liUuXiPBwNq1fw7UrlyhoXYg2Wnqg/w0yK4XhDPuFfENcXBwPHjzA19eXwoULU6tWLXx8fLDPgkd4QmQkLFQzVtbSSvuc2vnzWwIQHhqqd1pWOtICyG+pSS8sTJNegL9fyvYZk37kjPOxVMefOHKQzj168/UPP2V4/TdFhGvSz6elFxrAIimuV+FhWvdr07SN7rel9XHy0G7i4+IoV7EqZXX0ZGckLCz98sqXXF5hGceVUdnrSq9Ji88I8Pdl89oVfPflIOwdimFkZISX53Ms8uXjm/FTafhpM/0CShIaoikvXd8dy6RyTP7epJtW8vcwnXniU9J763vd+a236LOCdX7NcJngiFit+0MjNdsL5st4WI1DIYukc1SsHd0oZZhGsl6flOGPEw8Zv/mGXnkzNlIwtYemx/eMiy9hUfrPjJFbyyw5Ll3rDFi+dQ9LPy194tI/vfj4eH5fugiAevUbpNxP9ZHRv3FKPvS41yenZZlOXPkzSO+eyx3mzpyG54vnxMbGUrpMWWbM+SXdfyvxYTB4Oe34+HiWLFlCw4YN6dGjB9988w27du0CYPz48XTu3Jnnz59nWUbT069fP2rXrk1ISAhTp06lUaNGVKlShfbt27NtW9opiB4+fMiYMWNo2rQplStX5pNPPmH8+PF4eHikSnPixIkArFq1CicnJ65evQpoxjmPGDGCXbt20aBBA6pXr84PP/yQsu+TTz5Jc00vLy+cnJzo1atXyra9e/fi5OTEyZMn2b59O23btqVKlSo0a9aM1atXo1arcXd3Z9iwYdSsWZOGDRvy/fffExgYmCb9J0+e8P3339OwYUMqV65M8+bNmT9/PmFvNTCWLVuGk5MTLi4urF69ms8++4zKlSvTpEkT5s2bx//ZO++wKK6vAb+IUiyAqFhARVGxYo09RrF3LERR7GI30Rh715ho/CXRaDQx9t57r7GLGmOJBQVFehFBUMrSvj9mZ2HZXbZYkvjdNw/PE6ecOWfumbtn7px77ps3b1THurq6sm/fPgAGDRqkltudkpLCunXr6NWrF/Xq1aN69eo0bdqUcePG4efnx4ciRflJztJSe3kwuVamQqH9R12brJw5vdmxyCEvKVGaQX5o7y7OnznJ8DHjOXDqIkfPXWPi9DlYWlqxd8dW9u3abqBFqMnXlcMrb09N/TBVYVIVCi6cknIX23n0NlmOQtVe2u2S29GQ9tInKzd5jk5lKFHKkczMTEJDgggOkuZMFCxkY1RpP5mUFGkSkaWVLrss1XTOjeRk6RirXO2S9qUYcJ/eFmtlmkLO/GKZZIW03ZCJbwWspLGYQS0r4tGgDLO33aL88F2UHrqDsb9fIzEljeFtKzOkVSWDdFvUvx61yhVBkZbONztvG3SOzMfaZiq7dD1jSntTUvT3HbIsq1z6RHmuQIoB9+l/Cxfw6OED8ubNx6ix4/Qer66LoX2HIXYZ3nek6JD3NMAf/yePVbJiX77E9+plvdf+UIiqFKZj0ohxWloaw4cP58qVK+TNm5fq1atzT5nXBPDmzRsePHhA37592b9/P0WLFn1nCuemU79+/UhMTKRt27akpqZy+PBh5s2bR548eVQBaWBgIAMGDCA9PZ02bdpQpEgRAgICOHjwIH/88QeHDx+mWLFidOvWjUKFCnHmzBnq1atHw4YNccz2OenevXtcvXoVDw8PMjMzqVq1qsm6r1ixgsDAQNq3b0/jxo05ePAgP/zwAxEREezfvx83Nzd69+7NtWvXOHz4MDExMaxfv151/rVr1xg5ciSpqam0atUKJycnHj58yNq1azl79izbtm3D3t5e7Zpz584lICCAdu3a4e7uzokTJ1i3bh2RkZH89JP0Rj9mzBhOnz7No0eP6Nq1K6VLlwakOrA+Pj74+vpSp04devbsSXp6Ordu3eLYsWNcuHCBY8eOUby4cXmappAnT55c013kPEVDFmwwJD8xU1lf0wzpWDngevUqjkHDRtNnwBDVsZ08epKqSGXJ4gVsXL2Szt16kDevYZ9L8+TJk2v+XWamvO/D9Eo3Lp8l4VUchYs6UK9Jc5Pl6Gsv2S4zA+wyM6i9lPKytf++nVv45adF2NjaMW3uQho1bU56ehoX/zjDyqWLWTBzEq9iY/Hw9NIlVoM8ecwNs8sgP9Q/XiFfy5D79LakZ2RinotK8nNjSEV8OXguUsiKb3ffYenhB6p9m/7wxzJfHv43sD6TutVgw7knpKXrFjrdsyZDW0sv6/N23Obuc+MqrXysbabXrgzD+0QzM/12aXvGtLFi2RJ275QGCMZ8OZ7KVYz7zdTf18t6GCDLgIMy9chr2qw5Zy/fICkxkT/Onmb5kv+xfMkPpKSkMHT4KP1KCP61mBQYb9myhcuXL9O0aVO+/fZbHBwcqFy5smr/1q1bmTNnDvv372fNmjVMnjz5nSmsi6SkJGxsbNi1axfW1tYAdO7cGW9vbzZv3qwKjHfs2EFcXBzr16+nUaOs3M8VK1awdOlS9u7dy/Dhw+neXapAIAfGY8eOVbteTEwM8+bNo1evXm+t++PHj9m5cyfVqlUDoFmzZvj4+LBlyxaGDx/OV199BUhpK+3atePq1atERUXh4OBASkqKarR6586dagH6tm3bmDNnDgsWLOCHH9RrRgYHB3Po0CGclPl1I0aMoE2bNpw4cYLo6GiKFSvG2LFjCQ0N5dGjR3h4eNC4sbSK2KlTp/D19aV79+589913anLHjx/P0aNHOX36NH376i6s/66wss7P64R4naM6qcq3/dxGgWXk1elyG62UR2jlURJ5VCFv3rx49RukcXzn7j1ZtWIJL1/G8PjRQ52TBHNiaWVN4usEnaMfqanSJ2MLE1ePMpYbl/8A4JPGzTE3Nz0Dy8ramtcJCTrvsULVXvrtMqS9FKnq8uJiX7J6xVIAZn6zmNr1GqiObd+5G4UL2zNj4lhWr/gJ9zYdsLE1rMqBtbU1CQmpOv1QoZDay5DVvuSFYHIbWZTbX9do57skMSUNi7zmWOoYEbbIKwVPSan6V79LUo4uK9LS+TlbUCyz/uwTZvWqRXE7a2o62/NngPbSW/P71GFsR6mv++3EI5YffWiQLdn5WNtMtkvXiLD8jBllVy6jwVnytPexmZmZLP1hMZs3SgsG9erjjfcAzb5SH9bW+UlIiNfdJ+rRQ02WctXQ3EaX9dklT9orUKAAPXt5YWtnx4zJE9i8fg2fe/VVpc78U3yM1SI+FCalUuzbtw87OzuWLl2Kg4PmTGQrKyvmz5+Pg4MDFy5ceGslDWXgwIGqoBjgk08+oVChQmopHfJCf3/++SfZF/0bOHAgf/zxBz4+miW3dNGuXbt3oDU0btxYFRQD1K2bVVs1uz758uWjRg1p1n6ochLT2bNniY6OxsvLS2PU2svLC2dnZ44fP87r1+oTZzp37qwKigFsbW2pU6cO6enphITkPqHL1dWVb7/9li++0JxB3bBhQ4APVsVCziuL15FrG6/MezMk76uQMghKyCVvV86jk/MS5c/upZxKa5QfA8ibNx+lHKWR9ohslRH0IefGvknQroucW1zI5v3ns6WlpfH3LSmNqG7jz95Klly5IyFe+yQp+d7b2hU2WFa8DlkACcpUIltbSd5N3yukpCRTqUo1taBYpmHTz3Cp6EpycjI3rl3Sq4OMra2cj6q9veQ8RbvC+u2Sg/Hc8qzjZHkG3Ke3Jfa1FCAULqB9xT/7grnnIGcnXlmJ4lnka62pGWnpmQRGSn1V6aKay/vmMTNjuU9DVVD8+yk/g/ORc/KxtplKl3jtubFyH2aUXQb0iXaFNfui9PR05s2eoQqKPXt58fVk4+ZbaOiip70M6TsMaa9XRrZX67btKVqsGElJSTx+ZPyLmuDfg0lDP4GBgTRt2jTXdcnz5cuHm5sbly9/uJwbZ2dnjW2FChUiISFB9e/u3buzfft2li1bxvbt22ncuDGNGzemWbNmlCxpeF1XW1tbVcf6tuTUW76vhQsXplChQmr75PqN8tusnMLy7Nkzli3TXAnN3NyctLQ0/Pz81AJubfdKDjLlkY3c9HV2diY1NZUHDx4QGBhISEgIjx8/5tq1awBG1ex9G0qXLUdYaAhREeGgpeySvAqRo1NpvbLkyhK6Vi7KyMjgRZRUA7eUUl7pMs5A7p8RzZXfoY2pBlHSqSxR4aHEREeibbHNGGWtTAcd1R3eJY/v3yYp8Q0FCtpQuUZt/SfkQukyzoSHhhAZGa62IIeMfO91zajPKQsgOrf2ipbbS5IXHRUJgFNp3bPhS5ctR8ATP9WxhlDWuRwhIcFERIRTE817FB4Rpryu/lJOzs6SH0aE67ZL1q20AfLelifh8ZQrXginogW4oaVkm5MygH0Wqb1qRXYCIqS+OBPdKRLycsA50yjympuxenRTPBpIbbf08H1mb9Nf1k8XH2ublXV2JjQkmIjwcLUFOWRkHZ0M6BPLGmBXlLJPdMpRpiwtNZXpUyZy5pRUk73fwMF8+dVEww3JQZmySrsiwtUW5JCJUPYDTqUNsKusM5B7Xx+t7DsclfLS0tIIDwslMzOTMsrzc1KiZCleREf/K8qbfog0q48Vk0aM8+bNm+sojUxcXJzJpaFMQdunoZwBS6VKldi1axddu3ZFoVBw4MABJk+eTNOmTRkzZozB5clyFhh/G/LrWC9eXtknN+R2OHv2LMuXL9f4CwiQ6rLmHBXJ7V5l6kkWzMzMZO3atTRv3pxu3boxfvx4Vq5cSXh4OFWqVDFIxrvCtYo00v7wvvZa0w/vSy8OlavW0CurnEsFLCwsCAl6zuvXCRr7A548JiUlmaLFHHAoXkLt+qHBQbx5rRkYZGZm6i0Dp1WXitJ9DFDWM9bQxU+y18W1mtb97xL/R5IOlaq5vVUaBUClypK+fg+0t9cjZZ1jVz9kAu0AACAASURBVAPay9mlAvksLAgJ1t5eT/2l9ipS1IFiyvJ2+ZUvnbExup/zl8p91jqeS23ICxn8fe+u1v1/35W2V6+u3y6XChWxsLDg+fNAtZd6mSeP/UhOTqaYgwPFS5QwWEdTuf1USmeo66JZ7xWgnrLO8Z8B+vvOv5SyyhcvRCFr7fn2cnm4oBzl4X4e2lAVFM/fefutgmL4eNtMtkuu+5sT2V657m9uVFDaFfQ8kNc67ErRYdc3c2epguKRY758q6AYoIrSrgd/a2+v+0q7qlYzvL102eUv21XMgeLKvn7f7p307NKeRQvm6pQr9/VFixbTq4Pg34tJgXGVKlW4d++e6nO+NoKDg7l3755a7vG/hYoVK/L9999z9epVdu3axfjx4ylbtiynTp1i4sS3e3gBrRMEkpKS3lquNuTR5Z9++gk/Pz+df+7uxpWfyo0NGzawaNEiihcvzi+//MKZM2e4desWW7ZseafXMYRPm0vXO3vqmEYe3IvoKK5fvYSFpSXNWrTUK8vKypp6DRqTkZHB8cMHNPYfPSTV8G3Zpr1qWzmXCpRxLkdaWhqH9u3SOOfsqWMkxMdTzKE4FSsZ/izUbSSlLFw7f0ojhzY2Jpq7N6+Rz8KSeo2bGyzTVJ4HSFVG5GD9bWjyWQsAzp06rpHb+SI6ihvXLmNhYUlTA8qlWVlZU69+IzIyMjh19KDG/uOH9wPg3jor5clNuQT0vTu3VD9i2QkLCeaR8mXKLdty0fpo4S7514njRzX8MCoqkiuXL2JpaUmLlq31yrK2tqZh4yZkZGRw6OA+jf379+0BoF17zdX+3gdH/pTuU/eGzljmU//JKGFnTUu3UiQp0jicS61hmUehr/ALfYVFXnMGtNBcPax7w7IULmhJSMwbtcl0Pq0r0aeZCwAztvypddU8Y/lY26y5sq87qcWu6Kgorsp2ubfSK8vK2poGjSS7Dh/cr7H/4H6pT2zbTt2uHdu2qI4fN2ESQ4aNMMmW7HymtOvUcc2+PjoqimtXLmFpaUlzI+06ckjTrkMHJLtat++g2la33icA/PXnTa21ks+cOsHLmBhsbGyormNxlQ+JWPnOdEwKjL28vEhKSmLUqFE8eKA5gcLPz4+xY8eiUCjo2bPnWyv5Ltm+fTvz588nMzMTc3Nz3NzcGDFiBHv27CF//vzcuHFDdawhs3Zzki9fPrWSZzLvq3SdPEJ79672t+gVK1awcuVKVX6bsWi7B/v3Sx3J0qVLVVUw5OP8/f1Nuo6pVKpclbr1G/IiOooFs6aQlCSVT4uLi2X2lK9QKBS069QVu8LqVTlCQ4J4HvhUVc9Sxqv/YABWr1jKn9evqbafPHqI/bu2Y2FhQfde6pMKBw8fA8Ca35arljwG8H/8iF9+klZJ6jNgiFH+VK5iZarXrk9sTDQrv59NcrL0YpXwKo6fF0wlNVVBs9YdscmR/xYZFkJYcCAJBtQUNZTgZ8pFTMprS+owjoquVanzSUNiXkTx3dypqvZ6FRfL/Olfk6pQ0KZjF432CgsJJijwmap2sczn3tIknjW//sytG1ntdfr4YQ7u2U4+Cws8PPuotpdzqUijpp+RlpbGrElf8DzwaZadz58xd9pXKBQpNPq0udYlo3VRpWo1GjRsTHRUFNOnTlSV8YuNjWXShHEoFAo6d+2mUR0mODiIZ0+fEhurbtfAQUMBWL50Cb7Xrqq2Hzl0kJ3bt2JhYUHvPt4G6/c23Al8ybl74ZSyz8+qUU3IbylNwrMvaMn6Lz/FysKcrReeEpMjx9jZoSAVS9qocpBlvt0trdY43bMm3RtmpbRUL2PHAm/pZWTpoawvJfYFLZndW0oJ2HjO36SJdtr4WNusctVq1G/YiOioKGZOnaSyKy42lslfS3Z16uJB4Rx2hQQHEfjsqap2scyAQVKlnV9+XsL1bHYdPXyQXUq7evXJ6hPjYmNZvuRHQFoy2pSJdlrtqlKV+g0aER0dxezpk7P6+thYpk0cj0KhoKMRdnkPlPr6lcuWcMM3y65jRw6ye8c2LCws+Lx3ll3lK1SkcdNmpKenM23SV2rB8a2bN/j+23kADB42yqCvvYJ/LyZ9F+3QoQNXrlxh9+7d9OjRg0KFCmFmZsbFixdp3rw5kZGRZGZm0rFjR7p27fqudX4rbty4weHDh6lZsyZdumStaf/ixQtSUlIoUyYrT0pOA0lL0z/bWsbFxYVHjx7h6+tLgwbS5J7ExER+//33d2SBOq1atcLOzo4tW7bQvn17atbMelM9evQoS5cuxdnZmeHDTVupTL4H2fOO5TSSmJgYVQk3gOvXr7Nr1y6N4983E6fNYfTQfpw/e4o/b/ji6OTE82fPSE5OokJFV0Z9+bXGOV+NGkpEeBgDfUYyaNho1Xa3WnXoO2AIWzas4avRQ3Eu50JqqkLVCU6cPle1wpJMi1ZtefLoAVs2rGHe9EmsWr6EggUL8TTgCRkZGbRo1RaPnsbX/h385VTmfeXDjUtnuX/7BsVLOhIWFEhKSjJlylfEy+dLjXO+mzKaF1HhdOs7lB79hhl9TW3ExUqfv4sYuUyyLsZPmcW44QO4eO40f930pZRjaYICn5KcnIxLRVeGj52gcc7EsT5ERoTRb8gIBgzNKoVUo2YdevcbwvZNa5j0xTDKlnMhVaFQrZw3aeoc1Yp3Ml/PmM+kscMIePKIoX26Uca5PGmpqYSFBpOZmYlLxcp8PX2e0XbNnD2Pgf29OHPqJNevXcOpdGmePXtKclISlVwr89UEzSVyhw8dSHhYGMNHjmbEqKzKN7Xr1GXQEB/WrfmdET6DKO9SgVSFgmDlamWz5nyjtnra+2bcmmscn92WrvXL8lm1EjyLfE2lUrYUsMrLvecvmblVcxneg9NaUaZYQRbuucvCvVkv7geuB/Hjwb/5qkt11o79lDm9a/MqUUHV0naY58nD3muBrD6dtVz3APcKFLSS0i5qOttzbJbuVdUmb7hhVNm2j7XNps+ax5ABfTh7+iQ3fJV2PX1KcrJk1zgtdo30GUR4WBg+I0YzfNQY1fZadeoycIgP69f8zqhhgynv4oJCkapaOW/GnPlqK8Pt27NLFbQ+eviAIQN0VyeaOGW6UWXbps6ai8/Avpw7fZKbvtdwLF2aQKVdFSu58oWWdI0xwwYTHh7G0OGj8BmZza7adek/eCgb165mzPAhlCsv9fUhypUOp82ep7Hi3cx5Cxg5dACPHtzH06MjZctKc22Cg6SBrx6evfHy7m+wPe+Tj3Ek90NhcsLgN998Q61atVizZg3Pnj0DUL1BlypVigEDBtC//7/DQbIzevRoLly4wOTJkzl27BguLi7ExcVx4sQJMjMzVaXPANVkvAMHpM/qXbt2pVKl3AvP9+3bl5kzZzJy5Eg6deqElZUVp0+fxs7OjoImLBygj4IFC/L9998zZswYvLy8cHd3p2zZsgQEBHD+/Hny58/PwoULDaqzqQ35Hvz888/cvHmT0aNH0717d/766y98fHxo3749NjY2PHr0iCtXrlC4cGFSUlJMHqE2SUdHJ37ftJO1v/3CtcsXCHjyGPsiRenk0YOBw0apynoZyrAx4ylf0ZU92zfz1P8JADVr16PPgCE0bPKpznPcatdl59aN+D24z6tXcVR0rUInj5507tbTpK8PDiUcmb9sI3s3r+L29csEPfPHrnARmjfxoLu3D1ZW1vqFvCUZ6ekkvZFyPe3s303eXMlSTqxYt50Nq1fge/kiT/0fU7hIUTp0aUn/oSONbq+ho76kfIWK7N25hcAAqb3catWld//B1G+k2V62tnYsXbWBfTu38sfp44Qof9TKV6hE81bt6PZ5H5PuraOTE1t37OHXX5Zx8eJ5njx+TNGiRXHv4cmIkWOMylkG+GLcBCpWcmXblk08eSIFinXq1mPQkGE0/VRzEaH3yfPoNzSfcYypPdxoU8uRamXsiIxLZuO5Jyzce5fEFOMm287bcZurj6IY1b4KdcoXoXBBS+48i2XDuSdsOKf+1alBpSy/q1nOPqcoNWzyGzdS97G2maOTE5u37+a3Fcu5pLSrSNGidGvZk2Em2DXmy6+oUNGV7Vs24v9Eesbq1K3HgME+NMlh153bt1T/76enOkPOakn6KOXoxIatu1m1cjlXLp7H/7EfRYoWpat7T3xGjDa67xj9hWTXjq2bCFDaVbtuPfoPGkrjpprtZW9fhLWbdrB5w1rOnDxOcNBzLC2t+KRBQzx79eEzA9I4BP9+zDLfwSyp6OhowsPDycjIoFixYmoLYbxr5NXXsq+u1q9fP65fv87JkycpW1Z9trm7uzuhoaFqxwcEBLBq1Spu3rxJVFQU+fPnp3bt2vj4+KhVbgD49ttv2bdvHwqFghkzZuDp6YmrqyvFixfXWYpu+/btbNmyhWfPnmFnZ0e7du348ssvadWqFeXLl2fbtm2AtPLd1KlTGTFiBOPHj9ewU9s1pkyZwr59+9i4caNqRBqk1fxWrVqFr68vr169wsHBgXr16jF8+HBcXFxUxy1btozly5fzzTff4OnpqVd2XFwcEydO5Pr16+TLl4/t27dToUIFdu/ezaZNmwgKCsLCwgJHR0datWqFt7c3n332GQUKFOD8+fOYm5ur5K5bt05VC9lYIuI/3Aj0hyQ4JvGfVuG9UML23U1O/bdRpODH+Zm01CDNVUI/BsLWvf966v8E6R9ogvM/gVyZ5GPDzlr/6pDvisV/PNV/0DtiYvPyH+xaH4J3EhgLBO8bERj/txCB8X8PERj/txCB8X8PERj/NzDt+zpSDumhQ4cIDAxUbTt37hwdOnSgdu3aDBw4kEePHr0LHQUCgUAgEAgEBiKqUpiOSYFxfHw83bp1Y9KkSdy8Ka069Pz5c8aOHcvTp09JSkri2rVreHt7611FTSAQCAQCgUDw/5djx47Rq1cv6tatS/369Rk+fLjOalvaePXqFYsXL6Z9+/a4ubnRrFkzpk+fTnCw/jKSOTEpMF6zZg3+/v7UrFlTVS5s+/btpKWl0bVrV27evMnMmTN5/fo1q1atMuUSAoFAIBAIBAITMDP7cH9vy8qVKxk3bhwvXrzg888/p3Xr1vj6+uLl5cXFixf1nh8fH0/v3r1ZvXo1RYoUwdvbm9q1a7Nv3z66dOmiWiHYUEyqSnHmzBmKFi3Kxo0bVfX6Tp8+jZmZGSNGjKBgwYL07duXXbt2cenSJVMuIRAIBAKBQCD4iPH39+fnn3+mUqVK7NixQ7USsLe3N15eXsyYMYOTJ09qXa1XZsmSJTx9+lSjkMHp06cZPXo08+bNU5WSNQSTRoxDQkKoVauWKih+/vw5wcHBlCxZknLlyqmOK1u2LNHR0aZcQiAQCAQCgUBgAnnMzD7Y39uwfv16MjIyGDVqlCooBmnxsp49exIREcGZM2dylRESEkKRIkU01mto1aoVNjY23Lt3D4VCYbBOJgXGlpaWaoteyEPdOUtxxcbGihVgBAKBQCAQCAQaXL0qrTrYpEkTjX1yTHnlypVcZaxatYorV66oBdYAkZGRJCQkYGdnZ1QsalIqhbOzM3fu3CEpKQkrKysOHjyImZkZLVq0UB3z7Nkzbt26RfXq1U25hEAgEAgEAoHABP4L1SJSU1MJDQ3F3t4eGxsbjf3ySsQBAQFGyU1ISODWrVssXryYzMxMvvjiC6PONykwbt++PQsXLqR79+7Y2tpy9+5dihcvTrNm0koxv/32Gxs2bCA9PZ1u3bqZcgmBQCAQCAQCwb+cli1b5rpfVypEXFwcmZmZ2Nraat0vB8sJCQkG63LgwAEmTcpa8nzChAn06dPH4PPBxMB44MCBhIWFsXHjRgBsbW1ZvHgx+fJJ69nv2bOHly9fMmDAAHr16mXKJQQCgUAgEAgEHylySq4cO+ZETn9ISUkxWGahQoUYOHAg8fHxnD17lh9++IGoqCimT5+OmYH50CYFxgDTpk1j0KBBREdHU6lSJayssla6GjduHOXLl6dy5cqmihcIBAKBQCAQmMC7KKNmKPomx+lCrjSRmqp9ZVt5wlzO3OHccHd3x93dHYCYmBh69+7Npk2bqF+/Pm3atDFIhskr3wGULFkSNzc3taAYoEOHDiIoFggEAoFAIBBopVChQpibm+tMlYiPjwfQmn9sCEWKFGH06NGAVLrNUEweMQYICwtjz5493Lx5k6ioKPLmzUvJkiVp0KAB3bt3p3Dhwm8jXiAQCAQCgUBgJHn498++y5cvH2XKlCEwMJA3b95QoEABtf1BQUEAVKhQQaeMlJQUbt26RWpqqmqeW3acnJwAePnypcF6mRwYb9u2jYULF6JQKMjMzFRtf/LkCRcvXmTVqlV8//33fPbZZ6ZeQiAQCAQCgUDwkVK/fn2ePXvG1atXadWqldq+y5cvA/DJJ5/oPD8xMZFBgwZRsGBBrly5olGW7f79+4C0roahmJRKcfnyZebOnUt6ejp9+/Zl3bp1HDt2jKNHj/L777/TvXt3EhISGDt2LA8fPjTlEgKBQCAQCAQCE/ivLAnt6emJmZkZS5cuVUupePToEXv27KFEiRIaAXN2ChcuzKeffkpCQgJLly5V2+fv788vv/yCubk5np6eButk0ojx6tWryZMnD6tWrdJY1KN8+fJ8+umnNGnShK+++oply5axYsUKUy4jEAgEAoFAIPhIqVGjBoMGDWLt2rV07tyZdu3a8fr1aw4fPkxaWhrffvutahQ4Pj6eDRs2ADB27FiVjDlz5tCnTx9Wr17Nn3/+Se3atYmMjOTUqVOkpaUxe/Zso+a9mWVmz4MwkLp161K1alU2bdqU63G9e/cmICCAGzduGHsJgUCNiHjts1b/6wTHJP7TKrwXStha6T/oP0qRgh/nap6lBm35p1V4L4St6/tPq/BeSDf+p/s/Q3rGx2mbnbX5B7vWr1cDP9i1RjRyfmsZu3btYuvWrQQEBFCgQAFq1KjBmDFjcHNzUx0TEhKiqpns5+endn5MTAwrV67kzJkzREVFUbBgQerWrYuPjw+1a9c2SheTRozz5MmjsyBzdhwcHHj8+LEplxAIBAKBQCAQ/D/A09NTb7qDk5OTRkAsU6RIEWbMmMGMGTPeWheTAuNGjRpx9epVXr58ib29vdZj3rx5w82bN3NNmhYIBAKBQCAQvFvyfMhCxh8ZJk2+mzx5MtbW1gwcOJCbN29q7A8LC2PEiBFkZGQwefLkt1ZSIBAIBAKBQCB43xg0Yty8eXONbUlJSURHR9OvXz8cHBxwdHTE0tKSqKgonj17RmZmJuXKlWPBggWsWbPmXestEAgEAoFAINCCGDA2HYMC44iIiFz3R0ZGEhkZqbH96dOnPHv2zDTNBAKBQCAQCASCD4hBgbGp62ALBAKBQCAQCD4sIsfYdAwKjB0dHd+3HgKBQCAQCAQCwT+KyUtCJyYmEhAQoEqhKF68OOXLl9dY61ogEAgEAoFA8OEQA8amY3Rg/OjRI1atWsXZs2dJSUlR22dhYUGrVq0YNGgQ1atXf2dKCgQW5iYVUPnXU7FEwX9ahfdCatrHWaAfID457Z9W4b0QvLbPP63Ce6FIi7eva/pvxP/I7H9ahfdG4fz5/mkVBP+PMSowXrduHT/++COpqdIqZA4ODhQrVgxzc3NevHhBWFgYR44c4cSJE4wbN46hQ4e+F6UFAoFAIBAIBNr5OIeSPgwGB8b79+9n0aJF5M2blyFDhuDp6Ymzs7PaMVFRUWzfvp3Vq1fzww8/YGtrq3clE4FAIBAIBAKB4N+AWWam/gXXIyMjadu2LWZmZqxfv56aNWvmevzdu3cZNGgQGRkZnDhxAgcHh3emsOD/Jy/fpP/TKrwX8nykr/UfcypFuv4u8z9JAUvzf1qF94KD+8x/WoX3gkil+O+R3+LDJf5uuBn8wa41oF7pD3atD4FBP8tbt24lOTmZadOm6Q2KAdzc3JgxYwZJSUns37//rZUUCAQCgUAgEAjeNwYFxhcvXsTe3h4PDw+DBXt4eGBvby9qIAsEAoFAIBB8QMw+4N/HhkGBcWBgIK6uruTLZ/jnDTMzM2rUqEFISIjJygkEAoFAIBAIBB8KgybfpaamYmtra7Rwa2trXr16ZfR5AoFAIBAIBALTECvfmY5BI8ZFihQhONj4RO6wsDCKFCli9HkCgUAgEAgEAsGHxqDAuEaNGjx69IjQ0FCDBYeHh/P333/j5uZmsnICgUAgEAgEAuMQOcamY1Bg3L59e9LT0/nuu+8MFvzNN9+QmZlJ165dTVZOIBAIBAKBQCD4UBgUGHfo0IFq1apx5swZZs6cqbEUdHaSkpKYPHkyZ8+epUGDBrRq1eqdKSsQCAQCgUAgyB0zsw/397Fh8Mp3y5cvp1evXuzevZtTp07Rvn17atSoQZEiRbCwsODly5fcvn2bQ4cOERcXh5OTE0uWLHmfugsEAoFAIBAIBO8MgwPjkiVLsnfvXqZMmcKlS5fYtm0b27dvVztGXkSvffv2zJkzx6RKFgKBQCAQCAQC0zH7GIdyPxAGB8YARYsWZfXq1dy7d4/Tp09z584dYmJiyMjIoESJElStWpUuXbpQsWLF96WvQCAQCAQCgUDwXjAqMJapUaMGNWrUeNe6CAQCgUAgEAgE/xgmBcYCgUAgEAgEgn8nBlVWEGhF3DuBQCAQCAQCgQAxYiwQCAQCgUDwUSEm35mOGDEWCAQCgUAgEAgQI8YCgUAgEAgEHxVivNh0xIixQCAQCAQCgUCAGDEWfCS8iI5m1cqfuXrpAq9exVHMoTjN3VszeNgoChQoYLS8k8ePsGPrRvyfPMbSwhLXKlXxHjCEBo2aGHR+YuIb+vbsQkREOAeOncWheAmjdQDJrt9W/MyVSxd4FSfZ1aJla4YMN82uE8eOsGOLZJeFhSWVq0p2NWys3a7ExDesX72Ks6dPEhEeRiEbG2rVrku/gUOoWt30ko0vXkSzeuUyrl6+QPyrOIoq22vQ0JHkN8GuU8ePsHPbJgL8Jbtcq1Slb//B1G+o3a75s6Zy4uhBnfLqN2rCj8tWGa1HzIto1vy6jGuXL0p2FSvOZ+6tGGCiXadPHGV3drsqV8Wr/yA+0WEXwONHD9i8fjX3/vqThIR4HIqXoHnLNvQbMhxr6/xG6yDzIjqKlct/5rLSFx0ciuPeqg1DR5jmi8ePHmHb5o34P/HDwsKSKlWr0n/QUJ2+qFAo2LZ5IyePHyXo+XMyMjMoU6Ysbdt3xMu7P5aWlibZVaJIIWb5tKJdo0rY2+QnLDqe/efv8+26s7xOVBgkw7tDbX6f3tOgY30W7Gbz0b907h/zeWMWf9mRliNXceXuc4NkaiPmRTTrfluO7xXZFx34tEVr+g8ZYZIvnjlxlD07NvPU/zEWFhZUqlyVXt6D+aRhY7Xjjh/ez/fzZxokc9LM+bTr5GGUHtHRUaxY/jOXLp5X+WHL1m0YNmIUBQoUNEoWwLGjh9m6eSNPHst+WI2Bg4fQqHFTg87fsmkD//v+O9Zu2ELtOnWNvv77QuQYm45ZprxcnUDwL+blm3Td+2JeMKRfLyIiwrGxtaVUKScCnz0lOTmJcuVd+H39NgoUNLzD3LB2Fb8uX4KZmRnlXCqQkpxMaEgwZmZmTJ4+h67dPfXK+Gnxt+zcthkg18A4Ty7fbGJiXjDYuxcR4Uq7HJ0IfJpl1+qN2yhohF3r16xi5TLJrvIuFUjOZteUGXPw6KFuV3JSEkMH9OHJYz/y5ctHWedyvIqLIzo6CvO8eZk+ax4du2j/UUtN092tvIx5gc+A3kQq26tkKSeeK9vLubwLv63dalR7bVr3O7/9omyv8pJdYaGSXROnzaZLN832Gty3J4/9HlK1uhvm5uYa+6vVqMmYcRO1Xi9dR5f5MuYFIwZ6ZbPLkefPnkl2lXNhxdotRtm1ed3v/L5iKWZmZjiXr0BKchJhoSGYmZkxYepsOnfTDMROHTvMd3Onk56eTtFiDhQqZEPQ82ekp6dT0bUKP6/aQP782oPjApaa90EmJuYFA/p8TkR4OLZKX3ym9MXyLi6s3bTdKF9ct3oVv/z8k1ZfnDZzDt16fq52fGLiG0YMHcSDv+9hZmaGo1NpzMwgNCSEjIwMarjVZMWqtVhrsc3BXXeQ5lC4ABdXj6RMicLEvEokMDyWymWLUcDaggfPImk+7DcSElP02tOmYSUm9/9M5/7CNvmpUs4BgNajf+fS7UCtx9Wp7MiJZUMomN9Sb2Dsf2S2zn0vY14wanAfoiLCsbGxpUQpR4ICJV8sW86F5as3G+WLW9evZvVK2RddSE5OJlzpi+OnzKKTR5Yv+l65yJZ1v+uUlRD/iueBTwH4aeVaatb5ROOYwvnzaT035sULvPt8TkR4WJYfPntKclIS5V0qsGGzcX64ZvVvLF8q+aGL0g9DlH44Y9Zcuufww5zcv38Pn0EDSEpKNCgwzm/x4YLV3XfCP9i1etYs+cGu9SEQgbHgP0FugfH4McO4duUS7Tp0Zuqs+VhYWBAb+5LJX43l3p2/6Nrdkykz5hp0nb/v3mHYoD7kL1CAn5atokbNWgAcP3KQ+bOnYW5uzo59RylZylGnjPt/32XYwD5kZGQApgfG40YP4+rlS7Tr2Jnps5V2vXzJpPFjuXvnLzx6eDJ1pmF23bt7B58Bkl1Lf8my69iRg8ybKdm1c/9RSjlm2bXwmzns270T18pV+P6nZZQoWQqA/Xt28d382VhYWLD74DGKl9DsFHMLjCd8MRzfK5do274zk2fOU7XXtAljuXf3Nl26eTJp+hyD7Pr73h1GDu5L/vwF+GHZb1R3k+w6cfQQC+ZIdm3dc0StvTIyMmj9qfRjfOriDfLk1gha0BUYT/xiBNevXqJ1+05MmiHZFRf7kulff8Hfd2/TuZsnX0/THcxk5/69O4we4k3+/AX4/udfVXadPHqI7+ZOx9zcnE27D6vZFfw8kEFe3UhLA6owEwAAIABJREFUS2PshCl0/7wPZmZmPA98ytTxowkNCabvwKEMGz1O6zVzC4y/GDmMK5cv0r5TZ2bO+UblixPGjeHu7b/o1vNzps8y0Bfv3GZwf8kXl61chVvN2gAcPXyQOTOmYm5uzp6Dx9R8cdGCeezasY1y5V1Y9MMSyrtUAMD/8WMmTfiCoOfP8ezdh8nTNIPg3ALj/f8bQNtGldh6/C9GLtyHIjWdonb52fmdN43cyrJ6/3XGLj5gkF25cXjJIFp+UoFlOy4z6eejWo+pW9mRvf/rj0NhKbB7m8B4yrgRXL96mVbtOvH19LkqX5w56Uvu371NJ4+efDXVMF98cO8OY336kT9/ARYuXUm1GpIvnjp2iEXzZmBubs6GnYcokUufKJOZmcmkL4bx5/Vr9Ojtzejxk7UepyswHj3ChyuXL9KxUxdmzZX88OXLl3z15Wju3P6LHj0/Z8bseQbZdffObQb286JAgQIsX/k7NWtJfnjk0EFmzZiCubk5+w8do5Sjk9bz7/99j7GjhxP78iXAvy4w3vsBA+PuH1lgLHKMBf9p/B/7ce3KJQrbF2HyDOkHAKBwYXsWfP8TFhYWHDm4j5cvYwySt3nDGjIzMxkybJQqeARo17ELPT73IjU1le1bNuo8Py0tjYXzZ5NPqYepPHnsx9XLkl1TZ2azy96ebxdLdh0+YIRd6yW7hg5Xt6t9xy707KVpV3JyMsePHAJgzoJFqqAYwKOHJ02bNUehUHDymPYfeV34P/HDV9lek6bPUWuv+Ysku44e2kesgXZt3biWzMxMBvmMVAWPAG07dKa7p2TXzm3q7RUaEkxKSjJlyjobHRTrIuCJH9evXqKwvT0Tp2XZZVfYnrkLf8TCwoJjRti1TWnXgBx2tenQGQ/P3qSmprJ72ya1c9b8uozU1FR69R1Aj159VZ9SyzqXVwUgJ48eMtq2J4/9uHL5Ivb2RZg+a56aLy763xIsLCw4tH8fL2MMs22j0hd9RoxWBcUAHTp1wbN3H1JTU9m2eYNqe1JiIgf378XMzIy5CxaqgmKACpUqMW/BIgAO7N1NcnKywXZVdylO20aViHz5mtGL9qNIlV6+X8Ql0nfmNpJTUunfsQ7F7IxPO8jOiB4NaflJBZ4EvWDmrye1HjOk6yecWuGjCorfBskXL1O4sD0Tps5W88XZ3/5APgsLjh/eb7Avbt+8jszMTPoPHaEKigFat+9M155KX9y+2SBZ+3dv48/r13AqXRafUdpf0HTx2C/LD2fMzvJDe3t7vv9B8sMDRvjhhnWSHw4bMVoVFAN07NyFz5V+uGWzZl+fmZnJ7p3bGTLQWxUUCz4u/nOBsaurK66urm8lQ6FQsGrVKtLTdY9C/pvx9fXl2rVrqn+HhITg6uqKl5fXP6iVbvr164erqyvPn5ueL6eLk8ePAODeqi1WVlZq+4oVc6Bhk09JS0vj0oU/9MpKTHzDpYt/YGZmRtsOnTX2d/boAcAfZ0/plLF5wxr8n/gx2GekEVZocvKYZFfL1lrscnCgkWzX+T/0ykpMfMPFC5Jd7TrqtuvcmSy74l+9okNnD9q066gWiMjI26KiIgy2CaRcYIAWLdtgmcOuosUcaNBYsuuyge11+YLu9urYtTsA58+eVtv+NOAJAGXLlTdK99w4fVx6QWjesq1Wu+o3bkpaWhpXLv6hV1ZiYiJXLp7HzMyMNu07aezv2EW2K6u9kpKkcywsLfEe5KNxzicNGzN4+Bi8B/kY3e8dP3oYgJZttPti46afkpaWyoXz5wyw7Q0Xzktt1kGLL3btJvni2dNZtt2//zcpKSk4FC9B1WrVNc6p7lYTW1tbFAoFgU8DDLarV+uaAOw79zfJijS1feEvEjh57QkW+fLSoWllg2XmpKhdfuYObw3AhCWHSclxHYCLv49k+SQPLPOZ8+26szwPjzX5egBnTkq+2EzHM1a/keSLVy+d1ysrKTGRq0pfbNVO0xc7dJZ88eI53X2iTFzsS9as+BmAMROmYGFkTvgxpR+21uKHDg7FadK0GWlpqZw32A/PYWZmRsdOXTT2e3SXUkPOnNJ8kenX53MWzJ+DQqHAZ/goSpYqpXHMvwEzM7MP9vex8Z8LjN8F3t7e/PDDD/wXs0i2bdtG//79CQ4OVm2zsbFhzJgx9OjR4x/U7J/hwd/3AKhew03r/mrVpe13//pTryy/hw9JT0ujlKMT9vZFNPa7VKiEpZUVUZERhIeFauwPDgpk3epfcalQiT7eA42wQpP7sl1uOuxS2nvbCLscnbTbVaGipl0OxYszadpM5i9crFXmo4cPAHB0KqPfmGw8vH9PqX9NrfvlCX1379zSK+vxo4ekp0vtVVhXe1lKdkWEh6m2PwvwB8C5nItRuufGwweSXVWra2+vqtWUfnhb96QrmSePHuRqV3mlXdFRkSq7Ht7/m5SUZKrVqEkhG1uNcywsLBgwdAQePXtrzanOjfv3JNtquGlvs+rKtrzzl/42e/TggdIXS2NfRLcvRmbzRReXCnz/41LGfz1Jq8z09HSSU6Q84HRl+pIh1KsqfSL3/TtI6/4bD6Q+trFbWYNl5mTKgBbYFLDilO8TTvk+0anH46BoOny5jvmrz5h8LZlH9/8GdPtilWrSM3bvtgHPmJ/kiyV1+GK5ChU1fFEXm9euIjHxDfUaNKZ+I8MmtmXn/t93AaiR7QtKduTfgNu39PeJDx88IC0tDScdflixYiWslH4YlqOvv//3Pco6O/Pr7+sYNeYLY80Q/Af4f1mV4sWLF/+0CiajTXcbGxvGjh37D2jzzxMaKv14ldSRByanAISGBGvdn50wpSxdOWV58uShePESBD0PJDQkWCPPeNE3c0lVKJg8fQ5582nPkTOUMKW+pUq9vV2hemTpsys7CfHxbFj7O9evXaGwfRHaaxn1y42w0BAAndcoUcL49iqZi10OxUsQHBRIaEiQ6p7JgXHJUo7s372DG75XeP06gZKlnGjVtgP16jc0yiaAcNkuR+12FVdeW9Y5N+R7pCtnM7tdYSHBlChZisCnkk1lypYD4Nrli5w7dZzoqEiKOjjQpn1n6jVoZJxRSkL1PBfyfQ0J1h5gqssKUcrSbZvsiyHBki8WtrfHvVUbnTKvX7tKSnIy5ubmlCljeBBbrpQ9gM4R2qCIOADKO9obLDM7ZYrbMdSjPgDzV5/WedzIhfvYfPQWaemGB/W5ER4mP2Pa26t4CcN9MVzP85onTx6KFS9BSFAgYaHBailX2YkID+PQvp0ADBo2Wu91tRGi7BMcnbTbJY/cZh800oWqT8ytry9RgueBkh+Wymb/zDnz6dzFg3xv2ce/bz6+cdwPx//LwFjw8fAqTvpRs7W107q/UCEb6bhXcXplxemRlZu8g/v38OdNX7p79lbL4TUVlS522nWxsVHqEWe4XTY6ZAEU0iPv73t3+G7ebIKDnpOSkkJ5lwrM/fZ7nfrp4pUeu1R6GNRe0jG5tpdK3ivVNjmV4n8L55GUmJjtaF8OH9hDh87dmDxjrlEjq7JdNnr8MN6A9tLn06B5n6IiI1Tb506fyNmTx9SOP3HkIN179eHLr6fpvX5O4mKla9jp80VD2iw29/Y3Vl5aWhq//PwTAA0aNVbdF0MoYitVsIh5lah1f2xCEgD2tqaVuBveowGWFnm5evc5Nx6E6Dxu/aGbJsnXRZYvan45gCzfic/2TOiWJbWBjY3+PjE+l/Y6sHs7qampVHOrRRUdI9n6kP1Q13Nho/xSYlRfn6sfKuXleGa799BflUjw3+ajSKXo168f9erVIzY2llmzZtG0aVNq1KhBp06d2LJli+o4X19fXF1dCQ2VPo1Uq1aNfv36qfanp6ezadMmunXrRs2aNalbty4DBgzgwoULGtd0dXVl+PDh7Nixg8aNG1OrVi2+/vpr1b5Ro0bh5+fHiBEjqFevHrVq1cLb25urV69qyIqKimLhwoV06NCBWrVqUaNGDVq3bs0333xDbGzWaIa7uzvLly8HYMaMGbi6uhISEqIzxzg9PZ2NGzfSrVs33NzcqF27Nr179+bAAc1Z1u7u7nTt2pXQ0FAmTJhAgwYNcHNzo0ePHhw9qjnBKiEhgWXLluHh4UHt2rWpXr06zZs3Z+rUqar7+yFIUX5C1VXDVM6xUyj01yPVJ0tNXkqWvJcxL1i+ZDFFixZj5Jjxhin+lrpYWr5ju5TyUnTIexrgj/+TxypZsS9f4nv1st5r69bFSut+lV0p+u1SpEgTrSytcrPLUnmsdN20tFSCgwIBKF6iJD8s+41TF29w+PQlJkyZibW1NUcP7WPtql8MM0iJfruUeij0l/6SZVnokCXtU5cnB/iH9u7i/JmTDB8zngOnLnL03DUmTp+DpaUVe3dsZd+u7QZalF2fZDUbciLf/xQD2kyWZZWLbfIzJt+H3PjfwgU8eviAvHnzMWqscZO5rC2lEb/kFM28X4CklFRJVwvjx48s8pnTr4NUoWD5zitGn/82KPT4jzG+KD9jueUDZz1j2ttfoVBw/PB+AHr09tZ7TV2k6Hnecz7ruZGcLB1jZYBdKQbcp38jZmYf7u9j46MZMU5LS6Nfv34kJibStm1bUlNTOXz4MPPmzSNPnjx4eXnh6OjImDFj2LBhAwkJCYwaNYrSpUsDUhA5evRozp07R4UKFfD09CQ9PZ1Tp07h4+PDtGnTGDBggNo17927x9WrV/Hw8CAzM5OqVauq9gUGBtK7d2+VrNDQUE6ePMnQoUPZt28flSpVAiAyMpIePXoQGxtLixYtcHd3JyEhgT/++INNmzZx69Yt9u7dC0D//v05c+YM169fp0WLFlSrVg0bGxvi4+M17odCoWDkyJFcunSJ0qVL0717dxQKBefPn2fSpEn8+eefzJunXtYmLi6OXr16YWtrS9euXXn16hVHjhxh/PjxFCxYkGbNmgHS5KDevXsTEBBAkyZNaNKkCcnJyVy5coW9e/dy9epVjh07hrW19btrYB3kyZNHVRZNG5lG5BzmMeAJl6+V/dAfv/+WhPh4Ji/6kYKFChl8vVx10WNXRqamHjplGXBQph55TZs15+zlGyQlJvLH2dMsX/I/li/5gZSUFIYOH6VfCVkXfe1lhF1mZvrf6+V5BPIEEUWKgt7eA4l5Ec0XE6aoRrusrfPTrWdvChQsyLwZk9m2eT2eXv2wsyusXxEMaS91PXKXZUB7ZSjlKT+YykHOq1dxDBo2mj4DhqiO7eTRk1RFKksWL2Dj6pV07taDvHkN/wycJ4+5nmfMcNsMajPVM5a7vBXLlrB7pxToj/lyPJWrVM31+JykZ2Rgbq5bH7kdTJmK0q15NYoVLkBo1CsOXHhgvIC3QK8vGtNeBlRt0dcXXTx3ildxsdICI5+11CtPF3r9MNMwv5FkGWCX7IciKeH/HR9NYJyUlISNjQ27du1SBWSdO3fG29ubzZs34+XlhZOTE2PHjmXfvn0kJCQwevRo8uaVbsHmzZs5d+4cHh4eLFiwQLV93LhxeHl5sWjRIpo2bYqLS9aEnZiYGObNm0evXr009AkICGDw4MFMnpxVp3H58uUsW7aMbdu2MXu2VENy1apVREdHs2jRIjw8shZLSE5OpmPHjty/f58nT55QsWJFBg4cSEJCAtevX6dly5Z4ekqfdLQFxuvXr+fSpUu0aNGCn376SXVPXr58yaBBg9ixYwcNGzakQ4cOqnMiIiLo0KEDixcvVtnfqFEjJk+ezObNm1WB8fbt2/H392fs2LGMGTNGdX5GRgZ9+vThr7/+wtfXl+bNmxvafCZjbZ2fhIR4nSOn8vacs7O1yspfQO0cbaTmkHf54nnOnDpO46af0bJ1O6N0z1UXPXap9Mhl5E0lywC7FHrkyZP2ChQoQM9eXtja2TFj8gQ2r1/D5159VZ8d9WFlnZ/XCfE6R3X06ZEdeTGH3EYWs+RJoz/5CxRgRC6j+m3adWL1yuWEhQbz5w1fg9tUn11ye+U2Ciwjr06X24heaqq6H8r3K2/evHj1G6RxfOfuPVm1YgkvX8bw+NFDnROztOtjTUJCqs4R4Zz3ODfyG9Vm2u9VZmYmS39YzOaN6wDo1ccb7wGaNuvjTVIqFvnyYmmp/WfQMp+0XR45Noaun1UD4MD5+6S/o9xhQ7GytuZ1QoJO/1H5jgHtleWLufWJqUp52tvr4jlpQuGnLVphntf0kEP2Q919h6yHEX6Y6zOmlJfLF6l/M3lEQG8yH0UqhczAgQPVRik/+eQTChUqZFCZsJ07d2Jubs7MmTNVQSGAra0tI0eOJD09XTVym5127XT/cA4bNkzt3+7u7gAEBWVNUunYsSNz586lSxf1kjFWVlbUqiXlqr40oVbinj17yJMnD3PnzlW7J/b29kyfPh2AHTt2aJw3dOhQNftbtGgBoHYPGzduzLx58xg4cKDauXny5KF+/fom62wKch6drnw5Oe/NkJE/ObjLLfdOzl+ztStMYuIbFn8n3d+vp8wwSm+9uuixS857szXELj2yssszdIS0ddv2FC1WjKSkJB4/emjQOZDtHsfrai9puyG5y7KsBB2yJHmG3yeZcuWll9/ICMML5Mt5sbrtkvXQb1chW/12qfxQmW8pr2JWyqm01pfAvHnzUcpR+jqmr3pATlT+E689d1PWxa6wEb5ogG12hTXvVXp6OvNmz1AFxZ69vPh6svF50wCxCVL6iX0h7V+29OUg6yKveR7cP5HKGR68YPiz8a4opOe5UPmirf720idLTZ4W305LS+XP61L6YJPP3PVeLzdsbeUc4tz7RKP8MJc+Mc7IPlHw8fDRjBgDODs7a2wrVKgQCQkJuZ6XmJiIv78/BQsWZN26dRr7Y5QFwx88UP8kZmtrq3pYc2JnZ0fhHA9oIeVn9uxv33Xq1KFOnTq8fv0aPz8/goKCCAoK4uHDh/j6+gLk+vlIG2/evCEwMJBy5cpRvHhxjf116tTB3Nychw81O+2c91D+wZffngEqV65M5cqVSUlJ4e7duwQGBhIcHIyfn5+qvvKHqhFdpqwzoSHBREaEa530FqEMbhydSuuXpbQ9QkdAlJGRQXR0FABOTqV59OA+kRHSpKfunVrrlNu1vfSD8Muq9dSpV1+vHpBlV4Qeu5xK67erbFlnQHegl90uR6W8tLQ0wsNCyczMpIzy/JyUKFmKF9HRRr0ElSnrTFio1F7VtZRdilS1l/4ycGVUdmmvpZyRkUF0lNKuHO2fkpKic2RJzqfMa8ToVumy5QgLDSEqIhxytcsAP1RWlsitvV4o7SqllFe6jDOQ+2dkOW3AGLsAyjorfTE8XG1BDpmIcKUvGmBbWedyaufkJCMjg6go+RlT94G01FSmT5nImVMnAOg3cDBffqV92W5DeBz0gvKORShdwg7f+5qVDJyKS33701DjXvIb1yyLbUErXsYnculOoMn6mUrpMs6Eh4YQFRGBsjKbGlHK56WUAe1VWvmMRUXm4ovKvkN+8crOvdt/8ebNawrZ2FCzVu6rwumjrHM5QpR9Yk00/TA8Qnrhcyqtv+9wNsAPo6MiAShtgLx/Ix9j7u+H4qMaMdb2Q2dIvpEcOL9+/Zrly5dr/G3btg3QfFPNWWTcFF1ev37N7NmzadKkCX369GHKlCls3y7lzZUpIz2QxtZbfv36NZAViOckb9682Nvbk5ioORKSU29tOisUCn788UeaNGmCp6cnEydOZP369bx+/ZqKFSsapevbUrmqVPD/wf27Wvc/UNa+rKrtFyIHLi4VsbCwIDgokNdaXqb8n/iRkpxM0WIOOBQvQYGCBXGrVUfnn0yVajVwq1VHNapnCFWUCxnI+ufk/j0j7Kog2RX0XIddjyW7ihVzoLhy6ep9u3fSs0t7Fi3QvcyvXFasaNFienWQqVxV+sT8QFnPOCeyvVW0LOSQk/IVsrXXa027Ap74kZKS1V4A+/fspEWjWowZNkDjeJmn/soFQJQ/nobgWkWy66GyhmxO5PrNlavqb69yLhWwsLAgJOi5Drsea9glXz80OIg3yuc/O5mZmXrLwOlCXlRDrq2dk7+VvlhNRy3x7FTQ44tPZF90cKB4CfVl1L+ZO0sVFI8c8+VbBcUAtx5Jk4TrVdFesqt+VSnQu5lLRYnczrt6N+iDp1FAli88eqC9vR4q+0q578yNci4VyJeLLz71l3yxSDEHimlZ9l6+VjW32m+VRgFZfij7W07+vittr17d8D7x+fNArQNnTx77kazDDwUfPx9VYGwqBQpIOZguLi74+fnp/NOWSvG2TJo0ie3bt+Pu7s6GDRu4cuUKV69e5ddff6V8edNW5pLtiYyM1Lo/IyOD169f6yy/pI/Fixfz22+/UaNGDX7//XcuXLjAjRs3WLt2LbVra77Jv08+ay5N5jh14phG3mJ0dBTXrlzCwtKSz9xb6ZVlZW1N/YZNyMjI4KhyFnV2Dh+Q2r91Oykv27VyVX5bu1nnn8zC/y3lt7Wbca1s+OSgz1oo7Tquxa4oyS5LS0uaG2hXg0aSXUcOadp1SLarfVa+ed16nwDw1583tdYUPnPqBC9jYrCxsaG6joUftPGpsr3OnNS060V0FL5XpfZq1sIAu6ys+aRBYzIyMjh2WLPSypGD+wBo1TbLroqulUlNTcXv4X2CAp9pnHPj2hWeBz7F1taOWnU+McIu6avA2VPa7bquskv/5CMrK2vqKe06rsWuo4ek9mrZpr1qWzmXCpRxLkdaWhqH9u3SOOfsqWMkxMdTzKE4FSsZt5Jbc6XOJ48f1eqLVy9fxNLSkhZG+uLhg5q+eHC/ZFvbdh3Vtu/YtkV1/LgJkxgybIRRNmjjkDLNwbOVG5Y5Kk+ULFqI1g0qkpSSysEL942SW7NSSSAr8P7QyCkLZ08d18jHfREdxfVrl7GwtKRpc+N88eSRgxr7jx2SnjH31u019gH4P34EZAXrb0MLd0nfE1r8MCoqkiuyH7bU/fVOxtramoaNJT88pOwnsrN/3x4A2rXvqLHvv4LZB/zvY0MExkDBggUpXbo0QUFBauXRZO7fv8+iRYs4d07/UpPGEB8fz9mzZ3F0dOSnn36iYcOGFMm2Co+/v1S0P/uIsSEj4AULFqRs2bJERUWp5TPL3L17l6SkJJOX1t6/fz+WlpasXLmSZs2aqaVraNP5feJapSqfNGjEi+go5s6YTFKSNAoeFxvL9EnjUSgUdOzsQeHC6kX6Q4KDCHz2VFVXVcZ7wGAAfl2+hBu+WaX1jh85yJ6d27CwsMCzV9/3bBVUrlKV+g0aER0dxezp6nZNm6i0q4sHhe0NtGugZNfKZep2HTtykN07JLs+751lV/kKFWnctBnp6elMm/SVWnB86+YNvv9WqmgyeNgoLCwsDLbLtXJV6tWX2mv+zGx2xcUyc7JkV4dOmu0VGhLE88CnqvqjMn2U7bXqlyXcvJ61TPqJo4fYu0uyq2e29qpW3Y3qbrXIyMhg1rQJhIZkPR+3b91k7kxpsuxAn5EGTeKRqVS5KnXrN+RFdBQLZk1Rs2v2lK9QKBS069QVOwPt8uov2bV6xVL+zGbXyaOH2L9rOxYWFnTP4YeDh0sTYdf8tly1LDBIwckvPy1W3q8hRi/hWrlqNeo3bER0VBQzp05SlYaLi41l8tfjUCgUdDLCFwcMkipm/PLzEq5fy/LFo4cPsmv7ViwsLOjVJ8u2uNhYli/5EZCWjDZlop02bj8O48wNf0oVs2HdLE/yW0mVOorY5mfLfC+sLPOx6egtXsSpf1kr52hPpTJFVTnIOanuIo0w3vM3PEf9XSL7Ykx0FN/OnqryxVdxscydNoFUhYK2HbX5YjBBgU9VdZBlentL93v1yqXcupHli6eOHeLA7u3ks7Cg2+d9tOry1P8xAC4VK721XVWqVqNBw8ZER0UxfepElR/GxsYyaYLkh527dsM+hx8GBwfx7OlTjd/2gYOGArB86RJ8s/nhkUMH2an0w959TC8vJ/jv8lHlGBuKvGJNWlqaKt+uZ8+e/PTT/7F333FVVn8Axz+AXlCmiICAExVHbnOX5ciRVqampimKWzRtuLfpr53lNjW3aTlzpam5d+UeoKKogExBWZfx++MOQe7lDgHj9n374vWq+zz3PN/vPc/zcDj3POd8x/Tp0/nyyy+1v+wTExOZOnUqFy9epGpV03paDFEoFFhbW5OUlMTjx49xyPJV+5IlS7hx44Y2Tg1NvFnH/OrSpUsXvv32W2bMmMHcuXO1D+DFxsYya9YsADp37mxW3La2tjx58oS4uDg8s3zNtGPHDv7880+j4stL4yZNZ3C/Xhzcv5ezp0/i7VOGkNu3SE5OonIVP0aMzvmV64gh/QkPe0DAoGEMGPJ0Zo3adevzQb8BrP5pKSOHBlChoi+pqanahuH4yTNyXRkuL42fMp2B/r04+Mdezp46iXeZMoTceprXSB1fJQcO6k9Y2AMGDB7GwKFP86pTtz59+g9g1fKlBA5W5aVUpnJPvUrUhKk585o8YxZDB/Tl2pXLdHvnTcqVK49SqST0rupBzC7detCzdx+T8xozcRpDA3rz54F9nD1zCm+fMtxR11elKn4MH/VJjvd8ODSA8LAH9Bs4jIDBT1fOql2nPr39B7BmxVJGDQugfEVflFnqa+ykGTlW45r62ZcEDupL8I3rvN+lE2XLlUeZpuSeOq+3332PbmbMt/rphGkMH/ABhw7s49yZU3j7+HDn9m1VXpX9GPZhzrw+GjaA8LAH+A8cmm1FsFp16tGrbwBrVy7jo+EDKF9BVV+avD6dOD1HXq+3bkvQtSusXbmMGRPHsGTeHBwcHLl1M4iMjAxeb92Wd7r2MDkvgIlTZhDQ930O/LGXM6dO4lOmDLfV52IVv6qM+jjncs1DB/Yj7MEDBg4ZzuBhWc7FevXxDxjIimU/MmxQfyr6+pKaqtSunDdp2sxs5+KWTb9oG3fXrl4hoK8Q6PUqAAAgAElEQVT+P0w/HTfRpGnbhn+xlYOLBtH59Zd4rb4vtx7EULVcKeyLKTgfFMb4ebtzvGf39/0pV7oEny3bz6zlB3Js93BVDWG799DwAhr55aPxUxk5sA+HD+7jr7Mn8fIuw90Q1bnoW9mPISM/zvGeTwIHEBH2gD4DhuI/8OkUjDXr1KNnnwDWr1rGJ4EDKac+FzWrc46dME3vincx0aqVWt3d82Y4wuSpM/Dv05P9+/Zy+qT6PLx9i+Qk1Xn4kY7zcPAAf8IePGDw0OEMGfZ0hdi69erTL2AgPy37kSED+1HRtxLK1FRC1efhlGmfZVvxrrCRMcbm+082jEuXLk1ISAhjxozRLuIREBDAyZMn2b17N1evXqVZs2ZYW1vzxx9/EBYWRrt27ejYsWOexmFnZ0f79u3ZsWMH7777rnYGiNOnT3PlyhXc3NyIiorK9pdu6dKqr+lWrlxJWFgYvXvr/gXev39/Tpw4wZEjR+jUqRPNmzdHqVRy6NAhIiMj6datm9n5dOnShUWLFtG1a1fatWtH0aJFuXDhAmfPntXGHGfECl95xcvbh5/W/srSRfM4dvQQwUHXKenmxluvd2XAkOHaKYeMNWzER1Sq7MfGdau5qR5vWqdeA/r0G0CTZq/mRwo6eXn7sHLdryxZOI/jRw4RfEOV19stuzLQjLyGj1TltWHdam4GqfKqW1+VV9PmOfNydS3J8tUbWLNyOfv37iH07h1sbe14uVFjunV/36jhKfryWrbmF5YtnseJo4e5GXQd15JudOrchf6DTM9rSOBofCtV4Zef12jHB9ep14BefQfQpNkrOfYv7eXNT2t/Zc3KZRz58wD3Qu9ga1eMeg0a0rlrD15v3dasvEp7+/Dj6o0sXzyfk8cOczPoBq4l3ej4Thf8Bw0zOa9BgaOpWNmPTVnyql23Ae/3DaCxjrw076lVtz4b163i+pXLPHoUR2W/anR8pyudOnc1ubdYw9vHhzU//8riBfM4euQQQTduUNLNjc6tujJoaKB26jxjBX6oOhd/XruKYPW5WK9+A/r2H0izV7Kfi+f/+Uv739cNzIDyWMf46tzcCYulaf8FTApoRfumftT09SAi+jE//XaGz5YdIDHZtD/wra2tcHZQfdMQFpX7Q9/5qbSXD4tWbmDFkvmcPH6EW8Gqc7HD213wHzjU5HNx4PBRVKxUhc0b1nJbvXJkrbr16dkngEZNdZ+L6enp2vHuJUu5P19Cat4+PqzbsIlF8+dyRH0eurm50bJLN4aYcR6OHPUxlav4sX7taoKCVB1R9eo3oF/AIJq/UnD3evHvYpVZUN955xHN1//Xr1/XvvbBBx9w+vRp9u7dS7ly5bLt37JlS+7fv59t/0uXLjFhwgRu3bpF6dKl2bdvH6Dq5Vy7di3btm3j1q1bFC1alHLlyvHee+/RpUuXbE9z+/n54eHhoXdVPF3b7t27R6tWrWjYsCGrV68GVD3SixYtYvfu3URERODi4kK5cuXo1q0bXl5e9OrVi/bt2zNnzhxA9eDbhAkT2L9fNTfkDz/8QIUKFWjVqhX16tXTPiioyWfNmjVs3bqV27dvo1AoqFatGj179sw2f3HWz+ny5cs5nlr38/PD29ubAwdUvSNpaWmsWLGCzZs3c//+fe1QlI4dO/Laa6/RqlUratWqxS+//GKwfowV86RgZrkoaEbMM18oKdMK1W3FJOmF65ZpNHtb45fALkzcW05+0SHki+CdU190CPmmRHHjF6ApTIorCq4bd8/lyAI7Vrsaxj+AXRgUuoax+G+ShnHhIg3jwkcaxoWLNIwLH2kYFw7/yaEUQgghhBCWSsYYm89C+6uEEEIIIYQwjfQYCyGEEEJYEOkxNp/0GAshhBBCCIH0GAshhBBCWBRLXJGuoEiPsRBCCCGEEEiPsRBCCCGEeIF2797NihUrCA4OxsbGhrp16zJ8+HBq1apl1PujoqJYtGgRBw8eJCIiAltbW6pXr07fvn1p3dq0xaikx1gIIYQQwoJYWxXcz/NauHAho0aNIioqivfee482bdpw6tQpevbsyZEjRwy+//79+3Tu3JnVq1fj7u5O7969eeONN7h8+TLDhw9n3rx5JsUjC3yIQkEW+ChcZIGPwkcW+ChcZIGPwqcgF/jYfy2qwI7Vqqqb2e8NDg6mU6dOVKpUiQ0bNlBcvaz31atX6dmzJ87OzuzduxdbW1u9ZQQGBrJv3z5GjhzJ8OHDta+HhYXRtWtXoqOj2b59O1WqVDEqJgv9tSyEEEII8d9kVYD/nseKFSvIyMhg2LBh2kYxQLVq1ejatSvh4eHs379f7/sTExM5ePAgLi4uDBkyJNu20qVL07NnTzIzMzlw4IDRMUnDWAghhBBCFLgTJ04A0KxZsxzbmjZtCsDx48f1vj89PZ1PP/2UkSNHYmOT81svOzs7AJ48eWJ0TPLwnRBCCCGEBSkMC3wolUru37+Pq6srTk5OObaXLVsWgJs3b+otw9HREX9/f53bMjMz2bt3LwB+fn5GxyU9xkIIIYQQokDFxcWRmZmJs7Ozzu2axnJCQoJZ5a9du5bz58/j4eFh0swU0mMshBBCCGFBCnKBj1atWuW6Xd8Y4bS0NACKFtX9sKVCoQAgJSXF5Ji2bt3K7NmzsbGx4fPPP9cOqTCGNIyFEEIIIUSB0sw0oVQqdW5PTU0FyPZQnjF+/PFHvvnmG6ytrZk9e7Z2rLKxpGEshBBCCGFB8mJ+YWPlNmtEbhwdHbGxsdE7VCI+Ph5A5/hjXVJTU5k8eTJbt27Fzs6Ob775xuTFPUAaxkIIIYQQooAVLVqUsmXLEhISwpMnT7C3t8+2/e7duwBUqlTJYFmPHj1i6NChnDt3Djc3NxYuXGj0qnnPkofvhBBCCCEsSGGZx7hhw4ZkZmZqp23L6tixYwC8/PLLuZbx+PFj+vXrx7lz56hSpQq//PKL2Y1ikIaxEEIIIYR4Abp164aVlRXff/99tiEV165dY9OmTXh6ehocDjF16lQuX75M1apVWbt2LV5eXs8VkwylEEIIIYSwIIVhHmOAmjVr0q9fP5YvX06nTp1o164djx8/ZseOHaSlpTF79mzt7BTx8fGsXLkSgBEjRgBw+fJlduzYAajmKtZsf1bt2rV59dVXjYpJGsZCCCGEEOKFGDt2LBUrVmTdunWsW7cOe3t7GjZsSGBgYLYhEfHx8cybNw942jA+dOiQdvu2bdv0HqNPnz5GN4ytMjMzM81JRIiCFPMk/UWHkC+sLXQwkzLNcm8r6RZ6y7S3zbmcqiVwbzn5RYeQL4J3Tn3RIeSbEsV1z2tb2BVXFFw37rGg2AI7VrPKJQrsWAXBQn8tCyGEEEIIYRoZSiGEEEIIYUGsC8sg438haRiLQiFJaZlDKZItNC9LHkphqcNfFDaWmZilDjkY89uVFx1CvpnVvuqLDiFflHczflli8eJIw1gIIYQQwoJIf7H5LLOLQAghhBBCCBNJj7EQQgghhCWRLmOzSY+xEEIIIYQQSI+xEEIIIYRFsZIuY7NJj7EQQgghhBBIj7EQQgghhEWRaYzNJz3GQgghhBBCID3GQgghhBAWRTqMzSc9xkIIIYQQQiA9xkIIIYQQlkW6jM0mPcZCCCGEEEIgDWMhhBBCCCEAGUohhBBCCGFRZIEP80mPsRBCCCGEEEiPsRBCCCGERZEFPswnPcZCCCGEEEIgPcZCCCGEEBZFOozNJz3GQgghhBBCID3GQgghhBCWRbqMzSY9xkIIIYQQQiA9xsJCREdF8tPieZw6foT4R3G4lXLnldfb0CdgCMXt7U0ub//vu9i0YQ23gm+gUCioUrU63Xv35+XGTbPtt2fHVr6cOdmoMsdMnkm7ju+YHIsuMVGRrFq6gLMnjhIfH4ebmzvNXmtFz36DKV7c9Hyz2rpxDUt++Jqv5v9Ejdp18yTeZ8VER7J22QLOnTpKQvwjSrq50+TVVnTvO+i549/+y1qWzf+a//2wnOq1dMevTE3lt03rOHLgdx6E3iEjMxMvnzK80rIdb3XthcLW1uzjx0RFsmbZAs6dPEq8OremLVrRw//5c9u2cS1L533N5/OWU0NPbhrB16/w8ZA+vO8/mO59Bz7XcQGiIiNZsvAHThw9zKNHcZRy9+C1lm3oP2gY9mZcY3v37GTDulUEB93AVmGLX7Xq9O4bQKMmzYx6f2LiE3p1fYvw8DC27T6Au4enyTGA5d47XIoVoWvt0tTxdsLB1obYRCWn7z5iy4VwktMyTCrrWbZFrPmyU1XcHBSM2HSZmESlwfe0q1qKD172ZvqeIG5EPjH72NFRkaz6cT6nTxwlIT6OkqXcad6iNb36DTarvg7u282WjWu4HRyEwlZBJb/qvPe+P/UbNdW5f2pqKls2ruHA7zt5cC8UJxcXatSsQ48+A6hYqYrZeeU1mcfYfNIwFoVeTHQUwwN68TA8DCcnZyr4VuZuyG02rl3BqeNHmLd0DfYODkaXt27FUpYu/B4rKyvKV/QlOTmZv86c4u+zpxk9bgod3+mq3beEa0leyqWBkhD/iDshtwAo7eVtdo5ZxcZEM3pwHyIjwnB0cqZ8xcqE3rnFpvWrOHPiKN8uXkVxe+PzzerGtcus+nF+nsSpT1xMNGOG9SEyIhxHJ2fKVajEvbu32bphFedOHeXL+SvNjj/o2mXWLss9/qTERCZ/NIiga5exsrLCo7QPVlZw9/ZNVv84l9PH/mTGN4uxK1bM5OPHxkTzydCnuZWvWInQO7fZ8vMqzp48ytcLny+3NQZy00iIf8S3n00iIz3drGM9KyY6ioF9exAeHoaTszO+laoQcvsW61b/xIljh/lxxXqTrrGVy5ewaN4crKysqOBbiZTkZM6ePsm5M6cYO3Eab7/bzWAZi+d/T3h42POkZbH3Die7IkxvVwU3BwUJKWmExiXj5WxLxxru1PF2ZNqeIJKU5jeO36tTGjcHhdH7V3AtRrc65v3hklVsTDSjBn3Awyz3vrt3bvHr+pWcPnGEOUtWY2/C9fXzqmX8tPgHrKysKFfBl5TkZP45e4rz504zcsxkOrzVJdv+SYmJTPhoKFcu/gOAT9ny2NjYcGj/7xz9cz+fTJpJyzc6PHee4sWShrEo9L6cOYmH4WG0bteRTyZOR6FQEBcbw+QxH3L5wj8snvsNH42falRZVy6eZ9miH7C3d+Dz7xdSo2YdAPbt/o0vZkxi7tezadCwCZ7qX1SNmr5Co6av6CwrMzOTMSMHcSfkFl169KZ2vZfzJN9vZ00hMiKM19u+yaixUymqUPAoNoYZE0Zz9eJ5ls3/jhFjjOuJyurG1UtM/XQEyUlJeRKnPt9/PoXIiHBea/MmgZ9OUcUfF8PsSR9x7dJ5Viyaw7CPJ5lcbtC1y8wcN4Lk5NzjX7nke4KuXcanXAXGTv+KsuV9AQi5FcQXUz7h+pWLrFz8PYNHjTM5hjn/U+f2xpuMHPM0t1kTPuLqpfMsXzCHwE9Nz+3G1cvMGGtc3cTFxjBz3IeE3rlt8nH0mTl1AuHhYbTr0InxU2aiUCiIjY1h7EcjuHj+b+bO+Ypxk6YbVdalC+dZPP977B0c+G7uEmrWVl1je3ZuZ+bUCXzzxWc0bNw018bg5UsX+HXDuufOy1LvHUOalsXNQcHRWzH8eCKUtIxMHG1t+Oi1ClRxd6BnPS+Wn7pnUpkaFUsW5w0/NxP2L8YnLStiV9TGrONl9fWsyTyMCKNV2zcZNW6atr6mjx/NlYv/sHT+t3w4ZopRZV29dIEVS+ZS3N6BWd8uoPpLtQHY//sOvv5sMgu+/R/1Xm6MZ+mn5+GiH77iysV/cHJ2Ycrsb6lZp762rKljR/LVzImUK18R3ypVnzvX5yXzGJtPxhiLQu1m0HVOnzhGiRKufDx+KgqFqhfDpYQrU2d/Q1GFgj07thIbE21UeT+v+YnMzEz6DBii/cUG0KZ9J97u2gOlUsmvP68xqqytv67n3OmT+JQpx8Bho0xPTofbwTc4d+oYLiVcGTlmMkXV+TqXcGXCzK8oqlCwb9c24mJjjC4zMzOTXVt/ZczwAB7FxeZJnPqE3LzBX6eP41zClWGfTHoav4srY6Z9SdGiCvbvNj3+Pdt/ZcJIw/EnJyWxf9c2rKysGDV+prZRDFC+YmVGTfgMgH07t5CSkmxSbrdv3uCvU8dxKeFK4KfZcxs740uKKszLbfe2Xxk/wri6ufjPWUYP7MWNq5dMij03wTeuc/L4UUq4lmTspOnaa6xECVdmffkdCoWCndu3EGPkNbZm5TIyMzMJGDRM2ygGaPfmW3R5rydKpZKf167S+/60tDQ+nzlV+/may1LvHWVc7Kjt7cSjJCVLT6oaxQAJKel8fziE1PQMWvi64mRner+YtRUMaFwGpbpMQ1pWLsnkNyrjbFfU5GM961bwDc6eVN37Phw7JVt9TVLf+/bu3EZcrHH19ctaVX317j9Y2ygGaNW2I53e7Y5SqWTLhrXa16OjItm3azsAYybP0jaKAaq9VIuBwz8iIyODpQu+e+5cxYslDeP/iM2bN+Pn55fjp1q1atStW5f27dsze/ZsoqKiXnSoJtm/dxcAr7Z6A1s7u2zb3Eq507BJc9LS0jhx9JDBspISEzlx5BBWVla0btcxx/YOnd4F4MjBfQbLiouNYdmCHwAI/Hjcc41ZzerPfbsBaP56G2xts+db0s2dBo2akZaWxqljhvPVGD2oN/O+/gylMpWe/oNw9yydJ7HqcugPVfzNWuiOv546/jPHjY//06EfsPDbWSiVqbzXZyDuHvrjD7p2mdTUFEqW8qBy1Ro5tvtVr4mjkzNKZSr3TOxxPaSum2av6c6tvjq30ybUzceDP2DBN6rcuvcdmGvd/LRwDhNGDiTqYTgNmrxC0xatTIpfn717dgLQsnVb7J65xkqVcqdxs1dIS0vj6OE/DZaVmPiEo0f+xMrKirYdOuXY3ukd1VfXfx7Qf42tWbmM4KDr9B841IQscrLUe0fTCiUAOHUnDmV69gZsXFIa5+/HU8TGmro+TiaVC9CxhjvlXIux5UK4wX1ntK9MQOMyFLGxYvOFcCIfp5p8vKwO7lPV1yu67n2l3Hm5ser6OmlkfZ08dhgrKytatX0zx/a2HTsDcPTQH9rXLvx9lvT0NHzKluflJs1zvKdVu44UL27P32dPmfTHb36xKsAfSyMN4/+YqlWrEhgYqP0ZOnQoPXr0wNnZmZUrV9K1a1ciIyNfdJhGu3ZZ1TNW/aVaOrdXq1ETgIv//GWwrBvXr5CenkZpbx9KuJbMsb1CpcrY2toR+TCC8LAHuZa1ZvkSEhOf0KBRUxrquIma67q6J7BqDd35+lVX5Xv5wt9Gl3nj6mW8y5Rj1pzFfDBg2PMHmYuga5eBp3E+q0q1lwC0Y/iMLdOrTDlmfLOIXv1zj79shYqMm/E1/Yd9pHN7eno6KSkpAGRkmDYGM+iqOrcaeZubd5lyzPx2Eb0Dcs/txtVL2Ds4MmTUOKZ8/j12xYobfZzcXLl0EYCXauo+52qor70Lf58zWNb1q1dJT0vDy9sHVx3XmG+lKtja2fEwIpywB/dzbA+9G8JPSxfhW6kK7/f2NyGLnCz13uHrpqr34KhEndtvql/3K2Xag2oejgo61/TkbmwSu648NCIOex48SuZ/f9xk03nDDWlDrl9R1Vc1PfVVVX1PuWTEvS/4xlXS09Pw9PLBpYSO+vJV1VfUwwgiwlX19TBCNZ69kl81nWVaW1tT2tuHzMxMgq5fNZyQ+NeSMcb/MdWqVWPEiBE6t40ZM4Zt27Yxd+5cZsyYUcCRmSfsgWqcXGkvH53bPTy9AHhwP9RwWfc1Zeke22htbU0pD0/u3Q3hwf1QPEt76dwvPOwBv23ZCEC/QcMNHtcU4ep8PfQcW9OjqMnFGCPHTqF1+04UKfL8X3caEqGNX/dnrIk//IHh+tIY/slkWrYzLn5nF1eavKq/J/X8uVOkpiRjbW1Dae+yRscAEB5mZG5GnIsagWMm08rI3Dq88x616zfEydnF6PKNcV8db2lv3deY5jq4f89wXprr0EtPWdbW1nh4eHL3Tgj374XmuBa/+Gw6ytRUxk6cRpGiz3e+Wuq9w91B1cOsr4c26onqdQ9H03qiNb2/y06Gkm7ESIofT9zlyM0Yo/Y1Rrj6DyVPvdeX6jM15t6n2UdfWdbW1pRy9+Be6B3C7odqzwWA9LQ0veWmqbc9DM/9j58CYYlduQVEeoyF1pAhQwA4ePDgC47EeJpxl07Ozjq3Ozqpvi6Mf/TIiLLiVGU56W9YODpqyovTu8+2X39GqVRSo1Ydvb0b5tIcV1/jx0EdX0Iu8T2rXad3C6RRDE/jd3TSXV8ODur44w3Xl8YbHfMm/vS0NNYsnQdA3Zcb4+DoaNL7DeamOXdMyK2tCbm90vKNPG8Uw9NrzFlP2Zpr4pER51ycgbJyK2/71k2cO3uKzl27ZxubbC5LvXc42qoecktI0d2Ae5KqmqnEwdb4h+FaVHKlhqcj+29E6+2JftafwXnXKAZ49EhVX44G7n25fb5Py9LcR3XXffbyVPWvaUTfvhmkc//U1FRt4/3x4wSDMYh/L2kYCy0vL9VfxbGxTx/yiYuL44svvqB169a89NJLNGrUiKFDh/LPP9m/Dr537x5+fn5MmTKFEydO0K1bN2rVqkWLFi2YNm0a0dHGPRBhqlT1196KZ8acadiqx+elpqYYUVayuiz9PSna8lJ098akpqayZ8dWALr06G3wmKZ6mq/uGJ/m+3zj+fKLph70xa95XfkC4v9x7pfcvHGVIkWK0HtAoMnv19SN7b8wt+eRYiAvzfhcY845Q2VlKy/LNRYTHcW8OV/h5laKoYGjjQvcAEu9dyhsVL/Wlem6hwKlqucwLmpj3K9/J7sivF/Pi9hEJRv+fnE9oYauL1sTri9j6kvxTP3Xqd+QogoF9+6GcPjA3hz7/7b5Z+0Du2lKw/M65zerAvxnaaRhLLRCQkIA8PRUzTcZFhZG586dWb58Oa6urvTq1YvGjRtz5MgR3n//fbZu3ZqjjPPnzzNw4EAUCgW9e/fG29ub9evX071793x5sM/aOvdTOEP99LSVEXPXWBkoCyAjM0Ndnu7tRw7u41FcrGqRgDx6+Ckrg/lmGp/vi2Bs/AX9PeCapfPZve0XAD4YOIKKlU2fbslQbpkmnIv/JobzMn4strURuWvGdmfd9dsvZ5MQH8+oT8eb3JOvNxYLvXc8vYZ009SBgd20+r7sjYNtEVadufdccx8/L8P1pY4tj+or85l7qbNLCd7p+j4A3/1vGr/v3Erikyc8Tohn+6af+WnxXO23RUWKyCjVwkxqTwCqsVFz5swBoF27dgBMnjyZBw8e8OGHHzJs2NMHfy5fvkzv3r2ZPHkyjRo1onTpp0/KX7t2jT59+jBx4kTta99++y2LFy9mzpw5fPbZZ3kat12xYjxOSNDbq6NUqnoPcuuh0iimflgpt54vZapSXZ7uXqYjB/cD8MrrrbHJh5ujnV0xHj9O0Nsronk9r2bByGu2dsVIe5yg9zNOSzW+vvJCZmYmKxZ+x9aNqwF4890evNO9j1llGcpNcy4qFP/OutGnWLHiJCTE681L8/qzMzvoLEu98l/u11j28o4dOcT+fXto2rwFrdq0Myn23FjqvSMlLYMiNtZ6e4SL2Kgaevp6lLOq4+1E4/Il+PveI07fNX4IUH7Q1peeHnelUvP5Gl9fufUua++liqf11XdQIOFh9zlycB/fzp7Kt7OfznH9xptvU6xYcbb9ut7sRXzyUiH7+/tfRRrG/zFXr15l7ty52v/PzMwkNjaW48ePExISQuXKlRkyZAgREREcOXKEihUrZmsUA9SoUYOAgADmzp3L5s2bGT786UMiLi4ufPjhh9n2HzlyJJs2bWLnzp1MmfJ0/sm84OjkzOOEBL1jUjXjzZydSxhVFuQ+vlVbnkvOcW5paUrOnT4BQLMWLQ0ezxwOTs48fqw/34R4Tb55P9Y0Lzg6OfPkcQKPE/TUlzovfeMI81J6ejrzv57J/t3bAGj/znsMHDHG7PK0uemrG/VYRScd586/mZOzMwkJ8XrH2mquCRcXw9eYk/oay23c7iPtNVaCxMQnfPW/6RQrVoxPxpm+MEpuLPXe8Tg1HXvbItgrdI8hdrBV/drXNwZZw7aINf0a+ZCsTGfFafMWA8lLjo7q+tJz70gw8PxFtrKcDD/LoLkXZa2vokWLMumzrzl++ACHD+wjNjYadw9PWr7xJnUbNOJ/01SLAumamUQUHtIw/o+5du0a165d0/6/tbU19vb2lCtXjhEjRuDv74+DgwNnzpwB4OWXda+41KBBA0DV0M6qZs2aODyzhGqRIkWoWbMmBw8e5Pbt2/j5+eVZPmXKlifs/j0ehoeja5ash+GqaYK8fMoYLqtcedV7InQvM5uRkUFUpGqaIi/vnOVd/Odvnjx5jKOTE7WzTP6el3zKliP8wT0eRoRTLcuk9BoPI1T5euqI79/Au4wq/siIcKrWyBl/1EPVZ++pZ6aAvJKWpuSbmRM4rp6ntHOPvvgPeb5FWLLlpqNuIgsot7xWtlx57t8LJSI8TOdDb5plmb2NuMbKli+f7T3PysjIIFJ9jfn4lOHalctEqK/hdzu20Vvu2+1Vjcn5S1ZQr0FDg3GA5d47wuJT8HC0xc1eofNBOTd71cOcEQm5j8WtWLI4bvaqTozv380557fG3C6qbZ/tDeZqxGNzwzbIp2x5wh7c42F4WLYFOTQ09z5dn6+usrK+51kZGRlEq+urtI7ymr7akqav5vwD5uYN1e/WshV8c2wraNJhbD4ZY/wf07lzZ65fv679uXr1KmfPnmXTpk0EBgZqG7UJCaqnah31jOfz8PAAIOmZJWqzDqvI6tly84pfNdVN+dqVizq3X718AYCq1V8yWFYF30rqh+wIky8AACAASURBVCvu6Hyq+FbwDVJSkilZyp1SHp56j1WjVt18GUYBaBeluHFF98pm19Wfg+Zz+bfx9asOQNA13fFr8tLM+Ztf5n81U9so7hUw/LkbxQCVqqpy07fq3PUCyi2vaa6dK+rz+1lXLqler65n/uasfH0ro1AoCL0bwmMd94LgoOukJCfjVsoddw9P7B0cqFWnnt4fjWo1alKrTj3sHYz/CttS7x23olWNYc18xs/ydVMNZ7kZnfvsEomp6Vx/+Fjvj8bNqCdcf/iYRPVsF/mlsvr6uq7n+tLUo58R9VW+oqq+7ofe4YmO+rqtqS+3UpRyV/+uS0xkx5aNbPt1vc4yw8PuE3rnNq4l3SijbniLwkkaxkInTUM2IiJC5/b4+HhANXQiq2cbys/uX6KE4a8lTaH52vHAvj3ap5Y1oiIfcvrkMRS2tjR/zfDDLHZ2xWjQqCkZGRns3bk9x/bdv20BoGWb9jrfH6zuLcjPRmmTV14H4PD+nPlGRz3k3KnjKBS2Onsz/g0aN1fFf+TA7zrj/+u0Kv7G6jzzw87NP3Pg998A6Dd0NO99MCBPytXkdthAbk1ezb/c8kML9bWz7/fd2lklNCIjH3Ly+FEUtra0aNnaYFl2xYrRsHEzMjIy2LUj58O7O7ZtBqBNuw4A+FWtzuLla/T+aHz+9fcsXr4GP3XjyRiWeu84F6oaAtC4vAtFrbP3G7oUK0ItL0dS0zI4ezf3ac3uxCYx4/dgvT8acw6FMOP3YO7E6r735xXNPe3QHzrufZEPOXvqmNH3Pju7YtR/uQkZGRns252zvn7fqTo3X8tSXwqFgmULv2fhnC+0vclZ/bJ2BQDt3+ry73jAVpa+M5s0jIVO1aurfsH8888/2knLszp16hQAVapUyfb6hQs5e5WUSiUXLlzAxcWFcuXK5WmcVapWp37DxkRHPmT21PEkJal6QR7FxTJ9wscoU1Np++bbuJRwzfa++/dCuRtySzuXqUaP3v0AWLrwe/46c1L7+r7dv7Ht158pqlDQ+b33dcZyK/gGAL6Vq+jcnhcq+VWjToNGREdF8tXMiSSr/xB5FBfL7MmfokxNpXWHt3B+Jt+w+6GE3rmdI9+C5lulGrXrNyImKpJvZz2NPz4uli+njUGpTKVlu044u+SM/96d28Q/Z/zxcbGsWqJabrd1h3fMftBOF03dxERF8s1n2evmiyljUKam0qq97tz+DXWjj1+16rzcqAlRkQ+ZPmms9hqLi41l4pjRpKam8mandyjxzDl3L/QuIbdvERebPa/effsDsGjeHM6cOqF9fc/O7WzauB6FQkG37r3yOSvLvXeExCRxMSwB1+IKhjUvh20R1a95B1sbPny1PAobaw7fjCEhJXsPr7uDgtJOtibNb1yQKvtVo26DxkRHRfLFjAkkZ6mvz9T3vjYd3spRXw/uhXJXx/XVrZc/AD8tnsvfZ09pX9//+w5+27yBogoFb3ftqX3dpkgRmjRvQWZmJnO+mMGTJ6pe8/T0dDb/vJqdW3/BydmFd97L/3NX5C8ZYyx08vT0pHnz5hw9epQFCxYwcuRI7bZr166xbNkyFAoFHTp0yPa+O3fusGLFCvz9/QHVw33fffcdsbGx9O/fP1+msflo/FRGDuzD4YP7+OvsSby8y3A35DbJyUn4VvZjyMiPc7znk8ABRIQ9oM+AofgPfPpwYc069ejZJ4D1q5bxSeBAylXwRalM5YF6Va+xE6bpXbUqJlo1HZ27e86vSvPSyDFT+GSoP8f+/IPzZ0/h6V2G0Du3SElOpmKlKgwYnnO54/EfDuJheBjv9xtM74Ch+RqfIcM/mczYQH9OHN7Phb9O4+nlw727t0lJTqaCbxX6Dc0Z/5SPBvMwIowefQfTs98Qs4+9d+dmkpNVDdZbQdcYF9hP776DPhxr8rRtwz+ZzNjh/hw/tJ/z505T2tuH0Dvq3CpV0bkU9aTRg3kYHkZP/8G839/83PLTuEnTGdyvFwf37+Xs6ZN4+5Qh5PYtkpOTqFzFjxGjP83xnhFD+hMe9oCAQcMYMOTpvNC169bng34DWP3TUkYODaBCRV9SU1O1K+eNnzxD7wpyec1S7x3LToYytW1lGpZzoYanAxGPU/FytsWuiA13YpJY91fO+YgntKlEKQcFm86Hs/nC8y/hnB9GjZ3M6CH+HP3zD/45d4rSXmW4q733+TEoMOf1Ne7DQUSEP6B3/yF8kOXe91LtenTv3Z8Na5Yz7sNBlC1fEaVSSZh6pcNPxk3NtuIdwJAPx3D+rzOcPnGE3u+8gVeZskQ9jCAuNobixe357Jv52gdMXzRLnF+4oEjDWOg1Y8YMevXqxfz58zl27Bh16tQhIiKC/fv3k5GRwcyZMylTJvuDCQ4ODnz++eccOnQIPz8//v77b/755x9q1Kihdynq51Xay4dFKzewYsl8Th4/wq3gG7iWdKPD213wHzhUOzWPsQYOH0XFSlXYvGGtdpWjWnXr07NPAI2avqLzPenp6Tx5rOpBKFnK/fkSMsDTy5sflq1jzbKFnDlxhJCbNyjh6kbTTi3p1X8IdsWK5evxn5dHaW++XbKO9T8t4uzJI9y5FYSLqxtvvNmSHv75G//Vi+e1/30r6Foue6KtT1N4ennz3Y/rWPfTInXdqHJr27ElPfv9++tGHy9vH35a+ytLF83j2NFDBAddp6SbG2+93pUBQ4abfI0NG/ERlSr7sXHdam4Gq66xOvUa0KffAJo0ezU/UtDJUu8dkY9TmbTrOl1qe1LH24myLnbEJadxMCiGzefDSUl7cfMRPw9PLx/mLV/P6mULOX38MLdv3qBESTeadWrFBwFDsDOxvvoP/ZAKlaqwdeNabt9S1VfNOvXp3rs/LzdpnmN/J2cXfvhxLavU997bwUE4u5SgTfu3eN9/kFEPaop/P6vMTGOn+RaF2ebNmxk/fjydO3fm888/N/p9MTExLFq0iP379xMREYGzszMNGjQgICCAWrWeLll67949WrVqRb169RgwYABz587l5s2beHh40LFjRwYNGkTx4qbdtLK6H1e4VgszVrIyfx9YeVGUaZZ7WzFibYBCyc2hcM2vbKwkC73Gxvx25UWHkG9mtTd9gZ3CoLyb4bm+88qVB08K7FjVvewL7FgFQRrGIk9kbRivX6/7qd3nIQ3jwkUaxoWPNIwLF2kYFz7SMC4cZCiFEEIIIYQFkRHG5rPQvg8hhBBCCCFMIz3GQgghhBCWRLqMzSYNY5EnfHx8uH79+osOQwghhBDCbDKUQgghhBBCCKTHWAghhBDCosgCH+aTHmMhhBBCCCGQHmMhhBBCCItiJR3GZpMeYyGEEEIIIZAeYyGEEEIIiyIdxuaTHmMhhBBCCCGQHmMhhBBCCMsiXcZmkx5jIYQQQgjxwuzevZvu3btTv359GjZsyODBg7lw4YLZ5X388cc0aNDArPdKw1gIIYQQwoJYFeC/57Vw4UJGjRpFVFQU7733Hm3atOHUqVP07NmTI0eOmFzeggUL2LFjh9nxyFAKIYQQQghR4IKDg/nhhx+oUqUKGzZsoHjx4gD07t2bnj17MmnSJPbu3Yutra3BspKSkpgxYwabN29+rpikx1gIIYQQwoJYWRXcz/NYsWIFGRkZDBs2TNsoBqhWrRpdu3YlPDyc/fv3Gyxn165dtGvXjs2bN9OiRYvnikkaxkIIIYQQosCdOHECgGbNmuXY1rRpUwCOHz9usJz169ejVCqZOXMmixcvfq6YZCiFEEIIIYQFKQyTUiiVSu7fv4+rqytOTk45tpctWxaAmzdvGixryJAh1K1bN1uvs7mkYSyEEEIIIczSqlWrXLfrGwoRFxdHZmYmzs7OOrdrGssJCQkGY9DV42wuaRgLIYQQQliSQtBlnJaWBkDRokV1blcoFACkpKQUWEwgDWMhhBBCCGEmYx6O00Uz04RSqdS5PTU1FSBPhkeYQhrGQgghhBAWJC/mF85vjo6O2NjY6B0qER8fD6Bz/HF+klkphBBCCCFEgSpatChly5YlOjqaJ0+e5Nh+9+5dACpVqlSgcUnDWAghhBDCghSWeYwbNmxIZmamdtq2rI4dOwbAyy+//HwHMZFVZmZmZoEeUQgzJKRkvOgQ8kVyqmXmZcmKFvn3f0VpjgwLPRWtLbT7JyEp7UWHkG+qvPO/Fx1Cvkg6PK3AjnU7KrnAjlXBzc7s9168eJFu3bpRuXJl1q1bh6OjIwDXrl2jR48eODs7s2/fPu2DeMby8/PD0dGRs2fPmhyTjDEWQgghhLAgheXP95o1a9KvXz+WL19Op06daNeuHY8fP2bHjh2kpaUxe/ZsbaM4Pj6elStXAjBixIh8i0kaxkIIIYQQ4oUYO3YsFStWZN26daxbtw57e3saNmxIYGAgtWrV0u4XHx/PvHnzgPxtGMtQClEoyFAK8W8hQykKFxlKUfjIUIrnFxJdcEMpypc0fyjFv5GF3jKEEEIIIYQwjQylEEIIIYSwIIVhHuN/K+kxFkIIIYQQAukxFkIIIYSwKM87v/B/mfQYCyGEEEIIgfQYCyGEEEJYFOkwNp/0GAshhBBCCIE0jIUQQgghhABkKIUQQgghhEWRh+/MJz3GQgghhBBCID3GQgghhBAWRrqMzSU9xkIIIYQQQiA9xkIIIYQQFkXGGJtPeoyFEEIIIYRAeoyFEEIIISyKdBibT3qMhRBCCCGEQHqMhRBCCCEsiowxNp/0GAshhBBCCIH0GAsLERX5kIXzfuDY0cM8iovD3d2Dlq3fYMCQYdjb25tc3p5dO1m/ZhXBQddRKGypVr06ffoNoHHTZjr3T01NZf2aVezds4u7d+6QkZlB2bLlaNv+TXr27oOtra15eUVFsnThXE4cO0z8ozjc3D14rWUb+g0YSnEz8tq3Zycb16/mZvANFApb/KpVp1ef/jRsrDuvmVPG8/uu7XrLa9ikGd/OXWJyHBabV2Qkixf8wHH1eVjK3YPXW7UhYLB55+Hvu3eyYe0qgoNUeVWtXp3efQP0noeJiU9YsXQJB/7YS3jYAxydnKhTtz4f+AdQ/aWaJh//2dyWLPyBE0cP8+iRKrfXWrah/yDzctu7Zycb1qlys1XXWe++ATRqoju3ZyUmPqFX17cIDw9j2+4DuHt4mhwDWG6dRUdFsmLJPE6fOEr8ozhKlnLnldda80H/IWZdYwf27mLzhjXcCg5CYaugsl91uvfuR4NGTXXun5GRwW+bN7JnxxbuhtzGytqK8hV8efPtrrTr1BmrfOjS9CzpwJSAlrRrXBlXp2I8iEpg66ErzF5xiMdJqUaV0btdHX6c8I5R+w6cvZU1e/55npDzjZWMMjabVWZmZuaLDkIIQxJSMvRui46Oou/77xEeFoazszNe3j7cvnWL5OQkKvr6snz1zzg4OBh9rJ+WLmH+D99hZWVFRd9KJCcnc/9eKFZWVkyYPI3OXd/Ltn9i4hOGDOjHlUsXsbKywtunDFZWcP/ePTIyMqhZqzYLliynWPHiOY6VnKo/r5joKAb27UFEeBhOzs6U9vLhzm1VXuUr+rJ4+TrsTchr9U8/snj+HKysrKhQUZXXg/uqvD6dMJW3OnfL8Z7+vbpy4/pVqr9UCxsbmxzba9SsTeCoT42OwRLyKlpE9y+c6Ogo+vfuTniYKi8vbx9C1OdhhYq+LF213qTzcMWyJSycO0fneThu0jTe6ZI9r+SkJAb0fZ+gG9cpWrQo5cpX4FFcHJGRD7EpUoSJU2bw5lv6f+Fn6D8ViYmOIuCD7oSr68zLy4eQ209z+3HFepPqbOXyJSyap64z30qkZMlt7MRpvP1uzjp71ndfzWbj+jUAuTaMrXP5XrQw11lCUpreOGJjohke8D4Pw8NwdHKmtJc3d0NukZycTLkKvvzw42rs7Y3Pa93KpSxf9ANWVlaUq+BLSkoyYffvYWVlxaixk3nz7a7Z9s/IyGDmpE84cvAPrKysKO3lA0DYg3tkZmbSul1Hxk2drfd4Vd75n9GxabiXsOfI4oGU9XQh+lEiIWFxVC3nhn0xBVduP+S1octISEwxWM4bjSox9oNX9W4v4VSMauVLAdBmxE8cPX/H6BiTDk8zet/nFf5IWWDH8nQuWmDHKgjSMBaFQm4N45FDB3H82BHad+zE5GmfoVAoiI2J4eNRgVz45286d32PiVOmG3Wci+f/oX+f9ylub8/chUuoVbsuALt2bGfapPHY2NiwaftuvLy9te/5YtYMftmwngoVffnimzlU9K0EQPCNG4z5eCR379yhW4/3GTthco7j5dYw/njkYE4dP0rb9p0YO3mGKq/YGCZ8PIKLF/7hrc7dGDNxmlF5Xbp4nqH9e1G8uD3fzF3MS7XqAPD7rt+YNW0CNjY2rNu0k9JeT/PKyMigzSsvA7DvyBmsc2thmKCw56WvYTxq+CBOHDtKuzc7MXHqTO15OGb0CC6c/5t3unRj/GQjz8ML5xnYV3Uefj9/CTVrq/LavXM7Myar8tq4dVe28/Dzz6ax5deN+FWtxpffzcWztBcAWzf9wv9mTkWhUPDr9t14eJbWeczcGsajAwdx8vhR2nXoxPgpM7V1NvajEVw8/zdvv9uNcZOMy+3ShfMM6qfK7bu5T3Pbs3M7M6eqctuwZVe2OnvW5UsXGOT/PhnqoM1tGBfmOsutYTx+9FDOnDxG63Yd+Wj8NBQKBXGxMUwdO4rLF//hzbe7MnrcFKPyunLpPB8O6kOx4vZ8/t1CqtesDcAfe3bw5cxJ2NjY8NOG7XiWfprX7zu38dVnkylu78Csr+dSs059AP4+e4rJY0aSnJTE+Gn/o1XbN3Ue05yG8dYve9G2cWXW/X6eoV9uJ1WZjptzcTbO7kGTmmVZuv0sI77eYXK5z9rxzQe0etmXuRtPMGbe7ya9t0AbxvEF2DB2sqyGsYwxFoVa0I3rHD92BFfXkkycompkAZRwdeWLr+egUCj4besWYqKjjSpv1YplZGZmMnDIcG2jGKBDx7fo1uN9lEol69es1L6elJjI9q2bsbKyYvqsz7WNYoBKVaowY9YXAGzb/CvJyclG5xUcdJ1Tx49SwrUkYyZOe5pXCVdmfvEdCoWCXb9tITbGuLzWrVpOZmYm/QYO1TYeAdp26MS73XqiVCrZuH5VtvfcvxdKSkoyZcuVz7NGsaXmFXTjOieOqfIaP3l6tvNw9leqvHZs20KMkXmtUZ+HAwYP0zawANq/+RZdu6vy+nnt07ySk5PZs/M3AKbN+kLbwAJ4p0s3mr/6Gqmpqezdvcvk3IJvXOekus7GTpqerc5mfanKbed2E3JbqcotYFD23Nq9+RZd3suZ27PS0tL4fOZUiqrjMJel1tmt4BucOXkMlxKujB47RZuXSwlXJs/6mqIKBb/v3Gr0NbZxzQoyMzPpEzBE2ygGaN2uI2916YFSqWTzz2uyvefAXlXMPfsEaBvFAHUbNKJ7r36AqmGdV16q6EHbxpWJiHnM8K9+I1WZDkDUo0R6TfmF5JQ0+rSvSykX04eQZDXk3Ya0etmXoNBoJi/Znxehi38haRgXYps3b8bPz0/nz0svvUTjxo3p1asXP//8s7ZnJT/NnTsXPz8/fvnll3w/lsaeXaqba6s32mJnZ5dtWyl3d5o2f4W0NCWHDx00WFZi4hMOH/oTKysrOrzZKcf2tzt3AeDAH/u0r12+fImUlBTcPTypXuOlHO95qVZtnJ2dSU1NJeTWTaPz2rdnJwCvt3oD22fycivlTqOmr5CWlsaxw38aldexw6q82nbImdebb78LwKEDf2R7/dbNIADKVahodNyGWGpee3er8mrVRvd52KSZKq+jh/40WFZi4hOOqPNqp+M87PSO6jw8uP/peRj/6BEdOr3DG+3ezPbHmYbmtYcPw43OSWOvus5attaRWyl3GmtyM7LOjh7RX2ea3P48sC/HNo01K5cRHHSd/gOHmpBFTpZaZ/vVjdIWLXVfYw0bNyctLY2TRw8ZLCspMZETRw9hZWWls3e3fafOABz5M/s1FhX5EIAKvpVzvKeyXzUAIs04F/Xp3kY1FnvLn1dITs3ekx4WncDeU0EoitrQoVkVs4/h5lyc6QNbAfDx97tJSdXfY/9vYFWAP5ZGGsYWoGrVqgQGBmb78ff3p2HDhpw/f56pU6cye7b+8VyF2eWLFwGoWau2zu0vqXs4zv/9l8Gyrl25QnpaGt4+ZXAtWTLH9kqVq2BrZ0dERDhhD+4D4OtbiS+//Z7Rn4zRWWZ6ejrJKapxbekm/HFy9bIqrxo1deeleSjnwnnDed24dpX09DS8vH0o4ZozL99KVbC1teNhRDjhYQ+0r9++GQxA+Qq+RsdtiKXmdfmSKq+XatXSub1GTdXr//x9zmBZ169eVZ+HPrjqyEtzHj7Mch66e3gwZsJkZn7+lc4yr129AoC3T1nDyTzjiia3mnpye0n1+gUTcvPy1p2bb6WcuWUVejeEn5YuwrdSFd7v7W9CFjlZap1dv6LKq9pLuvOqWkN1jV268LfBsoKuXyE9PY3SXrqvsQq+lbG1tSPyYQQRWa4xN3cPQNV7/aw7IaoOArdSHgaPb6wG1VTDOE5dvqdz+5mrqs+8aU3Tz3+NcX1fxcneln2ng9l3OtjscsS/n8xKYQGqVavGiBEjdG67du0a3bt3Z82aNfTu3Zvy5csXbHD57P79UAC8vH10btd8PXkv9K4RZd1Tl6V7bKO1tTUeHp7cvRPCvdBQSnt5U8LVlZat39Bb5umTJ0hJTsbGxoayZcsZjEHjgToWfeMsPT1Ved2/F2pEWaHqsnR/RtbW1rh7eBJ6N4T79+5qPzNNA7K0lzdbf93AmVPHefw4gdJePrRu24EGDRsbnc/TWCw0L3W8Xnpi0RzbmLzuGygr63l4/15ormNxE+LjWbn8R06fPE4J15K019GbaTAezeds4Bozpc70Xa+Gcvvis+koU1MZO3EaRYo+37hGS62zsPv31fHrPoZmvLKmLnItS92I99QTr7W1NaU8PLh39w4P7ofiof7M2nfszLlTx9mw5idq1qlHzdr1ALhy8TzrVy0DoFPn93SWaY4KpUsAcCcsVuf2u+FxAFT0djWr/LIezgx4qwEAM5cZ/vbx30DmMTafNIwtXNWqVWnXrh1bt27l+PHjFtcwjotV3fBcXFx0bndycgLg0aM4I8pS3VSd9ZRlanlpaWnM/+E7ABo1aYqj+r3GeBSXeyyOpuQVp9rH2Vl/Xk/Le6R9TTPk4OvPZ5CUmJhl71Ps2LaJDp06M3bSdJ2zOuhjqXnFGchLe97EGZOXqiynXM5DRwPlXbp4nv/NmEro3TukpKRQ0bcS02d/meu5rY+2zvR8zo6OptRZ7mXlVt72rZs4d/YU73brkW0Mr7kstc4ePVLHouczdlB/vvFZrgm9ZcXlXpa+8l5r3ZaHEWGsWrqAj4b2w8u7DNbW1twLvYO9gwOjxk6hWYuWxiVkhJLOqhl/ouOTdG6PTVA93+HqVMys8gd3boitoggnLt7V9j4LyyVDKf4DXF1VfyU/fvxY+1pycjLz5s2jQ4cO1KxZkwYNGuDv78+hQ7rHnd25c4eJEyfSokULatWqRdu2bfnqq6+Ij4/P9dgpKSn4+/vj5+fH9OnTyetJUFJSVDc8ffME29rZqvczPIelpiw7Wzu9+2jG7KWkGJ725+vPZ3Ht6hWKFCnKsBGjDO6fPRZV+bZ6YtG8nmpEXqmaz8hO/1zKms8vVX3ctDQloXdDAFUP0zdzF7PvyBl2/HGUj8dNplixYuz6bQvLl8w3LiE1y89Lz3moySvVmPMw97Kylpeip7xbN4MJDrqhLSs2JoZTJ44ZPLY58WiuiTzLzS7nORATHcW8OV/h5laKoYGjjQv8OWMprHWWanRehu9hhsrKrTxvn7J4enmTmZnJ/Xt3Cb0bQmZmJg6OTiZN7WeMYraqPr7kFN0zMSSpX7dTmN4XqChqwwcdVH+IzfvlpJkRFjyrAvxnaaRhbOEyMjI4dkx1c61atSoACQkJ9OjRg7lz52JjY0P37t15/fXXuXjxIoMGDWLRokXZyvj7779599132bRpE1WrVqVXr164u7uzdOlS/P39SczW6/ZUamoqI0aM4MSJE3zwwQdMnTo1zyd1t7bOvVcvM0PVEDfmuFZWhi+HTPU4YUPlLZg7h183/gxA4IejqVqtusGyszI0W0JmpiYOw2UZlVdm9s8pNSWVHr39ad/xbRYuW0OjJs0pVqw4Li4l6Ny1B5+qp1Nbv2aFtrfMGP/VvDJMyMvaiJ0MfU7NX32NA8fOsHPfIT4dP5nk5CTmzfmGpYsXGA7g2XgM1ZkJY+eNyS0jI2du3345m4T4eEZ9Oh4HR0ejj5drLBZaZ0ZfY0Y0aKysjchLxz1xy8a1TB03ipjoaCZM/5zf9p9k696jfDxhOvGPHjFr8hi2/rLeYNnGSs/IvcPFWp2HOf0ynVtUp5SLPfcfxrPtyDVzwhOFjDSMLVRSUhLXrl3jo48+4vr169SuXZvmzZsD8PXXX3P16lW6d+/Oli1bmDRpEl999RVbt27F09OTOXPmcP78eUDVsBg/fjxJSUksWLCAxYsXM3bsWFavXk2vXr24fPkymzdvznH8tLQ0Ro8ezaFDh+jXrx+TJk3KlzyLFVN9NaavR1jT22PMynPF1Qtw5NYb/LQ83T2emZmZzPn6S5b/uBiA7u/3pnfffgaP/Sy7YqpYUvXEYiiOrIqZlJfqcypub8+QwNFMnDZb+9V2Vm+064iXdxlSU1I4d+aUwRg0LDWvYpq89PQGKk3Kyz7XsrJu01eeq2tJ7O3tcStViq7dezJx2meAakqx+HjDX6Fni8dAbtpY7PImN+Uz5R07coj9+/bQtHkLWrVpZ3zghmKx0DqzU98T9fUIa+JQGHFPfPoZ5XKNKbOXFxcbw9IF3wMw+bOvaPlGB4oVL46DoxPtqFxi+gAAIABJREFUO3VmwjTVHMVLF3xn1HAOYzxJVn+2enqEbYuqXk9KNX1u37dfVc2ise3wVdLT8392pzwj01KYTRrGFmDLli05pmurU6cOb7/9Nr///jtt27Zl8eLFWFtbk5qayvbt23FycmLixIkUKfL0RlKmTBlGjRpFZmYmGzZsAODChQvcvn2b119/nZYts48JGzJkCAMHDqRChQrZXk9PT+fTTz/ljz/+ICAggHHjxuVb7k7OzgDEx+set6cZp+hSooQJZem/WT8tL+eYu/T0dGZMncSaVT8B0K17Tz4ZO8HgcXXG4pR7LJpfKMaMP9SUlZBLXvHqvJxdDH9OGhUqqmZ1iAgPM/o9FpuX5tzR84teM67UmDgMlZW1PBcj82rTtj1upUqRlJTEjWtXjXqPsfFoPmNjYtHWf265ZamzxMQnfPW/6RQrVoxPxuXtH9eWWmeO2utC9zA3zfViTF6O2utV/5C5BM0166wq7+yp46SkJFOlWg3qNmiUY//GzVvgW9mP5ORkzpw8ajAGY8SqxxbrG0Nc0ln1enSc7m839SliY03LBqppHbcfld7i/wppGFuArNO1DRo0iBo1agBQsWJFduzYwQ8//EAJdcMwJCSExMREatWqpbMXtUED1ZO3V6+qbsRXrqimDKpTJ+fDLu7u7nzyySc0a9Ys2+sLFixg1y7VXJrPNqbzWjn1w4ThYbobMZrXfXzKGFFWhVzLysjI4OHDh+rysk/7k6ZUMmHMx/y2VdV7/oF/f8ZOnGL20JGy5coD+htnmteNmcrpaVm65w3NyMggUp2X9zOfU269sZoeoqx/XBkfi2XmFa4nL83rPmWMOA8NfEYZGRlEqueJ9VaXl5aWRujdO9y9E6K3XM0sCzExMQZjyMpQnYVr68xwbmU116sRufn4lOHalctEhIeTlJTEux3b0KRe9Ww/Gm+3b0mTetX56+xpY9Oy2DorU1YdS0Tu15i+mUF0lRWZS16aOYu9fFTlRT6MAMCnjP5ZeMqUq5Bt3+d1I1S1WEkZD2ed233cVa/femD88CiAprXK4uxgR0x8kklLP/8bSIex+aRhbAE007WNGDGCjz/+mM2bNzNo0CBu3bpFYGBgtptqQkICAI56xul5eKjmltSMG9Y8+a9vf10iIiJo06YNABMnTjRpxTdTaRbV0MxJ+qxLFy8AT+ckzU2lSpVRKBTcvRPCY/XnlFXQjeukJCdTyt0dD8/sy89+Nn0K+/eplgcdGvghH370qUl5PKtqddUfN1cu687ryiVVXtV0LCryrIrqvELvhvD4cc68bgZdJyUlGbdS7tpldbdu2sjrTeoQOKiv3nJvBasXyihfQe8+z7LUvDTxauJ/1mX1eVhdPYdsbnwNnIfBmvOwlDse6ry2/LqRrm+154tZ+pcv1kyV5+ZWymAMWVWtrs7tsu7cNDkblZtvljrTlVuQKjdNndk7OFCrTj29PxrVatSkVp16Jj3UZal1VqWq6hq7fuWSzu3X1PMc+1U3nFd530oUVSi4F3pH5zV2K/gGKSnJlHRzp5S7Kq/i9qphJbH/Z+/O42Le/j+Av0abSmW7lyhRaLlkLbLdJBcJJVmyL2Ura0Ku61rK+uVasm8lVJaoLgrhVoqy/miRpbRZ2tNipmZ+f3TNlZrWqU8z837eh8fDfD5nxuvcWXp35nzOyUgX+LiZ/577Nh2qrh7Hlq6h/G094x8Z6pUW7VE1XFHi2/3C/++9aE2jIHVChbGYWrFiBYyNjfH27VssXboUJSWlW2Q2+/cHx8ePFf+m/u0rs28jzIr/fsjlVfBhDwD5+fnljk2aNAkHDhyAlZUVEhISsHfv3rp1phLGQ0t3Igq6ca3cKODnT58QHhYCOTk5DDUxrfKxmsrLo5/RQHC5XAT4XSl33u/f0eARI8vuAOV9/iy//bKVTphrt6BWffneYOPSft0Oul6uX+mfP+FBeChk5eQwZGg1+tVUHgb9BoDL5eJ6wNVy5//28wUAmI4w4x/roq0DDoeDuJiXeJ/wrtx9IiPuIzHhLVRUmqNnbwOJ79ev/74Ob94o36/Pnz4h4n4o5OTkYFzD1+Hf/uVfh/5XS1+Hw0f9168+fUuzPnkUVeG6u7dvBiIzIwPKysroJmAzHEF+/fc5uxlYQd8+l/ZNVk4Ov1azb4b9S/t2LaB83wK+9W1kad+0dfRw5KSnwD/fbNu1F0dOekJbp/oXuYrrczbw16EAgDs3b5Sby5/++RMiI8IgKyuHQdVYLq1pU3n0NTQCl8vFzWt+5c7f+Pc5NPlu7rf+v1tA/9+zx/zC/nupyUmI/fcXY/3vtouuC/9/pzlYm3QrN89YtZUShht2RuFXDvz+qdk0oh5dSov9x3GpVbRsfFishvsjbqgwFlMsFgsuLi5o0aIFHj58iBMnShdV19TUhLy8PF69elXhvLEHD0ovOOratXTrzG8rWTx/Xn5UJTs7G3379sXcuXPLHO/evXQkYvXq1WjdujXc3d0rvL8w6Oj9AsP+Rvj86RPWr3Xir0ubnZWF1Y7LwGazYT7WAi1all3YPTnpPRLeveWvXfzNzNmlfXHb9xceRoTzj18L8MMFr3OQlZXFJJup/OPZWVk48NduAKVbRtfmQruKaOvooa+hEdI/f8Lm9atRWPhtBD8L61cvB5vNhpm5BVq0KNuvlOT3SEx4W25FBZuZcwAAR93+QtTD/5YcCrzmj8sXzkNWVhYTJv3Xr1+66aObfk9wuVz84bwSKcn/bZDy9HEUNq5fDQCYZbuwWhc2inu/dHT1YNjPCJ8/f8KGdd/1KysLzqtK+zW6Bq/DabNK+3Vo/1+IfPDf6/D633646F3ar4mT/+uXZucuGDBoCEpKSuDstKJMofU4KhI7XDcBAObYLYKsrGy1+wUA2rp6MOhX+pxt/L1s39Y5/du3MeWfM4F9+/c5O3ygbN9u/O2HSz6lfbP+7jmrL+L6nHXR1kNvg/7ISP+ErRvX8vuVk52FzescwWGz8dvosWj+w/OVmpyE9wnv+GsXfzNxWuln2onD+/A48r/32K0bAfC75AUZWVlYWNvwj3fS6gKjQb+iuLgYfzgtQWLCW/65pMR32Oi8Amz2VxgNNq5wy+jaePoqDbcj36DdT8o49ft4KDQt3fyllYoCzm6yRlM5aZy5/hTpOWXnGHdq1wJdO7Tmr4P8o25apd+g/t9r4Uz5IKKBxRP2wrKkwVy+fBlr166FpaUltm3bVmEbf39/ODo6Qk5ODv7+/tDQ0MAff/wBb29vjB8/Hps3b+bPpUxOTsasWbOQnJyMc+fOoXfv3igpKcGIESOQlpaGo0ePlplPvHXrVpw+fRpr167FrFmzsH//fhw4cABbtmyBtbU1AODatWtYvnw5unTpgsuXL9f4h/I3eV8Ff42VkpyMuTNtkP75M5SUlKGmro53b9+iqKgQXbV1cML9bLmv7MaMHIa01FTYLliM+Yvsy5w7sHc3Tp84BgDQ1NICm83h75y3yXU7zMzH8tueOn6Uv4mHto4u/4rwiqxas67csm1FbMH9Sk1JxsK505CR/hnNlJTRXk0die9K+9W5qzYOnfDkXzX+zYQxw/EhLRWzbRdh7vzFZc4dPrAHnqePAwA6amqBw2bzfxiv37QNI8zK7rCVlpoCe7uZ+PghDVJS0uig0RGcYg6S35fOtRs3fiJWOW8QmF9c+yUjXfEQSWpKMmxnTeW/DturqyPh39dhl67aOOZ+tly/LEaZIi0tFfPmL4LtwrKvQ7d9u+FxsrRfnTS1wOGwkZxU2q8/XbZh1OixZdpnZmZg4byZSHj7FlLS0tDQ6AgOh4Okf/tlZT0ZTuv+ENivylZdS01JxvzZU5Ge/m/f1NSR8O6/vh05Vb5vlqNN8SEtFXPtFmHegrJ9O7h/N86c+q9v7O+esw2bt2HkD30T5Ns846vXg/nTZX5U2eplovyc5RUWC+xXWmoyls2f+e97TAnt2qvjfcJbFBUVQauLNv464l6uX1MtR+Ljh1RMn7sAM+ctKnPu+MG98DpTOrii0an0PfZt57w1G1xhOtK8TPucnGw4OdjhTXwsWCwWOnTURDGHg9SUJPB4PGh10cGO/UcFbvTS1WKrwL4JoqHaHHfc5kK1tRKy8grxNiULOhqtoSgvi2fxH2Cy+AQKisquShHrvQwaqs2x5dRduJy6W+4xU/9ejRZK8hgw7wievKr+xbiCFP7zZ50fo7oy80sa7N9qqVj9zZBEAe18J+bGjBmDgIAA3L17F7///js8PDywatUqPHnyBJcvX8aLFy/Qr18/5ObmIjg4GHl5eVi6dCl69y6dvyclJYVt27bB1tYW8+bNw7Bhw6Curo5nz57h0aNHMDQ0xLRp0wT++2ZmZrh69Sru3r2LgwcPYtmymm10UR3t1dTg6XURRw4eQGjIPcS/eoVWrVvDctgE2C20r/E8NvulK9C5iza8znrgdXzpfNPeffpi5hxbDBw8pEzbZ08f8/8eV8WV499vsFId7dqr4YTnBZw4cgDhof/gTXwcWrZqjTGWVphjt7jcD7aqLLBfDq3OXXHBy5M/j7Zn776YOnMejAYOLtdetV17nDp7EZ7uJxByNxjJSYmQayqP3n0NYTlhMoaajqjRvy8J/XI/dxFHDx3A/ZB7eP0qDq1at8Y4kwmwXVDzfi1eUvo69D53Bm/+fR326tMXM2bPw4BBQ8q1b9myFU6e8Yan+0ncDrqBpPeJkJNrCoN+/WE9yaZaUx0q69upsxdx/PABhIXew+v40r6NHToB82rRt0UOpX3zOXcGb757zmbMngejgeX7Vl/E9TlTbaeGg6e84H78IB6EheDt61do0ao1zMYOw4x5C2vcr3mLlkKzcxdc9jmLhH93jtTv2QeTZ8yBoVH595iKSnPsPeoOX59zuHvrBv+XTs3OXWFsOhKWE23QtGntdqETJDEtGwNsj+D32UMxyqgLumu1wcfMLzgV8BhbTt0tVxRXpUkTFlQUS5fWS8uoeCohEU80YizCqjNiDAAfPnyAmZkZ8vPzsXnzZkycOBH5+fk4ceIErl+/jqSkJCgqKkJfXx+zZs0qt8oEALx58wYHDx5EeHg4cnJy0KZNG4wePRoLFy7kr/9b0YgxAKSmpmL06NFgs9m4ePEidHV1a9zXykaMRVllI8akcRI0YizqarBPh0ipYr8LkVXZiLGoq82IsShoyBHjrIKGGzFuoSBeI8ZUGBORQIUxaSyoMBYtVBiLHiqM644K49oT048MQgghhBBCaoYKY0IIIYQQQkCFMSGEEEIIIQBoVQpCCCGEELEijhtvNBQaMSaEEEIIIQQ0YkwIIYQQIlZYoCHj2qIRY0IIIYQQQkAjxoQQQgghYoXmGNcejRgTQgghhBACGjEmhBBCCBErNGBcezRiTAghhBBCCGjEmBBCCCFEvNCQca3RiDEhhBBCCCGgEWNCCCGEELFC6xjXHo0YE0IIIYQQAhoxJoQQQggRK7SOce3RiDEhhBBCCCGgEWNCCCGEELEiagPG169fx+nTp/H69WtISUmhV69eWLx4MfT19at1fy6XCx8fH3h5eSExMRFycnLo378/li5dik6dOtUoC40YE0IIIYQQRhw6dAjLli1Deno6Jk6ciOHDh+PBgweYMmUKQkJCqvUYf/zxBzZs2ICSkhLY2Nhg4MCBuHnzJqysrBAbG1ujPCwej8erTUcIaUh5X7lMR6gXRWzx7Jc4k5EWtbGY6uGK6UuxiZgO/+QVFjMdod50tdjKdIR6UfjPnw32bxVwGq60U5Cp/Wfi69evMWbMGHTu3Bne3t5QUFAAAMTExGDKlClQUVFBUFAQ5OTkBD7GvXv3YGdnh0GDBuHIkSOQli6dDBESEgJbW1vo6enh8uXL1c4kph8ZhBBCCCGkMTt9+jS4XC4WLVrEL4oBQFdXFxMmTMCHDx9w+/btKh8DAJYuXcovigFg8ODBMDY2xsuXL/Hs2bNqZ6LCmBBCCCFEjLAa8L+6CA8PBwAMHDiw3LkBAwYAAO7fvy/w/hwOB1FRUVBRUUH37t3Lnf/2uJU9xo+oMCaEEEIIIQ2Kw+EgJSUFLVu2hLKycrnzHTp0AAC8efNG4GOkpqaCzWajQ4cOYFWwRl11HuNHtCoFIYQQQogYEYV1jLOzs8Hj8aCiolLh+W/Fcl5ensDHyMrKAoA6PcaPqDAmhBBCCCG1MmzYsErPC5ojXFxcegGpjIxMhedlZWUBAF+/fhX42MJ4jB9RYUxEgpKceM76Edd+EULqV3N5KaYj1JuGXL1BXDUVgeru20oTHA6nwvNsNhsAylyUVx+P8SMR+F9HCCGEEEIao6pWjRBESUkJUlJSAqc55ObmAkCF84+/ad68OQDBUyWq8xg/ouEqQgghhBDSoGRkZNChQwdkZGQgPz+/3Pn3798DADp37izwMdq3bw95eXl+29o8xo+oMCaEEEIIIQ3O0NAQPB6Pv2zb98LCwgAABgYGAu/fpEkT9OnTB1lZWRXucFedxyj3mNVuSQghhBBCiJBYW1uDxWJh7969ZaZDxMbG4tKlS2jbti1MTU0rfYyJEycCALZv386fUwyU7nx39+5d6Ovro0ePHtXORFtCE0IIIYQQRmzfvh0nT56EqqoqRo4ciS9fviAgIADFxcU4cuQIf5OO3NxcuLu7AwAcHBzKPMaSJUsQGBgITU1NmJiY4OPHj7h+/Trk5eXh6ekJHR2dauehwpgQQgghhDDmwoULOHfuHN68eQNFRUV0794d9vb20NfX57dJTk7mLw0XFxdX5v7FxcU4ffo0Ll++jKSkJKioqKBv375wcHCAlpZWjbJQYUwIIYQQQghojjEhhBBCCCEAqDAmhBBCCCEEABXGhBBCCCGEAKDCmBBCCCGEEABUGBNCCCGEEAKACmNCCCGEEEIAUGFMCCGEEEIIACqMCSGEEEIIAQBIMx2AkMaAy+WioKAAzZo14x979OgRevbsCSkpKQaTkdqKjY2t0TagjcmTJ08QHR2N3NxctGzZEj169BDZvhDRxuFwkJCQwH8tamhooEkT8R5TE+XPDlJ3tPMdkXjXrl2Dq6sr5s6di9mzZwMoLZT19fWhoqKCnTt3YsCAAQynrBqXy631fUXpB93mzZuxfv16geeLi4vh5uaGY8eO4cWLFw2YrO6ioqKwfv16JCQkAAB4PB5YLBYAoHv37nB1dUXnzp0ZTFg94eHhtb6vkZGREJMIV1JSUq3vq66uLsQk9S8zMxN//fUX/v77bxQUFPCPN2/eHFZWVrC3t0fTpk0ZTFhz4vzZQYSHRoyJRLt//z5WrlwJRUVFqKio8I8XFxdjypQp8PPzg62tLdzd3dG3b18Gk1btl19+qdX9WCwWoqOjhZym/pw9exbS0tJYu3ZtuXP/93//B2dnZ8THx0NRUZGBdLUXExMDW1tbfP36FcOHD0fv3r2hqKiI3NxcREVF4d69e5g5cyZ8fHzQvn17puNWavbs2fyCvqZiYmKEnEZ4hg8fXqt+idp7LDMzE5MnT8b79+/RunVrGBoaolmzZsjNzcXz589x/PhxPHjwAGfOnBGp4lhcPzuIcFFhTCTa0aNHoaysjIsXL5YZ0ZGVlcW6deswc+ZMWFpa4tChQzhx4gSDSaumqqrKdIQG0b9/f3h4eEBKSgpOTk4AADabjb1798Ld3R3FxcUwNjbGhg0bGE5aM/v37weHw8GRI0cwePDgMufmzp2L27dvw8HBAW5ubnB1dWUoZfVYWFjUujBuzAwMDJiO0CD279+P9+/fY/78+ViyZEmZ6WTFxcXYvXs3Tp48iWPHjsHBwYHBpDUjrp8dRLhoKgWRaEZGRjAzM6v067U//vgDAQEBePz4cQMmI4Kw2WzY29sjJCQE8+bNw9ChQ+Hs7IzExES0atUKzs7OMDMzYzpmjfXv3x/9+/fHX3/9JbDN4sWL8ezZM4SGhjZgMiJpjI2NoaamBk9PT4FtJk+ejMzMTAQFBTVgsroR188OIlyiM7GQkHrAZrNRXFxcaRtZWdk6zd8lwiUrKws3NzeYmJjg2LFjmDp1KhISEjB+/Hhcu3ZNZH+wcTicKqdIqKmpIT8/v4ESNTwap2kcsrKy0LNnz0rb9OrVCx8/fmygRMIhrp8dRLhoKgWRaJ07d0ZISAgKCgqgoKBQ7nxRURFCQkKgqanJQDrhePPmDTIzM1FSUlKm8OBwOMjOzsbdu3exe/duBhPWnIyMDPbt2wdHR0dcv34dv/32G1xcXJiOVSeGhoa4desWli5dCllZ2XLni4uLcf/+/UY/112Qz58/4+bNm8jMzASXy+W/Fnk8HoqLi5GdnY2QkBDcu3eP4aQ18/XrV0RERCArK6vMe+z7ft27dw9eXl4MJ62+rl274tmzZ5W2iYuLg5aWVgMlEh5x/OwgwkVTKYhE8/HxwR9//IGBAwdi9erV6Nq1K/9cfHw8du7ciZCQEKxbtw7Tpk1jMGnNZWdnY968eXj58mWVbRvzBU8XL14UeI7L5cLNzQ2fPn3CpEmT0K1btzLnJ0yYUN/xhCY5ORnTpk2Dqqoq1qxZgx49evDPffz4Edu2bUNYWBg8PT3LrUzR2FcVefXqFWxsbJCfn19mpY0f/y4vL48nT54wGbVGUlNTMW3aNKSlpVXZtjG/x34UHh4OW1tbTJs2DUuWLCk3aODu7o7t27fDzc0NQ4cOZShl1STls4MIFxXGROItXboUgYGBYLFYkJeXh6KiIvLz81FYWAgejwdTU1Ps379f5C4mcnFxwZkzZ6CmpoYePXogODgYGhoa0NTURHx8POLj49G6dWvs27cPvXv3ZjquQDo6OpX+v//+I+zHgkuUihEzMzPk5eXh8+fPYLFYaNq0Kdq0aYOioqJKv7IWhRUPli9fjuvXr8PMzAz9+/fH/v37oaenh6FDhyI+Ph4XL16EkpISbty4UWYt8cbO2dkZly9fRq9evWBoaAgvLy907doVPXv2RHx8PO7du4dWrVrBx8cH7dq1Yzputf355594+vQp4uLioKKiAn19fbRt2xZFRUV49uwZ3r9/j2bNmpUZSABKX4uVzUtuaJLy2UGEi6ZSEIm3d+9eBAQE4MqVK4iNjUVWVhYUFRXRrVs3WFpawtLSkumItXLv3j2oqqri2rVrkJWVxYIFC9CkSRP+tImjR49iz5491RrtYtLixYtF7peS2igqKoKMjEyZAorNZqNJkyYiv+JIZGQkunfvzn/tRUZG4sOHD5g8eTIAYMSIEZg9ezbOnj2L+fPnMxm1RsLDw6GlpYXz588DABISEvDlyxesXLkSABAQEABHR0fcvXsXNjY2TEatke+nfWRnZ+Off/4p1yYvLw+PHj0qc6yxvU8l5bODCBcVxoQAMDc3h7m5OdMxhOrDhw+wsrLiz1fV09ODt7c3/7ydnR1u3LgBHx8fjB49mqmYVRKl5aDqIjg4mOkI9SY7O7vMa6xLly64ffs2/7ahoSEGDBiAmzdvilRhnJ6ejkmTJvFva2trw93dnX/b3NwcXl5e8Pf3F6nC+PvnRpRJymcHES4qjAkRU1JSUlBSUuLf7tChAzIzM5GZmYmWLVsCKC1Ibty4wVREIiHk5eXLzINWU1NDYWEhUlNT+SPkOjo6lc4JbYxkZGQgLy/Pv62uro7c3Fx8+vQJP//8MwBAX18ffn5+TEWslca+gUxdFBUV4dKlS9DU1Cyzy6KtrS2GDBmCqVOnNvo5+6R+UWFMJMrUqVNhZWWF8ePH829XR2ObO1cd7dq1428tDJQWxgDw+vVrGBoa8o9nZ2c3dLQa+bYQf02xWCxs375dyGnq340bN+Dt7Y3o6GgUFhaiefPm6Nq1K8aPHy+yy0lpaWnh+fPn/NudOnUCj8dDbGwsvzDOycnB169fmYpYKxoaGmXmompoaIDH4yE+Pp5fGLPZbJFdYu/jx4+4fPkyYmJiUFBQwH8tjh49WiSL57y8PMyaNQvR0dGwtbXlF8YFBQUIDQ1FaGgobt26hSNHjojUjn5EuKgwJhLl0aNHZUYJfpwjJ4gozlMbPHgwPD094efnh7Fjx0JbWxtycnLw9vaGoaEh8vPzcefOHbRp04bpqJWq7WibKBbGGzZsgI+PD3g8HqSkpNCyZUvk5eUhNDQUYWFhiIiIwKZNm5iOWWMjRozA9u3b8fvvv8PBwQFdunRB69atcfDgQejo6CA9PR03btyAhoYG01FrxMTEBIcOHcKhQ4cwY8YM6OjoQElJCSdPnoSBgQGysrIQGBgokkWkn58f1q9fDzabXW59aTc3N2zcuBEWFhYMpaudI0eO4OXLl5g6dSqmT5/OP66goICIiAgcPHgQ7u7uOHToEJYvX85gUsIkWpWCSJSUlBQoKyvzpxikpKRU+76i9sPt8+fPsLS0REZGBjZu3IiJEydiw4YN8Pb2Rvv27VFUVITMzEzY2dk16h8CDx8+rPV9vx8Zb+z8/Pzg5OQEHR0drFu3Dr1794aUlBR4PB6ePXsGFxcXvHjxAnv27MHIkSOZjlsjbDYb8+bNQ2RkJFxdXWFpaYmTJ09ix44dZVYDcHV15X+bIwq+fPmCSZMm4e3bt9i0aROsra2xe/duHD16FE2bNkVxcTFKSkqwatUqzJkzh+m41fbs2TPY2NhATk4Oc+bMgYGBAdq0aYPc3FxERETgxIkTyM/Px/nz59G9e3em41bbyJEj0aZNmzLzwH9kY2ODjx8/is08a1JzVBgTIsY+fvyIY8eOwdzcHD179sSXL1/g5OSEO3fuoEmTJhg1ahQ2b95cZp4kYcaUKVOQlJQEf39/tGjRotz5rKwsjBkzBpqamvDw8GAgYd3weDzcvHkT2tra/JHh06dP4+rVq5CTk4OVlRWsra0ZTllzhYWF8PLywoABA6CtrQ0Oh4MdO3bw+zV+/HgsXbpUpOatLlq0CKGhofD29oaurm6587GxsZiQVsAMAAAgAElEQVQ4cSJMTU1FanOgHj16YNq0aVi1apXANjt27ICHhwdevHjRgMlIY0KFMSEASkpKkJWVBQ6HI3BbWlFah7QqeXl5kJWVhZycHNNRaq2oqAhBQUFl5j9qa2tj6NChIlno9+7dG2ZmZtiyZYvANr///juCgoLqNIreWLHZbCQlJYnkbmripn///jAyMsKePXsEtlm+fDkiIyMRGhragMnqxtjYGDo6Ojh8+LDANg4ODnjy5IlI9YsIF80xJhKtpKQEe/fuhbe3N3JzcwW2E4VNFH40Y8YMjB8/vsJ5gN+mknh4eODs2bMIDAxs6Hh1Eh4eDkdHR2RmZpZbpL9Fixb43//+V2YuuSgoKSmpcCvo78nIyIDNZjdQIuHR1dWFvb09Fi9eLLDNgQMH4OXlJZZFv6j58uUL2rZtW2mbNm3aICcnp4ESCcfAgQPh6+uLe/fu4ddffy13/v79+7h9+7bIXuRKhIMKYyLRjhw5gqNHj0JaWhpdu3aFsrIy05Fqjcfj8YtEHo+Hhw8fwtDQEFwut8L2xcXFiIqKavQbfPzozZs3WLRoEb5+/QoLCwv+/MecnBxERETA19cXixYtgq+vLzp27Mh03GrT0tJCaGgovn79WuFIflFREUJDQ9GpUycG0tXMq1evkJGRwb/N4/GQlJSE8PDwCtsXFxfj/v374HA4DRVRaEJDQ+Hp6YnExESB3zixWCzcunWLgXS1o6qqWuXW3E+fPq2yeG5s5s+fjxs3bmDx4sUwMTFBjx49oKSkhLy8PDx79gzBwcFo2rQpFi1axHRUwiAqjIlEu3LlClq3bo3z589DXV2d6Th1cvz48XLz/dzc3ODm5lbp/bS1teszltAdOnQIX79+xdGjRzFo0KAy58zMzDBy5EjMmzcPx48fr3RaQmNjYWEBV1dXrFixAhs3bkTr1q3555KSkrB582YkJydj9erVDKasnsTERDg4OPAvrGOxWLh69SquXr0q8D48Hq/CUbzG7Nq1a1i5cqXA6VeiytTUFKdPn8aRI0fKbbjC5XLh5uaGZ8+eYebMmQwlrJ0OHTrg+PHjWLt2LYKCghAUFAQWi8V//tTV1bFt2zZoamoynJQwieYYE4nWvXt3TJkyBc7OzkxHqTMOh4OpU6ciPT0dAJCWloZmzZqV2eTjGxaLBWlpabRr1w6Ojo745ZdfGjpurQ0aNAj6+vo4ePCgwDaLFi1CTEwM7ty504DJ6obL5cLW1hZhYWGQkpKChoYGlJSU8PHjR3z69AlcLhdGRkY4fvw4pKSkmI5bpV27dvFHjX19faGjo1PhhVxA6RQRVVVV2NjYQEVFpSFj1smECRMQFxeHzZs3w8TERKS/cfpeTk4OLCws8OHDB2hqasLAwID/Wnz69CmSkpKgqqqKS5cuVXihqCh4/vw5oqOjkZ2dDUVFRejo6KBPnz4idZEkqR80Ykwk2k8//SRymwoIIiMjAx8fH/5tHR0dzJw5E/b29gymEr7s7Owq17vV0NBASEhIAyUSjiZNmuDw4cM4deoULl26hLdv3/LPaWhowMrKCnPmzBGJohgAHB0d+X/39fWFqamp2L0W4+PjYW5uLnLr+VZFRUUF586dw/r16xEaGoo3b96UOT9w4EBs3rxZZItioHRHQn19faZjkEaICmMi0czMzODr6wtHR8cKR1ZFmYeHh8itvVwdrVu3RlxcXKVtYmNj0apVqwZKJDwyMjKws7ODnZ0dCgoKkJeXh2bNmkFRUZHpaHUSGxvLdIR6IS8vL1Ij3DWhqqqK48eP49OnT4iOjua/FvX09Br9pkBVef78OXx8fMrsLqmtrQ0LCwv07NmT6XiEYVQYE4k2Y8YMPHjwANbW1pgyZQo6duwocGUAUVvlQJQ2t6iJIUOG4MKFC/D398eYMWPKnb906RIiIiIwYcIEBtIJj4KCAhQUFJiOIVQZGRlITk6udFlEAwODBk5VewMHDkRYWBi4XK7IfwWfkZGB/fv3486dO8jKykLbtm0xatQozJ8/H8bGxkzHE5qjR4/ir7/+KndR8pMnT+Dj44OlS5eWm1dNJAvNMSYSTUdHh3/xRVXbPsfExDRQKuHx9vYuc8V8RURtKbq0tDSMGzcOeXl5GDJkCPr27cuf/xgVFYWoqCgoKyvj8uXLjXrE/MCBA7W6H4vFqnTZs8aooKAA69evR2BgIEpKSiptK0rvs9TUVEyaNAmGhoaYN28eOnbsKHBt8MZcOGdkZMDa2hppaWnllj/s0qULzp8/L/LfWgDAP//8Azs7O7Rt2xbLli1D3759y+zot2fPHqSkpODkyZMiNxBChIcKYyLR1qxZU2VB/M3WrVvrOY1wnT17Flu2bAGPx4OSklKlU0WCg4MbMFndxcTEYNWqVXj9+jUAlLmyXEtLCzt37oSenh6TEav0/S9l3/t+i+Qfj3/7BU6UikcA2L59O06dOgUVFRX06dMHysrKAt93ovQ+s7S0RHZ2Nj58+FBpu8b+y+fWrVvh7u6OcePGYcGCBWjXrh3evXuHv/76C/fu3cOSJUuwcOFCpmPW2ezZs/HixQv4+vpCTU2t3Pnk5GRYWlqiT58+lW4CQsQbFcaEiKkxY8YgLS0Nhw8fRt++fZmOI3Q8Hg9Pnz4tN/+xV69e1f5lh0mCRowfPHiAqKioSkeFRe0itqFDh0JKSgqXL18Wm5UbAMDExKTabRvzL59mZmZQUVHB+fPnyxwvKSmBmZkZlJWVceHCBYbSCY+BgQFMTEywfft2gW1Wr16Nf/75R+Ca20T80RxjQv7F4XDw7t07/sUY7dq1g4yMDNOxai0xMRHjx48X+aLY0tISkydPxqRJk8ocZ7FY6NWrF3r16sVQsrqprLiNiooSueK3Munp6Zg+fbpYFcVA4y52ayItLQ1Dhw4td1xKSgoDBw5EQEAAA6mE7+vXr1W+BpWVlZGfn99AiUhjRIUxkXgFBQXYtWsXfH19UVRUxD+uqKgIc3NzrFq1SiTn1ykrK0NaWvTf4jExMfj8+XO5476+vvD19YWHhwcDqUhNtGvXDtnZ2UzHIAJ8/foV8vLyFZ5r0aKF2BSK6urqePDggcCLJUtKShARESHymz2Rumm8VwMQ0gCKioowY8YMnDt3DjIyMujbty/MzMwwaNAgNGnSBF5eXpg5c6ZIblVrYmKCO3fuiM06zT9KSUlBZGQk0zFINVhZWSEwMFDkth+vrhs3bmD27Nno168f9PX1MWTIEMybNw/Xrl1jOlq1CNo2Hij9Zqay86Jk1KhRePXqFTZt2gQ2m13m3JcvX/DHH3/g9evXGDVqFEMJSWMg+sNJhNTByZMn8eLFC1haWsLZ2bnMBWpsNhtbtmzBhQsX4OHhgblz5zKYtOZWrFiBJ0+eYN68eZg5c2alV8zTCAmpTwMGDMDNmzcxfvx4jBkzBhoaGgJfi6K2zN6GDRvg4+MDHo8HKSkptGzZEnl5eQgNDUVYWBgiIiKwadMmpmMSALa2trh16xa8vLxw/fp16Ovr81e0efXqFfLy8qCtrS1yn/VEuKgwJhLt2rVr6NKlC1xcXMp9tSYrK4sNGzbgyZMn8Pf3F7kPy99++w0cDgfx8fGIiooS2K6xXzFPRN+ECRP4q2p4eHhUeHHktxU3RKkw9vPzg7e3N3R0dLBu3Tr07t0bUlJS4PF4ePbsGVxcXHDhwgUMGDAAI0eOZDquxJOTk4Onpyd27twJPz+/MrtjysvLY+LEiXBychI4rYRIBiqMiUR7//49Jk2aJHCNUSkpKfTv3x8XL15s4GR1p62tzXQEQgAAixcvFomVQmrq/PnzaN26NU6dOlVme2QWi4WePXvi6NGjGDNmDM6dO9foC+Pbt28jJSWl3PFvuxauXbu23DkWiwVXV9d6zyZMzZo1w8aNG/H7778jISGBv6KNpqYm/5qMCxcuwNramuGkhClUGBOJJisri9zc3Erb5ObmQkpKqoESCc+ZM2eYjkAIAMDBwYHpCPUiLi4OZmZmZYri77Vo0QLGxsYICgpq4GQ1FxMTU+n62L6+vuWOiUph/P79e9y/fx95eXnQ1dXFoEGDICMjgy5dupRpl5SUhHXr1iEyMpIKYwlGhTGRaN27d8edO3eQlpYGVVXVcudTUlIQHByMbt26MZBO+AoKCsRum2FRNWPGjAqPfxu1E3SexWLB3d293nLVt4KCAsTFxSEnJwfGxsbIzc0V2WXcSkpKBG4h/42MjEy5C70aG1HaVKUmeDwetm7dCk9PzzIb5vTo0QNHjhyBiooKv92JEydw4MABFBUVoVmzZkxFJo0AbfBBJNrdu3exYMECaGhoYPny5TAwMOBfjBEZGYkDBw4gLS0Nbm5uNVrMvzG5cOECLl68iOjoaJSUlCA6Ohpnz55FbGwsli9fjpYtWzIdsVI6Ojpo3759ue2dU1JSkJqaCgMDgwrv19gLSB0dnVrdTxR3vgOA7OxsuLi44Pr16ygpKeHPbT98+DCuXLmCHTt2QF9fn+mYNTJ+/Hh8+fIF/v7+FV5MWFRUhDFjxqBZs2YVjriS+uXt7Y0NGzagadOmGDlyJFq2bInQ0FC8evUKo0aNwp49e5CZmYlly5YhMjISPB4PxsbG2LhxI9q0acN0fMIQGjEmEs3Y2Bj29vY4cOAAli9fXu48j8fD4sWLRbIo5vF4WLZsGYKCgsDj8dC0aVMUFxcDABISEnDhwgU8efIE586da/QjdikpKRXOfwSAhw8fVni8sc9plaT1l3NzczFlyhS8e/cOHTt2hJSUFN6+fQugdKmwhIQEzJkzBxcuXECnTp0YTlt9FhYWcHV1xYoVK7Bx40a0bt2afy4pKQmbN29GcnIyVq9ezWBKyeXv7w8ZGRl4e3vzr7lYtWoVli9fjqCgILx79w729vZ48+YNWrRogXXr1sHc3Jzh1IRpNGJMCIDnz5/jwoULiI6OxpcvX6CoqIhffvkFVlZW6NmzJ9PxasXT0xNbtmyBubk5nJyc4O3tjYMHDyImJgb5+fnYtWsXzp8/j4ULF2Lp0qVMxxVIUOFbHYaGhkJMQmpr+/btOHXqFDZu3IhJkyZh//79/NciULo6jKOjI8aNGydSX+tzuVzY2toiLCwMUlJS0NDQ4H/j9OnTJ3C5XBgZGeH48eMieZ2CqDMyMoKhoSH27t1b5nhsbCwsLCygpaWFN2/ewNjYGC4uLmjVqhVDSUljQiPGRKKdPXsWvXr1gr6+vsh9jVuVixcvQltbG7t27QJQdgRVUVERGzZswIsXLxAUFNSoC2NJLm4fPnyIhw8fivz20Ddv3sTgwYP523r/OJpvZmYGf39/kduwpUmTJjh8+DBOnTqFS5cu8UfBAUBDQwNWVlaYM2cOFcUMycvLg4aGRrnjHTt2BAC8ffsWdnZ2WLFiRQMnI40Z7XxHJNq+fftw+PBhpmPUi3fv3mHQoEGVtjEwMEBqamoDJSI19fDhQ7i5uTEdo84+fvwIXV3dSttoaWnh06dPDZRIeGRkZGBnZ4fAwEA8fvwY9+7dw6NHjxAYGAg7Ozux2JZdVBUXF1d4cWTTpk0BAHp6elQUk3LoHUskGpvNhpqaGtMx6kV1lqLLysqCjIxMAyUikkpFRQXJycmVtklMTGz0c92roqCgQKu+iJCqBg6IZKLCmEg0CwsL+Pv7w9raWqQu+qmOX375BcHBwVi1alWFBUd6erpYLUVHGq9+/fohKCgIsbGxFa7G8fz5cwQHBzf6TTCmTp0KKysrjB8/nn+7OlgsFjw9PeszGqkFGhQgFaHCmEg0VVVV8Hg8mJubo2vXrlBXV+d/zfY9FouF7du3M5Cw9mbPno358+djxowZWLFiBXJycgCUjhI/e/YMO3fuRG5uLqZPn85wUiLuFi1ahODgYNjY2MDGxoY/FzcwMBBPnz7FuXPnIC0tjfnz5zOctHKPHj2CkZFRmdvV0dhXSCGE/IdWpSASrbpryYrq2rHHjh3Dnj17UNHbnMfjYdGiRViyZAkDyUh17N+/H25ubvxteUVZREQEHB0dkZ6ezj/GYrHA4/GgoqKCHTt24Ndff2UwYdVSUlKgrKwMJSUl/u3q+nEdblL/dHR0oKurW+HnvK+vr8BzorKjH6kfVBgTifbgwYNqj+aI6uoIMTEx8PHxwYsXL5CbmwtFRUXo6upiwoQJ6NWrF9PxSCXy8vKQm5srNkUVm83G7du3y70WTU1NoaioyHS8GktNTYWysnKlO6V9+vQJ8fHxGDhwYAMmI4DkbaJDhIMKY0KqwGazkZSUBC0tLaajEAnx8eNHxMTEIDc3Fy1btkS3bt3QvHlzpmORH+jq6sLe3h6LFy8W2Gb37t04e/ZstaddEOGpy26DlpaWQkxCRAnNMSYSrTo/2A4cOAAvL686bTRBSHW8ffsWLi4uCA8PLzP9RUpKCsOHD4ezszN++uknBhPWTXp6OlJSUsBmswW2EbTFd2Pw4MEDJCUl8W/zeDy8fPkSFy9erLB9cXExgoKCGioe+QEVt6Q2qDAmEuXVq1fIyMjg3+bxeEhKSkJ4eHiF7YuLi3H//n1wOJyGiig0xcXFOH78OK5evYqUlBSBfWCxWIiOjm7gdORHSUlJmDZtGjIzM6Gnp4fevXujWbNmyM3NRVRUFK5fv46XL1/C29sbLVq0YDpujaSnp8PJyUng++x7jfkrbBaLhd9//50//YrFYuHOnTu4c+eOwPvweDyMHTu2oSISQuqICmMiURITE+Hg4FDmB9vVq1dx9epVgffh8XiN/qKgiri5ueHQoUMAgFatWkFOTo7hRKQy+/btQ2ZmJjZv3gxra+ty579t8X3o0CE4OzszkLD2tm3bhvv370NNTQ3du3evcOUXUWBoaIgNGzYgIyMDPB4Pbm5uMDQ0FHj9gYyMDFRVVRv9MnSEkP/QHGMicXbt2sUfNfb19eVfuVyRbz/YbGxsoKKi0pAx68zU1BQcDgceHh4VbotKGpdBgwbhl19+wZEjRwS2mTNnDt69e1fpCGVjNGjQILRt2xZeXl5itROciYkJZs2ahRkzZjAdhRAiJOLzCUVINTk6OvL/7uvrC1NTU9jb2zOYqH6kp6fDxsaGimIRkZ+fjy5dulTaRltbG48fP26gRMJTWFiI/v37i1VRDADBwcFMRyCECJl4fUoRUkPf1oflcrkoKCgos+zSo0eP0LNnT0hJSTEVr060tLTw6dMnpmOQaurevTvCwsKwcuVKgUsIPn78GHp6eg2crO569+4t1vPY37x5g8zMTJSUlJS5aJLD4SA7Oxt3797F7t27GUxICKkumkpBJN61a9fg6uqKuXPnYvbs2QBKC2V9fX2oqKhg586dGDBgAMMpa+7WrVtYtmwZjh07Vma3LtI4xcbGYtq0aRgwYADWrl0LVVVV/jk2m43du3fj/PnzOH36tMitP/3q1StMmTIF06dPx7x58ypd91eUZGdnY968eXj58mWVbRvzRYWEkP9QYUwk2v379zF37lwoKirC2dkZ48ePB1BaiOzcuRN+fn748uUL3N3d0bdvX4bT1tzOnTtx8uRJ6OrqokOHDpCVlS3XRhS3uxZHtra2SE5ORkJCAqSlpdGhQwe0bdsWRUVFiIuLQ35+PuTk5MqtZ/xtZYTGbvPmzTh37hwAoEWLFgJfi6LQl29cXFxw5swZqKmpoUePHggODoaGhgY0NTURHx+P+Ph4tG7dGvv27UPv3r2ZjksIqQYqjIlEmzVrFmJiYnDx4kWoq6uXO5+cnAxLS0vo6+vjxIkTDCSsvTt37sDBwQHFxcWVtqNdnhqH2u7SBaDRbxl99OhRgVuT/6ix9+V7v/32GzgcDgIDAyErK4sFCxagSZMmOHjwIID/+r1r1y6MHj2a4bSEkOqgOcZEosXFxcHc3LzCohgA1NTUMGrUKAQEBDRwsrrbt28fuFwubG1t0adPHygoKDAdiVRClArCmvLy8oKysjJ27dolVq/FDx8+wMrKij/6raenB29vb/55Ozs73LhxAz4+PlQYEyIiqDAmEo3NZlc5oiorKwsul9tAiYTn7du3GDt2LFauXMl0FCLh0tPTMWnSJAwePJjpKEIlJSUFJSUl/u0OHTogMzMTmZmZaNmyJYDStY9v3LjBVERCSA1RYUwkWufOnRESEoKCgoIKR7GKiooQEhICTU1NBtLVTfPmzcvNRyWNR3h4ONTV1aGmpsa/XV2idjGluro6CgsLmY4hdO3atUNCQgL/docOHQAAr1+/LrPpR3Z2dkNHI4TUEhXGRKJZWVnhjz/+gIODA1avXo2uXbvyz8XHx2Pnzp14//491q1bx2DK2jEzM0NgYCDs7e3FZhUAcTJ79mzY29vz19CePXu2wGXafiRqc8KnTp2KXbt2Ydq0aXWaS93YDB48GJ6envDz88PYsWOhra0NOTk5eHt7w9DQEPn5+bhz5w7atGnDdFRCSDVRYUwk2sSJExEWFobAwECMGzcO8vLyUFRURH5+PgoLC8Hj8WBqaoqpU6cyHbXGZs2ahQcPHsDKygqTJk2ChoaGwLmdojYCKQ4sLCzK7LhoYWFR7cJY1Pz888/o2LEjJkyYgIEDB6Jjx44VvhZZLBaWLFnCQMLamTt3LgICArB69WoUFRVh4sSJGDduHLy9vfH06VMUFRUhMzMTdnZ2TEclhFQTrUpBCICAgABcuXIFsbGxyM7OhqKiIrS1tWFpaQlLS0um49WKjo4OWCwWeDxelQWXqI1AEtFS3VFiUVwh5ePHjzh27BjMzc3Rs2dPfPnyBU5OTrhz5w6aNGmCUaNGYcuWLWjatCnTUQkh1UCFMSFias2aNdUegdy6dWs9pyE/unLlSq3va2FhIcQk9c/X17fabUX1F9Ef5eXlQVZWFnJyckxHIYTUABXGhPyroKAAcXFxyMnJgbGxMXJzc6GsrMx0LCKmvo3o18S30X9RG1UlhBBRQXOMicTLzs6Gi4sLrl+/jpKSErBYLERHR+PcuXO4cuUKduzYAX19faZjEjEjaE5xTEwM4uLiRG5UWFK9fv0a58+fR2JiIjgcToWbmLBYLLi7uzOQjhBSU1QYE4mWm5uLKVOm4N27d+jYsSOkpKTw9u1bAACXy0VCQgLmzJmDCxcuoFOnTgynrZyTkxN+++03mJqa8m9XB20JzYxt27ZVePzAgQOIi4sTq+kt1b14lcViwdPTs57TCE94eDhsbW2rtbskIUQ0UGFMJNqhQ4fw7t07bNy4EZMmTcL+/fv527kuWrQIHTt2hKOjI44ePdroCxU/Pz906NCBXxj7+flV635UGJP69ujRo0rPs1gsKCoqQlpatH4kHTx4ECUlJXBwcICJiQmUlJSoCCZExInWpxAhQnbz5k0MHjwYkyZNAlB+ZMfMzAz+/v6IjIxkIl6NeHh4oH379mVuE9IY3L59u8LjhYWFSEhIwLFjx1BcXCxy0w1evHiBESNGYPHixUxHIYQICRXGRKJ9/PgRZmZmlbbR0tJCWFhYAyWqve932gJKNyjp1asX9PT0GEpESKnvf2H7UefOnTFgwACYm5tj3759cHZ2bsBkdSMtLY127doxHYMQIkRNmA5ACJNUVFSQnJxcaZvExESRXJ1i3759OHz4MNMxCKmSgoIChg8fjhs3bjAdpUb69OlT5TQRQohoocKYSLR+/frh5s2biI2NrfD88+fPERwcjH79+jVwsrpjs9lQU1NjOgYh1VJUVITs7GymY9TIihUr+FvH5+TkMB2HECIENJWCSLRFixYhODgYNjY2sLGx4a9IERgYiKdPn+LcuXOQlpbG/PnzGU5acxYWFvD394e1tXWjX1GDSLbIyEgEBASgY8eOTEepkX379qFdu3Y4efIkTp48iebNm1e4oQeLxcKdO3cYSEgIqSna4INIvIiICDg6OiI9PZ1/7NtWyioqKtixYwd+/fVXBhPWztGjR+Hh4YGsrCx07doV6urqFW5LS6tSMGPt2rUVHo+NjUVsbKzAdYxZLBZcXV3rM5rQGRsbV3icy+UiPz8fBQUF4PF42LRpEyZOnNiw4eqgultdAxD4rRQhpHGhwpgQlE47uH37Nl68eIHc3FwoKipCV1cXpqamUFRUZDperVT3hzbtpMaMmhRV3xPF56uyvsrIyEBLSwtTp06FtbV1A6YihJDyqDAmREw9fPiw2m1/XNGC1D9fX99a39fS0lKISUhtOTk5oW/fviI1yk0IqRwVxkSiJCUl1fq+6urqQkxCiOQQ1wKyV69eGDNmDDZt2sR0FEKIkNDFd0SiDB8+vFY7U7FYLERHR9dDovrH5XIRFhaG6Oho5OTkwMnJCa9evUKzZs1oDVbSIG7evImmTZuKXWGsoKBAO90RImaoMCYSxcDAgOkIDerJkydwdHREamoqeDweWCwWnJyccP36dRw7dgxr167F1KlTmY5JxJy4FpBLly6Fq6srunXrhpEjR0JJSYnpSISQOqKpFISIqbdv32LChAkoKSnBuHHj8OHDB4SEhCAmJgZ///03Nm7ciLy8PJw8eRJGRkZMxyVizMfHB66urli3bp1YFZALFizA//3f/yEzMxMAoKysDHl5+XLtaLk2QkQHFcZEonh4eKBnz57Q19ev9n18fX1x5coVuLu712My4Vu5ciVu3boFb29v6Ojo4MCBA3Bzc+OvaPCtcO7Tpw+OHTvGcFoizsS1gKTl2ggRPzSVgkgUV1dX2NvblyuM3d3d4eHhgdu3b5e7T0pKSo1WeGgsIiIiMHLkSIE/vDU1NTFixAiEhIQ0cDIiae7evVvmdk5OjljsFEfFLiHihwpjQgDk5eUhNTWV6RhClZubi59++qnSNs2bN0dubm4DJSKSigpIQoioaMJ0AEJI/Wjbti1evHhRaZvnz5+jbdu2DZSISKrIyMgqf/F8/fo1Ll682ECJhOvdu3f43//+h7lz52LChAkASkfJ/f39QbMVCREtVBgTIvA70ZUAABgNSURBVKZMTU3x4MEDgcWGh4cHHj9+jGHDhjVwMiJpZsyYUeWGJleuXIGLi0sDJRKeM2fOYMyYMTh27BjCwsLw8uVLAKUb7Dg5OWHlypXgcrkMpySEVBdNpSBETC1YsAA3b97E+vXr4ePjAzabDQDYtGkTnj9/jpcvX0JVVRV2dnYMJyXi5tatW/wCEQB4PB4iIiJQXFxcYfvi4mJcvXoVsrKyDRVRKEJCQuDi4gItLS0sXLgQjx49gpeXFwDA3NwcDx8+xPXr12FkZETbXRMiIqgwJkRMqaio4Pz58/jzzz8RHBzM/0r33LlzAICBAwdi8+bNaNGiBZMxiRhSU1PDkiVL+COlLBYLkZGRiIyMrPR+s2bNaoB0wnPixAn89NNP8PLygpKSEhISEvjn9PT04OHhgdGjR8PHx4cKY0JEBBXGhIixn376CW5ubsjIyMCLFy+Qm5sLRUVF6OrqQlVVlel4REzp6Ojg0KFDyMzMBI/Hg7OzM0xNTSuctsNisSAtLQ1VVVX06dOHgbS19+LFC4wbN07guswKCgoYNmwY/Pz8GjgZIaS2qDAmRAK0atUKv/76K9MxiAT5/vXm6+sLU1NTWFhYMJhI+IqLiyElJVVpGx6PBw6H00CJCCF1RYUxkTi3b99GSkpKmWPflpNau3ZtufbfNsQQVQEBAfD19cXLly/x5csXNG/eHL169YK1tTWGDBnCdDwiAc6cOcN0hHqhqamJ8PBwcLlcNGlS/lp2DoeD0NBQdOrUiYF0hJDaoMKYSJyYmBiBxa6gK+dZLFZ9RqoXJSUlsLe3x927d8Hj8aCoqIhWrVohNzcXN2/exK1btzB58mRs2LCB6ahEAmRkZODSpUv8iz0zMjLg5OSEyMhIqKurw9HREUOHDmU4Zc1YWlrCxcUF69atw++//17mXE5ODjZu3Ij3799jzZo1DCUkhNQUbQlNJEpVS0ZVxtLSUohJ6t+xY8fwv//9D0ZGRli7di26du3KPxcdHY2tW7ciKioKrq6uItc3IloSExMxceJE5Obm4u7du2jTpg0cHBxw8+ZNKCgo4OvXrwCAs2fPomfPngynrT4ul4tFixbh7t27kJaWhry8PL58+QItLS0kJiaCw+HAyMgIx48fr3LKBSGkcaDCmBAxNWrUKPB4PFy9ehVycnLlzhcUFGDs2LFQUVHBpUuXGEhIJMWaNWvg5+cHBwcHzJ49GwUFBRg8eDA6duyIixcv4vPnz5gwYQIMDAzg5ubGdNwa4XK5OHPmDHx8fPDmzRv+cXV1dUyYMAFz586FtDR9OUuIqKB3KyFiKjU1FZMnT66wKAZKr5g3NjamopjUu/DwcJiYmGDhwoUAgMDAQJSUlGDcuHGQl5dHhw4dMGLECNy6dYvhpDXXpEkTzJw5EzNnzkRhYSF/5ZdmzZoxHY0QUgu08x0hYqpt27ZIT0+vtE1WVhatY0zqXWZmJrS0tPi379+/DxaLhQEDBvCPNW/eHAUFBUzEq7UZM2bgypUr/Nvy8vJo06ZNmaLYw8MDI0aMYCIeIaQWqDAmRExNnz4dN27cwO3btys8/+zZMwQFBWHKlCkNnIxImp9++gkZGRn822FhYVBWVsYvv/zCP/bmzRv8/PPPTMSrNh6PBy6XCy6Xi5KSEjx8+BDJycn8Yz/+YbPZiIqKQlpaGtPRCSHVRFMpCBFTLVu2hK6uLuzt7TFw4ED0798fqqqqKCwsxPPnz+Hn58e/WGjv3r38+7FYLCxZsoTB5ETc6OnpISgoCGPGjMGjR4+Qnp4OCwsL/movAQEBuHfvHsaOHctw0sodP34cu3fvLnPMzc2tynnR2tra9RmLECJEdPEdIWJKR0en3DEWi4Wq3vIsFkvk124mjUtcXBxmzJiB3Nxc8Hg8yMvL4+LFi9DS0sKWLVvg6ekJFRUVeHl5Neo1fzkcDqZOncqfopSWloZmzZpVuPPdtx392rVrB0dHxzKj44SQxosKY0LE1OXLl2u9/jIt30aELTExEV5eXgCA8ePHo0uXLgAAb29vPHz4EPb29o26KK6Ijo4O7O3tYW9vz3QUQoiQUGFMiITj8XgiuYEJIUx7+PAh2rdvj/bt2zMdhRAiJHTxHSFiys3NrcppE+/fv6eL7wipJUNDQyqKCREzNGJMiJjS0dGBgYEBdu7cibZt25Y7f/78eezYsQNFRUU0p5jUO29vb3h6evJ3hKsIi8VCdHR0AyerG3HtFyGSilalIERMmZqa4tatWxg3bhw2b96M3377DQDw6dMnODs7IywsDE2bNsXatWsZTkrE3dmzZ7FlyxbweDwoKSmhdevWTEcSCnHtFyGSjEaMCRFjFy5cgKurK4qKimBtbY3evXtj69atyMnJwcCBA7Fp0yb6KpjUuzFjxiAtLQ2HDx9G3759mY4jNOLaL0IkGRXGhIi5pKQkrFmzBo8fPwYAKCkpwdnZGRYWFgwnI5JCX18f48ePx59//sl0FKES134RIsno4jtCxFxWVhYKCgrA4/HA4/FQUFCAd+/egc1mMx2NSAhlZWVIS4vfzD1x7RchkowKY0LEVGFhIVxcXDBlyhTExsZi2rRpOHv2LDp06ICjR4/C0tIST548YTomkQAmJia4c+cOvn79ynQUoRLXfhEiyWgqBSFiysTEBGlpaWjTpg22bt0KIyMjAACbzcauXbtw5swZsFgsTJ06FevWrWM4LRFn2dnZmD59Opo3b46ZM2eiY8eOkJOTq7Cturp6A6erPXHtFyGSjApjQsSUjo4Oxo4di/Xr11e4ZW1ERATWrl2LDx8+0HJtpF4ZGhqCw+GgsLCw0s1kRG1ZM3HtFyGSjCZHESKm9u7dixEjRgg8379/f/j7+8PFxaUBUxFJpK2tzXSEeiGu/SJEktGIMSFiwsPDAz179oS+vn617+Pr6wtfX194eHjUYzJCCCFENNDFd4SICVdXV/zzzz/ljru7u2PYsGEV3iclJQWRkZH1HY0QQggRCVQYEyLm8vLykJqaynQMQgghpNGjOcaEEEKESldXt1b3a+wXqYlrvwgh/6HCmBBCiFDV9tKVxn7Ji7j2ixDyHyqMCSGECFVsbCzTEeqFuPaLEPIfmmNMCCGEEEIIqDAmhBBCCCEEABXGhBBCCCGEAKA5xoSIldu3byMlJaXMsW/zIteuXVuuPW0FTQghhPyHdr4jREzo6OjU6n4sFosKZEIIIQQ0YkyI2Ni6dSvTEQghhBCRRiPGhBBCCCGEgC6+I4QQQgghBAAVxoQQQgghhACgwpgQQsQOzZAjhJDaocKYECJWHjx4AG1t7Qr/dOvWDf369cOUKVPg7u4ONpvNWM79+/dDW1sbe/bs4R+7fPkytLW14ejoWOvHff78OSZNmoTi4mJhxKxQTXJ+ez6mTJlSp39z+vTp0NbWxv379+v0OIIkJydDW1sbQ4YMqZfHJ4SIBlqVghAilhQUFDBs2LAyx0pKSpCbm4vIyEg8fvwYQUFBOH36NGRkZBhKKXwTJ06kEWNCCKklKowJIWKpRYsW2LVrV4XnkpOTYWNjg6ioKJw7dw4zZ85s4HQVGz58OHr06AElJaVaPwYVxYQQUns0lYIQInHU1NRga2sLAAgKCmI4zX+UlJSgpaWFn3/+mekohBAikWjEmBAikTp06AAASE9P5x9bs2YNfH19cebMGZw5cwb37t2DgoICFi9ejOnTpwMAPn78iCNH/r+9ew+qquweOP4FXjBwwoQSjRNm2UZBBdEjpZhoiJWAOo54Q/AygTqNl0jLW04G4WVEHUerEdMoTcuUxjEzRBTMOEpcJARBTUBEICxAMeSyf384Z7+e3zko76t/mO/6zPAHaz/72WvvPcMsnrP2Pp9x/PhxqqqqcHR0xNfXlzlz5qAoitlxqqqq+PTTT0lNTaWmpoaePXsSFRVlMaf9+/ezZMkSgoODzVa7MzIySExMJDc3l4aGBnQ6HUFBQYSHh2Nvb6/ta+Tp6QnA+fPntVhdXR0JCQn89NNPlJeX4+DggLe3N2+99RYDBw40y6e+vp5t27Zx+PBhKisr0el0REREPLTWkx9//JH9+/eTn59PbW0tHTp04MUXX2TMmDFMnjwZa2vztZvm5mY++eQTvv32W6qrq9HpdIwZM4YZM2bQoUMHs/Fnz54lISGBM2fOUF9fj4uLCwEBAURFReHk5HTfHGtra9m6dSunTp2irKwMGxsbXnrpJUJCQpg4cSI2NjYP5VoIIR4NUhgLIf4nFRUVAfDss8+abVuxYgU1NTUMHTqU4uJi7eu2CwoKmDlzJtevX8fNzQ1/f38qKyv54YcfSElJYfPmzQwbNkyb58qVK4SFhVFRUUH37t3x9/fnwoULzJs3j549e7Y7123btrF+/XqsrKzw8fGhc+fO5OTkEB8fT3p6Op9//jlubm4EBwdz8OBBAIKCgrCystLmuHr1KuHh4ZSVldG1a1f8/Pyor68nPT2dtLQ0Vq1axYQJE7TxtbW1TJs2jfPnz9OlSxf8/f25cuUKH3zwwX+Ue1tiYmL48ssvcXBwwMfHh44dO1JSUkJubi65ubmUlpaaFPpGcXFxXLp0iQEDBuDh4YHBYGDDhg2kpaWxc+dO7OzstLEHDhxg2bJltLa24uHhgV6vp6CggJ07d5KcnExiYiI6na7NHBsbG4mKiiI7Oxs3Nzf8/Py4desWZ86cITs7m/z8fGJjYx/4WgghHiGqEEI8RjIyMlRFUdThw4e3OaagoEDV6/Wqoijqvn37tPh7772nKoqient7q6WlpaqqqmpLS4uqqqp6+/ZtNSAgQFUURU1ISFBbW1u1/VJSUlRPT09Vr9erNTU1WjwqKkpVFEVdsWKF2tzcrKqqqra2tqobN25UFUVRFUVR4+PjtfHfffedqiiKGh0drcXOnj2r9urVS/Xx8VEzMzO1+M2bN9WwsDBVURR1x44dWtw4b1NTk8k5T5kyRVUURY2NjVVv376txXNyctSBAweqnp6eanFxsRZftWqVqiiKGhUVpd66dUuLf/PNN9ox7s6zLcb7MWnSJC2Wl5enKoqiBgQEmFwvVVXVgwcPqoqiqF5eXiZ5Gs+1d+/eanJysha/fv26Om7cOFVRFPWzzz7T4hcuXFA9PT1Vb29v9dSpU1q8paVFjY+PN8uprKxMVRRFHTp0qBY7cOCAdp533++SkhJVr9er7u7u6tWrV+97DYQQ/xzSYyyEeCz9+eefvPvuuyY/8+fPZ/z48YwdO5ba2loCAwMZN26c2b6vvfYazz33HID2cX5ycjKlpaX4+/sza9Ysk9XYESNGEBoaSm1tLfv27QPg2rVrpKam4uzszPLly7WP3K2srJg3bx69e/du13ns3buX1tZWZs+ezYABA7S4g4MDixYtws3NjaqqqnvOkZubS2ZmJu7u7rz//vsmrRBeXl7Mnj2bpqYmEhMTAbh9+zb79+/H1taW2NhYnnjiCW38hAkTzN728Z+qq6tj1KhRLFiwwKydISgoCEdHR27dukVNTY3ZviEhIQQEBGi/d+7cmY8++giA3bt3a/HExESampp4++23eeWVV7S4tbU1CxYsQFEUsrKyyMnJaTPP6upqAFxcXEzut5ubGx9//DFr1qwxuTZCiH8+aaUQQjyWGhoatLYCI1tbW5566in8/PwYPXo0Y8eONSl4jCz1CmdkZACYFFl3GzZsGLt27cJgMBAZGcnp06e18Xd/vA93iuOAgAAKCgruex7GeUaMGGG2rV+/fiQnJ993DmPugwYNsti3O2zYMNauXasdKy8vj4aGBvr374+zs7PZ+MDAQFJSUu573LYMHjyYwYMHm8Sam5u5fPkyOTk5tLa2Alh8z3RwcLBZzNPTExcXFyoqKigvL8fV1fWe98vKyoqhQ4dSVFTE6dOn8fb2tpinXq8HICEhgbKyMkaOHMmQIUNwcnIyKc6FEI8PKYyFEI8lV1dXjh079l/t26lTJ7NYRUUFcKfHNS4urs19r127BqCt4rq4uFgcd6/e1rsZVy0t9UK3lzF340OFbXnYud9LY2MjSUlJpKSkcOnSJSoqKrQvJTH+s6JaePWcq6urxfm6detGZWUlVVVVuLq6audi6ROBuxmvjSXe3t4sXbqU9evXc+TIEY4cOYKVlRV9+vRh1KhRTJw4EUdHx3adrxDin0EKYyGE+H8sraoaVzF9fX3v+To1Y2uApZXou/3rX+378/swvsHOmHvfvn15/vnn2xxnzPl+uT/omxiqqqoICwujpKQER0dH+vbty/Dhw3F3d2fQoEFERERw9epVi/taevME/LuINl7XlpYWAEaPHm3xfhoZH6xsS0REBMHBwRw9epS0tDQMBgN5eXnk5eXxxRdf8PXXX2ttN0KIfz4pjIUQoh2eeeYZ4M5H+Xe/vaEtXbt2BaC8vNzi9vv1Bd993PLycq5du0aPHj3Mtu/ZswcXFxeGDx9+zzkAhgwZwsKFC+97zIeVe1s2bNhASUkJISEhxMbGmrWa1NXVtblvVVUV3bp1M4sbC2njti5dulBeXs78+fPp3r37A+Xr5OREaGgooaGhtLa2kpWVRVxcHL/99hvbtm1j1apVDzS/EOLRIQ/fCSFEOxj7TU+cOGFx+65duxgzZgxbt24F4OWXX8ba2ppTp05x8+ZNs/HHjx9v13GND9ylpaWZbbt48SIrV65k8+bN7co9PT1dWz2+29GjRwkKCuLDDz8E7vTsdurUiXPnzllcuW1v7m3Jzs4GYNasWWZFcW5uLjdu3ACwmGt6erpZLDMzk+rqal544QWefvpp4P73a/HixYSGht6z3WbNmjX4+flx5swZLWZtbc3AgQOZM2cO8O/2EyHE40EKYyGEaIc333yTLl26kJyczI4dO0z6X8+ePcvGjRspLCzUHtxzdnYmKCiIuro6li1bZvIgWWJiIgaDoV3HnTp1KlZWVmzdupXCwkItfvPmTW2lMiQkRIsbWw3q6+u1mK+vLx4eHuTn57N27VqTXEpKSoiJiaG4uFhrs7C1tWXKlCm0tLSwePFirVCFO2/nSEpKalfubTG2mxw9etQkXlRUxKJFi7TfGxsbzfZNSEjQCmu484Ury5cvB2DGjBlafNq0adjY2LBp0yZ++eUXkzn27NnD999/T0FBAf369Wszz65du1JdXU18fLzJNWhububw4cMA99xfCPHPI60UQgjRDvb29mzatInIyEhWr17NV199hbu7O3/99RdZWVmoqkp4eLjJ2wqWLFlCYWEhhw8fJjs7Gy8vL8rKyjh37hz9+/c3KfDa4u3tzTvvvMP69esZP348er0ee3t7cnNzqamp4dVXXyU8PFwb3717d4qKiggPD6dHjx6sXr0aBwcH4uPjiYiIYMeOHRw6dAhPT0/+/vtvMjMzaWpqIjAwkLCwMG2euXPnkpWVhcFgICAgAL1ezx9//EFWVla7c2/L9OnT+fXXX9m8eTPHjh1Dp9NRWVlJbm4uHTp0QKfTceXKFZNvJTTq1asXU6dOZdCgQdjb25ORkUFDQwNBQUEmLS59+vRh6dKlxMTEMH36dDw8PNDpdPz+++8UFxdjY2PDunXrtBVmSyZPnsyhQ4fIyspixIgReHl5YWdnp62k9+zZk4iIiP/6OgghHj2yYiyEEO3k4+NDUlISkyZNQlVV0tLSKC0txdfXly1btrBs2TKT8U5OTuzevZvIyEhsbW1JTU2lsbGRmJgYJk+e3O7jRkZGkpCQgK+vL/n5+aSnp9OpUycWLlzIli1bTB4ui42NxdPTk8uXL2MwGCgrKwOgR48eJCUlMWvWLBwcHPj5558pLCykT58+xMXFsWHDBpOH6uzs7EhISCA6OprOnTtz4sQJqqqqiI6OJjo6+oGuY2BgINu3b0ev11NeXs7Jkye5ceMG48aN48CBA1qBnpqaarbvmjVrmDlzJhcvXuTkyZPodDpWrlzJunXrzB4aDAsLY9euXYwcOVJ7r3RDQwNvvPEG+/bt4/XXX79nnnZ2dmzfvp3IyEicnZ0xGAycPHmSjh07MnfuXPbu3cuTTz75QNdCCPFosVItvQ9HCCGEEEKI/zGyYiyEEEIIIQRSGAshhBBCCAFIYSyEEEIIIQQghbEQQgghhBCAFMZCCCGEEEIAUhgLIYQQQggBSGEshBBCCCEEIIWxEEIIIYQQgBTGQgghhBBCAFIYCyGEEEIIAUhhLIQQQgghBCCFsRBCCCGEEIAUxkIIIYQQQgDwf0ufnajK2XvKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 700x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(7, 7), dpi = 100)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_hat = XGB3_reg.predict(pred_proba_test_t)\n",
    "cm = confusion_matrix(y_true = targets_test, y_pred = y_hat, normalize = 'true')\n",
    "cm = np.round(cm, 2)\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.set(font_scale=1.4) # Adjust to fit\n",
    "sns.heatmap(cm, annot=True, ax=ax, cmap=\"Blues\", fmt=\"g\");  \n",
    "\n",
    "label_font = {'size':'10'}  # Adjust to fit\n",
    "ax.set_xlabel('Predicted labels', fontsize= 16);\n",
    "ax.set_ylabel('Observed labels', fontsize= 16);\n",
    "\n",
    "title_font = {'size':'21'}  # Adjust to fit\n",
    "ax.set_title('Confusion Matrix', fontdict=title_font);\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)  # Adjust to fit\n",
    "ax.xaxis.set_ticklabels(['Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International','Pop', 'Rock']);\n",
    "ax.yaxis.set_ticklabels(['Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International','Pop', 'Rock']);\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66, 0.04, 0.  , 0.09, 0.05, 0.03, 0.11, 0.01],\n",
       "       [0.04, 0.54, 0.08, 0.05, 0.09, 0.03, 0.1 , 0.06],\n",
       "       [0.01, 0.03, 0.7 , 0.01, 0.08, 0.03, 0.1 , 0.03],\n",
       "       [0.11, 0.02, 0.  , 0.68, 0.  , 0.05, 0.1 , 0.03],\n",
       "       [0.06, 0.14, 0.06, 0.  , 0.67, 0.01, 0.04, 0.03],\n",
       "       [0.06, 0.04, 0.02, 0.05, 0.02, 0.71, 0.08, 0.02],\n",
       "       [0.07, 0.09, 0.11, 0.11, 0.05, 0.07, 0.41, 0.09],\n",
       "       [0.03, 0.07, 0.05, 0.02, 0.04, 0.02, 0.09, 0.68]])"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:59:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:59:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "XGB_reg_fitted_fi = XGB_reg.fit(pred_proba_train_t, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_XGB = XGB_fitted.feature_importances_\n",
    "top_features = np.argsort(importances_XGB)[-80:]\n",
    "pred_proba_train_t.iloc[:, top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15148406196385622"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGB1\n",
    "sum(importances_XGB[0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09628592617809772"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LDA\n",
    "sum(importances_XGB[8:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07046711537986994"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#QDA\n",
    "sum(importances_XGB[16:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07924075983464718"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN\n",
    "sum(importances_XGB[24:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06241098418831825"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LR\n",
    "sum(importances_XGB[32:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15150816831737757"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGB2\n",
    "sum(importances_XGB[40:48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13309240993112326"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGB3\n",
    "sum(importances_XGB[48:56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06814045924693346"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NB\n",
    "sum(importances_XGB[56:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11019650101661682"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XTR\n",
    "sum(importances_XGB[64:72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07717357855290174"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NN\n",
    "sum(importances_XGB[72:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_transform = LinearDiscriminantAnalysis(n_components = 8 - 1)\n",
    "LDA_transform.fit(inputs_train_sc, targets_train)\n",
    "inputs_train_lda = LDA_transform.transform(inputs_train_sc)\n",
    "inputs_test_lda = LDA_transform.transform(inputs_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(X = targets_test, y_pred = y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
